--- Execution profile ---
Total samples       : 2775697
not_walkable_not_Java: 2 (0.00%)
unknown_Java        : 15169 (0.55%)
not_walkable_Java   : 4525 (0.16%)
deoptimization      : 3 (0.00%)
skipped             : 2 (0.00%)

--- 541643866 total (19.51%), 541589 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 258719356 total (9.32%), 258658 samples
  [ 0] Thread.interrupted
  [ 1] ReentrantLock$Sync.lockInterruptibly
  [ 2] ReentrantLock.lockInterruptibly
  [ 3] LinkedBlockingQueue.put
  [ 4] BlockingQueue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$60.0x0000000801036300.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 240251476 total (8.66%), 240376 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$60.0x0000000801036300.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 77198849 total (2.78%), 77047 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$Head.<init>
  [ 3] StreamSupport.stream
  [ 4] Collection.stream
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 77154526 total (2.78%), 77483 samples
  [ 0] Thread.interrupted
  [ 1] ReentrantLock$Sync.lockInterruptibly
  [ 2] ReentrantLock.lockInterruptibly
  [ 3] LinkedBlockingQueue.take
  [ 4] BlockingQueue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run

--- 63635048 total (2.29%), 63660 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] Cell.lambda$notifyLiveness$0
  [ 8] Cell$$Lambda$60.0x0000000801036300.accept
  [ 9] ArrayList.forEach
  [10] Cell.notifyLiveness
  [11] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 54744250 total (1.97%), 54816 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LinkedBlockingQueue.put
  [ 3] BlockingQueue.put
  [ 4] Channel.put
  [ 5] Cell.lambda$notifyLiveness$0
  [ 6] Cell$$Lambda$60.0x0000000801036300.accept
  [ 7] ArrayList.forEach
  [ 8] Cell.notifyLiveness
  [ 9] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 47709334 total (1.72%), 47740 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LinkedBlockingQueue.signalNotEmpty
  [ 5] LinkedBlockingQueue.put
  [ 6] BlockingQueue.put
  [ 7] Channel.put
  [ 8] Cell.lambda$notifyLiveness$0
  [ 9] Cell$$Lambda$60.0x0000000801036300.accept
  [10] ArrayList.forEach
  [11] Cell.notifyLiveness
  [12] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 42537599 total (1.53%), 42450 samples
  [ 0] StreamOpFlag.fromCharacteristics
  [ 1] StreamSupport.stream
  [ 2] Collection.stream
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 34374933 total (1.24%), 34531 samples
  [ 0] LinkedBlockingQueue.take
  [ 1] BlockingQueue.take
  [ 2] Channel.take
  [ 3] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 4] ReferencePipeline$3$1.accept
  [ 5] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 6] AbstractPipeline.copyInto
  [ 7] AbstractPipeline.wrapAndCopyInto
  [ 8] ReduceOps$ReduceOp.evaluateSequential
  [ 9] AbstractPipeline.evaluate
  [10] IntPipeline.reduce
  [11] IntPipeline.sum
  [12] Cell.calculateNextState
  [13] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [14] Iterable.forEach
  [15] CellsGroup.run
  [16] Continuation.enterSpecial
  [17] Continuation.run
  [18] VirtualThread.runContinuation
  [19] VirtualThread$$Lambda$51.0x000000080103df08.run
  [20] ForkJoinTask$RunnableExecuteAction.exec
  [21] ForkJoinTask.doExec
  [22] ForkJoinPool$WorkQueue.topLevelExec
  [23] ForkJoinPool.scan
  [24] ForkJoinPool.runWorker
  [25] ForkJoinWorkerThread.run

--- 33523512 total (1.21%), 33644 samples
  [ 0] Thread.interrupted
  [ 1] ReentrantLock$Sync.lockInterruptibly
  [ 2] ReentrantLock.lockInterruptibly
  [ 3] LinkedBlockingQueue.put
  [ 4] BlockingQueue.put
  [ 5] Channel.put
  [ 6] TickPerCell.lambda$tick$0
  [ 7] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 8] ChannelsGrid.lambda$forEachChannel$0
  [ 9] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [10] Dimensions.forEachRowCol
  [11] ChannelsGrid.forEachChannel
  [12] TickPerCell.tick
  [13] GameOfLife.calculateFrame
  [14] GameOfLife.lambda$calculateFrameBlocking$4
  [15] GameOfLife$$Lambda$53.0x0000000801035268.run
  [16] VirtualThread.run
  [17] VirtualThread$VThreadContinuation.lambda$new$0
  [18] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [19] Continuation.enter0
  [20] Continuation.enter
  [21] Continuation.enterSpecial
  [22] Continuation.run
  [23] VirtualThread.runContinuation
  [24] VirtualThread$$Lambda$51.0x000000080103df08.run
  [25] ForkJoinTask$RunnableExecuteAction.exec
  [26] ForkJoinTask.doExec
  [27] ForkJoinPool$WorkQueue.topLevelExec
  [28] ForkJoinPool.scan
  [29] ForkJoinPool.runWorker
  [30] ForkJoinWorkerThread.run

--- 33211187 total (1.20%), 33217 samples
  [ 0] vtable stub
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 31333477 total (1.13%), 31434 samples
  [ 0] Thread.interrupted
  [ 1] ReentrantLock$Sync.lockInterruptibly
  [ 2] ReentrantLock.lockInterruptibly
  [ 3] LinkedBlockingQueue.put
  [ 4] BlockingQueue.put
  [ 5] Channel.put
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 30851643 total (1.11%), 30844 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LinkedBlockingQueue.signalNotEmpty
  [ 3] LinkedBlockingQueue.put
  [ 4] BlockingQueue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$60.0x0000000801036300.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 28582291 total (1.03%), 28594 samples
  [ 0] ReferencePipeline$4.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 26767834 total (0.96%), 26804 samples
  [ 0] ReferencePipeline$3.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 26048644 total (0.94%), 26143 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LinkedBlockingQueue.signalNotEmpty
  [ 3] LinkedBlockingQueue.put
  [ 4] BlockingQueue.put
  [ 5] Channel.put
  [ 6] TickPerCell.lambda$tick$0
  [ 7] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 8] ChannelsGrid.lambda$forEachChannel$0
  [ 9] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [10] Dimensions.forEachRowCol
  [11] ChannelsGrid.forEachChannel
  [12] TickPerCell.tick
  [13] GameOfLife.calculateFrame
  [14] GameOfLife.lambda$calculateFrameBlocking$4
  [15] GameOfLife$$Lambda$53.0x0000000801035268.run
  [16] VirtualThread.run
  [17] VirtualThread$VThreadContinuation.lambda$new$0
  [18] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [19] Continuation.enter0
  [20] Continuation.enter
  [21] Continuation.enterSpecial
  [22] Continuation.run
  [23] VirtualThread.runContinuation
  [24] VirtualThread$$Lambda$51.0x000000080103df08.run
  [25] ForkJoinTask$RunnableExecuteAction.exec
  [26] ForkJoinTask.doExec
  [27] ForkJoinPool$WorkQueue.topLevelExec
  [28] ForkJoinPool.scan
  [29] ForkJoinPool.runWorker
  [30] ForkJoinWorkerThread.run

--- 22803523 total (0.82%), 22843 samples
  [ 0] Thread.interrupted
  [ 1] ReentrantLock$Sync.lockInterruptibly
  [ 2] ReentrantLock.lockInterruptibly
  [ 3] LinkedBlockingQueue.take
  [ 4] BlockingQueue.take
  [ 5] Channel.take
  [ 6] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 7] ChannelsGrid.lambda$forEachChannel$1
  [ 8] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 9] Dimensions.forEachRowCol
  [10] ChannelsGrid.forEachChannel
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$53.0x0000000801035268.run
  [14] VirtualThread.run
  [15] VirtualThread$VThreadContinuation.lambda$new$0
  [16] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [17] Continuation.enter0
  [18] Continuation.enter
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run

--- 22723185 total (0.82%), 22718 samples
  [ 0] Cell$$Lambda$60.0x0000000801036300.accept
  [ 1] ArrayList.forEach
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 22094039 total (0.80%), 22175 samples
  [ 0] LinkedBlockingQueue.put
  [ 1] BlockingQueue.put
  [ 2] Channel.put
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 21805408 total (0.79%), 21911 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.take
  [ 5] BlockingQueue.take
  [ 6] Channel.take
  [ 7] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 8] ReferencePipeline$3$1.accept
  [ 9] ArrayList$ArrayListSpliterator.forEachRemaining
  [10] AbstractPipeline.copyInto
  [11] AbstractPipeline.wrapAndCopyInto
  [12] ReduceOps$ReduceOp.evaluateSequential
  [13] AbstractPipeline.evaluate
  [14] IntPipeline.reduce
  [15] IntPipeline.sum
  [16] Cell.calculateNextState
  [17] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [18] Iterable.forEach
  [19] CellsGroup.run
  [20] Continuation.enterSpecial
  [21] Continuation.run
  [22] VirtualThread.runContinuation
  [23] VirtualThread$$Lambda$51.0x000000080103df08.run
  [24] ForkJoinTask$RunnableExecuteAction.exec
  [25] ForkJoinTask.doExec
  [26] ForkJoinPool$WorkQueue.topLevelExec
  [27] ForkJoinPool.scan
  [28] ForkJoinPool.runWorker
  [29] ForkJoinWorkerThread.run

--- 20527571 total (0.74%), 20605 samples
  [ 0] ReentrantLock.lockInterruptibly
  [ 1] LinkedBlockingQueue.take
  [ 2] BlockingQueue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run

--- 20408987 total (0.74%), 20368 samples
  [ 0] StreamOpFlag.fromCharacteristics
  [ 1] StreamSupport.stream
  [ 2] Collection.stream
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 18233758 total (0.66%), 18297 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LinkedBlockingQueue.put
  [ 3] BlockingQueue.put
  [ 4] Channel.put
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 17967064 total (0.65%), 17572 samples
  [ 0] vframeStream::vframeStream(JavaThread*, bool, bool, bool)
  [ 1] SharedRuntime::find_callee_method(JavaThread*)
  [ 2] SharedRuntime::reresolve_call_site(JavaThread*)
  [ 3] SharedRuntime::handle_wrong_method(JavaThread*)
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 17592654 total (0.63%), 17617 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$4$1.<init>
  [ 2] ReferencePipeline$4.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 17275335 total (0.62%), 17295 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$3$1.<init>
  [ 2] ReferencePipeline$3.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 16961263 total (0.61%), 17041 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LinkedBlockingQueue.take
  [ 3] BlockingQueue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run

--- 16360503 total (0.59%), 16432 samples
  [ 0] LinkedBlockingQueue.put
  [ 1] BlockingQueue.put
  [ 2] Channel.put
  [ 3] TickPerCell.lambda$tick$0
  [ 4] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 5] ChannelsGrid.lambda$forEachChannel$0
  [ 6] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] TickPerCell.tick
  [10] GameOfLife.calculateFrame
  [11] GameOfLife.lambda$calculateFrameBlocking$4
  [12] GameOfLife$$Lambda$53.0x0000000801035268.run
  [13] VirtualThread.run
  [14] VirtualThread$VThreadContinuation.lambda$new$0
  [15] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [16] Continuation.enter0
  [17] Continuation.enter
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run

--- 15864127 total (0.57%), 15899 samples
  [ 0] LinkedBlockingQueue.take
  [ 1] BlockingQueue.take
  [ 2] Channel.take
  [ 3] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 4] ChannelsGrid.lambda$forEachChannel$1
  [ 5] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 6] Dimensions.forEachRowCol
  [ 7] ChannelsGrid.forEachChannel
  [ 8] GameOfLife.calculateFrame
  [ 9] GameOfLife.lambda$calculateFrameBlocking$4
  [10] GameOfLife$$Lambda$53.0x0000000801035268.run
  [11] VirtualThread.run
  [12] VirtualThread$VThreadContinuation.lambda$new$0
  [13] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [14] Continuation.enter0
  [15] Continuation.enter
  [16] Continuation.enterSpecial
  [17] Continuation.run
  [18] VirtualThread.runContinuation
  [19] VirtualThread$$Lambda$51.0x000000080103df08.run
  [20] ForkJoinTask$RunnableExecuteAction.exec
  [21] ForkJoinTask.doExec
  [22] ForkJoinPool$WorkQueue.topLevelExec
  [23] ForkJoinPool.scan
  [24] ForkJoinPool.runWorker
  [25] ForkJoinWorkerThread.run

--- 14605849 total (0.53%), 14584 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 14192428 total (0.51%), 14255 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LinkedBlockingQueue.signalNotFull
  [ 5] LinkedBlockingQueue.take
  [ 6] BlockingQueue.take
  [ 7] Channel.take
  [ 8] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 9] ReferencePipeline$3$1.accept
  [10] ArrayList$ArrayListSpliterator.forEachRemaining
  [11] AbstractPipeline.copyInto
  [12] AbstractPipeline.wrapAndCopyInto
  [13] ReduceOps$ReduceOp.evaluateSequential
  [14] AbstractPipeline.evaluate
  [15] IntPipeline.reduce
  [16] IntPipeline.sum
  [17] Cell.calculateNextState
  [18] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [19] Iterable.forEach
  [20] CellsGroup.run
  [21] Continuation.enterSpecial
  [22] Continuation.run
  [23] VirtualThread.runContinuation
  [24] VirtualThread$$Lambda$51.0x000000080103df08.run
  [25] ForkJoinTask$RunnableExecuteAction.exec
  [26] ForkJoinTask.doExec
  [27] ForkJoinPool$WorkQueue.topLevelExec
  [28] ForkJoinPool.scan
  [29] ForkJoinPool.runWorker
  [30] ForkJoinWorkerThread.run

--- 13874741 total (0.50%), 13939 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LinkedBlockingQueue.signalNotFull
  [ 3] LinkedBlockingQueue.take
  [ 4] BlockingQueue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run

--- 13320834 total (0.48%), 13368 samples
  [ 0] LinkedBlockingQueue.take
  [ 1] BlockingQueue.take
  [ 2] Channel.take
  [ 3] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 4] ReferencePipeline$3$1.accept
  [ 5] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 6] AbstractPipeline.copyInto
  [ 7] AbstractPipeline.wrapAndCopyInto
  [ 8] ReduceOps$ReduceOp.evaluateSequential
  [ 9] AbstractPipeline.evaluate
  [10] IntPipeline.reduce
  [11] IntPipeline.sum
  [12] Cell.calculateNextState
  [13] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [14] Iterable.forEach
  [15] CellsGroup.run
  [16] Continuation.enterSpecial
  [17] Continuation.run
  [18] VirtualThread.runContinuation
  [19] VirtualThread$$Lambda$51.0x000000080103df08.run
  [20] ForkJoinTask$RunnableExecuteAction.exec
  [21] ForkJoinTask.doExec
  [22] ForkJoinPool$WorkQueue.topLevelExec
  [23] ForkJoinPool.scan
  [24] ForkJoinPool.runWorker
  [25] ForkJoinWorkerThread.run

--- 11964795 total (0.43%), 11996 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LinkedBlockingQueue.signalNotFull
  [ 3] LinkedBlockingQueue.take
  [ 4] BlockingQueue.take
  [ 5] Channel.take
  [ 6] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 7] ChannelsGrid.lambda$forEachChannel$1
  [ 8] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 9] Dimensions.forEachRowCol
  [10] ChannelsGrid.forEachChannel
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$53.0x0000000801035268.run
  [14] VirtualThread.run
  [15] VirtualThread$VThreadContinuation.lambda$new$0
  [16] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [17] Continuation.enter0
  [18] Continuation.enter
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run

--- 11543343 total (0.42%), 11576 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LinkedBlockingQueue.signalNotEmpty
  [ 3] LinkedBlockingQueue.put
  [ 4] BlockingQueue.put
  [ 5] Channel.put
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 11162781 total (0.40%), 11214 samples
  [ 0] LinkedBlockingQueue.dequeue
  [ 1] LinkedBlockingQueue.take
  [ 2] BlockingQueue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run

--- 11065125 total (0.40%), 11114 samples
  [ 0] AbstractOwnableSynchronizer.setExclusiveOwnerThread
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] TickPerCell.lambda$tick$0
  [ 8] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 9] ChannelsGrid.lambda$forEachChannel$0
  [10] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [11] Dimensions.forEachRowCol
  [12] ChannelsGrid.forEachChannel
  [13] TickPerCell.tick
  [14] GameOfLife.calculateFrame
  [15] GameOfLife.lambda$calculateFrameBlocking$4
  [16] GameOfLife$$Lambda$53.0x0000000801035268.run
  [17] VirtualThread.run
  [18] VirtualThread$VThreadContinuation.lambda$new$0
  [19] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [20] Continuation.enter0
  [21] Continuation.enter
  [22] Continuation.enterSpecial
  [23] Continuation.run
  [24] VirtualThread.runContinuation
  [25] VirtualThread$$Lambda$51.0x000000080103df08.run
  [26] ForkJoinTask$RunnableExecuteAction.exec
  [27] ForkJoinTask.doExec
  [28] ForkJoinPool$WorkQueue.topLevelExec
  [29] ForkJoinPool.scan
  [30] ForkJoinPool.runWorker
  [31] ForkJoinWorkerThread.run

--- 10959709 total (0.39%), 11000 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] TickPerCell.lambda$tick$0
  [ 8] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 9] ChannelsGrid.lambda$forEachChannel$0
  [10] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [11] Dimensions.forEachRowCol
  [12] ChannelsGrid.forEachChannel
  [13] TickPerCell.tick
  [14] GameOfLife.calculateFrame
  [15] GameOfLife.lambda$calculateFrameBlocking$4
  [16] GameOfLife$$Lambda$53.0x0000000801035268.run
  [17] VirtualThread.run
  [18] VirtualThread$VThreadContinuation.lambda$new$0
  [19] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [20] Continuation.enter0
  [21] Continuation.enter
  [22] Continuation.enterSpecial
  [23] Continuation.run
  [24] VirtualThread.runContinuation
  [25] VirtualThread$$Lambda$51.0x000000080103df08.run
  [26] ForkJoinTask$RunnableExecuteAction.exec
  [27] ForkJoinTask.doExec
  [28] ForkJoinPool$WorkQueue.topLevelExec
  [29] ForkJoinPool.scan
  [30] ForkJoinPool.runWorker
  [31] ForkJoinWorkerThread.run

--- 10888916 total (0.39%), 10933 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LinkedBlockingQueue.put
  [ 3] BlockingQueue.put
  [ 4] Channel.put
  [ 5] TickPerCell.lambda$tick$0
  [ 6] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 7] ChannelsGrid.lambda$forEachChannel$0
  [ 8] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [ 9] Dimensions.forEachRowCol
  [10] ChannelsGrid.forEachChannel
  [11] TickPerCell.tick
  [12] GameOfLife.calculateFrame
  [13] GameOfLife.lambda$calculateFrameBlocking$4
  [14] GameOfLife$$Lambda$53.0x0000000801035268.run
  [15] VirtualThread.run
  [16] VirtualThread$VThreadContinuation.lambda$new$0
  [17] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [18] Continuation.enter0
  [19] Continuation.enter
  [20] Continuation.enterSpecial
  [21] Continuation.run
  [22] VirtualThread.runContinuation
  [23] VirtualThread$$Lambda$51.0x000000080103df08.run
  [24] ForkJoinTask$RunnableExecuteAction.exec
  [25] ForkJoinTask.doExec
  [26] ForkJoinPool$WorkQueue.topLevelExec
  [27] ForkJoinPool.scan
  [28] ForkJoinPool.runWorker
  [29] ForkJoinWorkerThread.run

--- 10530073 total (0.38%), 10569 samples
  [ 0] LinkedBlockingQueue.enqueue
  [ 1] LinkedBlockingQueue.put
  [ 2] BlockingQueue.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] Continuation.enterSpecial
  [ 9] Continuation.run
  [10] VirtualThread.runContinuation
  [11] VirtualThread$$Lambda$51.0x000000080103df08.run
  [12] ForkJoinTask$RunnableExecuteAction.exec
  [13] ForkJoinTask.doExec
  [14] ForkJoinPool$WorkQueue.topLevelExec
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 10377005 total (0.37%), 10395 samples
  [ 0] ArrayList$ArrayListSpliterator.<init>
  [ 1] ArrayList.spliterator
  [ 2] Collection.stream
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 9824267 total (0.35%), 9853 samples
  [ 0] Dimensions.forEachRowCol
  [ 1] ChannelsGrid.forEachChannel
  [ 2] GameOfLife.calculateFrame
  [ 3] GameOfLife.lambda$calculateFrameBlocking$4
  [ 4] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 5] VirtualThread.run
  [ 6] VirtualThread$VThreadContinuation.lambda$new$0
  [ 7] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 8] Continuation.enter0
  [ 9] Continuation.enter
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 9789787 total (0.35%), 9812 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LinkedBlockingQueue.signalNotEmpty
  [ 5] LinkedBlockingQueue.put
  [ 6] BlockingQueue.put
  [ 7] Channel.put
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 9636875 total (0.35%), 9632 samples
  [ 0] StreamSupport.stream
  [ 1] Collection.stream
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 9330960 total (0.34%), 9347 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$Head.<init>
  [ 3] StreamSupport.stream
  [ 4] Collection.stream
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 9046164 total (0.33%), 9085 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LinkedBlockingQueue.signalNotEmpty
  [ 5] LinkedBlockingQueue.put
  [ 6] BlockingQueue.put
  [ 7] Channel.put
  [ 8] TickPerCell.lambda$tick$0
  [ 9] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [10] ChannelsGrid.lambda$forEachChannel$0
  [11] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [12] Dimensions.forEachRowCol
  [13] ChannelsGrid.forEachChannel
  [14] TickPerCell.tick
  [15] GameOfLife.calculateFrame
  [16] GameOfLife.lambda$calculateFrameBlocking$4
  [17] GameOfLife$$Lambda$53.0x0000000801035268.run
  [18] VirtualThread.run
  [19] VirtualThread$VThreadContinuation.lambda$new$0
  [20] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [21] Continuation.enter0
  [22] Continuation.enter
  [23] Continuation.enterSpecial
  [24] Continuation.run
  [25] VirtualThread.runContinuation
  [26] VirtualThread$$Lambda$51.0x000000080103df08.run
  [27] ForkJoinTask$RunnableExecuteAction.exec
  [28] ForkJoinTask.doExec
  [29] ForkJoinPool$WorkQueue.topLevelExec
  [30] ForkJoinPool.scan
  [31] ForkJoinPool.runWorker
  [32] ForkJoinWorkerThread.run

--- 8715088 total (0.31%), 8718 samples
  [ 0] AbstractOwnableSynchronizer.getExclusiveOwnerThread
  [ 1] ReentrantLock$Sync.tryRelease
  [ 2] AbstractQueuedSynchronizer.release
  [ 3] ReentrantLock.unlock
  [ 4] LinkedBlockingQueue.signalNotEmpty
  [ 5] LinkedBlockingQueue.put
  [ 6] BlockingQueue.put
  [ 7] Channel.put
  [ 8] Cell.lambda$notifyLiveness$0
  [ 9] Cell$$Lambda$60.0x0000000801036300.accept
  [10] ArrayList.forEach
  [11] Cell.notifyLiveness
  [12] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 8551164 total (0.31%), 8561 samples
  [ 0] Sink$ChainedReference.begin
  [ 1] Sink$ChainedReference.begin
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 8410679 total (0.30%), 8445 samples
  [ 0] LinkedBlockingQueue.enqueue
  [ 1] LinkedBlockingQueue.put
  [ 2] BlockingQueue.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$53.0x0000000801035268.run
  [14] VirtualThread.run
  [15] VirtualThread$VThreadContinuation.lambda$new$0
  [16] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [17] Continuation.enter0
  [18] Continuation.enter
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run

--- 7437045 total (0.27%), 7458 samples
  [ 0] Dimensions.forEachRowCol
  [ 1] ChannelsGrid.forEachChannel
  [ 2] TickPerCell.tick
  [ 3] GameOfLife.calculateFrame
  [ 4] GameOfLife.lambda$calculateFrameBlocking$4
  [ 5] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 6] VirtualThread.run
  [ 7] VirtualThread$VThreadContinuation.lambda$new$0
  [ 8] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 9] Continuation.enter0
  [10] Continuation.enter
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 7436322 total (0.27%), 7437 samples
  [ 0] Thread.interrupted
  [ 1] ReentrantLock$Sync.lockInterruptibly
  [ 2] ReentrantLock.lockInterruptibly
  [ 3] LinkedBlockingQueue.take
  [ 4] BlockingQueue.take
  [ 5] Channel.take
  [ 6] TickPerCell.waitTick
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 7260602 total (0.26%), 7279 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LinkedBlockingQueue.take
  [ 3] BlockingQueue.take
  [ 4] Channel.take
  [ 5] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 6] ChannelsGrid.lambda$forEachChannel$1
  [ 7] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] GameOfLife.calculateFrame
  [11] GameOfLife.lambda$calculateFrameBlocking$4
  [12] GameOfLife$$Lambda$53.0x0000000801035268.run
  [13] VirtualThread.run
  [14] VirtualThread$VThreadContinuation.lambda$new$0
  [15] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [16] Continuation.enter0
  [17] Continuation.enter
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run

--- 7198536 total (0.26%), 7217 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LinkedBlockingQueue.signalNotFull
  [ 5] LinkedBlockingQueue.take
  [ 6] BlockingQueue.take
  [ 7] Channel.take
  [ 8] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 9] ChannelsGrid.lambda$forEachChannel$1
  [10] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [11] Dimensions.forEachRowCol
  [12] ChannelsGrid.forEachChannel
  [13] GameOfLife.calculateFrame
  [14] GameOfLife.lambda$calculateFrameBlocking$4
  [15] GameOfLife$$Lambda$53.0x0000000801035268.run
  [16] VirtualThread.run
  [17] VirtualThread$VThreadContinuation.lambda$new$0
  [18] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [19] Continuation.enter0
  [20] Continuation.enter
  [21] Continuation.enterSpecial
  [22] Continuation.run
  [23] VirtualThread.runContinuation
  [24] VirtualThread$$Lambda$51.0x000000080103df08.run
  [25] ForkJoinTask$RunnableExecuteAction.exec
  [26] ForkJoinTask.doExec
  [27] ForkJoinPool$WorkQueue.topLevelExec
  [28] ForkJoinPool.scan
  [29] ForkJoinPool.runWorker
  [30] ForkJoinWorkerThread.run

--- 6887955 total (0.25%), 6914 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 6508871 total (0.23%), 6489 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 6380202 total (0.23%), 6376 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LinkedBlockingQueue.signalNotFull
  [ 3] LinkedBlockingQueue.take
  [ 4] BlockingQueue.take
  [ 5] Channel.take
  [ 6] TickPerCell.waitTick
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 6232279 total (0.22%), 6244 samples
  [ 0] LinkedBlockingQueue.dequeue
  [ 1] LinkedBlockingQueue.take
  [ 2] BlockingQueue.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$53.0x0000000801035268.run
  [12] VirtualThread.run
  [13] VirtualThread$VThreadContinuation.lambda$new$0
  [14] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [15] Continuation.enter0
  [16] Continuation.enter
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run

--- 5792062 total (0.21%), 5801 samples
  [ 0] AbstractQueuedSynchronizer.signalNext
  [ 1] AbstractQueuedSynchronizer.release
  [ 2] ReentrantLock.unlock
  [ 3] LinkedBlockingQueue.signalNotEmpty
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 5776248 total (0.21%), 5774 samples
  [ 0] LinkedBlockingQueue.take
  [ 1] BlockingQueue.take
  [ 2] Channel.take
  [ 3] TickPerCell.waitTick
  [ 4] Cell.notifyLiveness
  [ 5] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] Continuation.enterSpecial
  [ 9] Continuation.run
  [10] VirtualThread.runContinuation
  [11] VirtualThread$$Lambda$51.0x000000080103df08.run
  [12] ForkJoinTask$RunnableExecuteAction.exec
  [13] ForkJoinTask.doExec
  [14] ForkJoinPool$WorkQueue.topLevelExec
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 5040512 total (0.18%), 5055 samples
  [ 0] AbstractOwnableSynchronizer.setExclusiveOwnerThread
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LinkedBlockingQueue.signalNotFull
  [ 5] LinkedBlockingQueue.take
  [ 6] BlockingQueue.take
  [ 7] Channel.take
  [ 8] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 9] ChannelsGrid.lambda$forEachChannel$1
  [10] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [11] Dimensions.forEachRowCol
  [12] ChannelsGrid.forEachChannel
  [13] GameOfLife.calculateFrame
  [14] GameOfLife.lambda$calculateFrameBlocking$4
  [15] GameOfLife$$Lambda$53.0x0000000801035268.run
  [16] VirtualThread.run
  [17] VirtualThread$VThreadContinuation.lambda$new$0
  [18] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [19] Continuation.enter0
  [20] Continuation.enter
  [21] Continuation.enterSpecial
  [22] Continuation.run
  [23] VirtualThread.runContinuation
  [24] VirtualThread$$Lambda$51.0x000000080103df08.run
  [25] ForkJoinTask$RunnableExecuteAction.exec
  [26] ForkJoinTask.doExec
  [27] ForkJoinPool$WorkQueue.topLevelExec
  [28] ForkJoinPool.scan
  [29] ForkJoinPool.runWorker
  [30] ForkJoinWorkerThread.run

--- 4890581 total (0.18%), 4798 samples
  [ 0] psi_group_change_[k]
  [ 1] psi_task_switch_[k]
  [ 2] __schedule_[k]
  [ 3] schedule_[k]
  [ 4] futex_wait_queue_[k]
  [ 5] futex_wait_[k]
  [ 6] do_futex_[k]
  [ 7] __x64_sys_futex_[k]
  [ 8] do_syscall_64_[k]
  [ 9] entry_SYSCALL_64_after_hwframe_[k]
  [10] __futex_abstimed_wait_common
  [11] Unsafe.park
  [12] LockSupport.park
  [13] ForkJoinPool.awaitWork
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 4684128 total (0.17%), 4686 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$4$1.<init>
  [ 2] ReferencePipeline$4.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 4657491 total (0.17%), 4660 samples
  [ 0] ReferencePipeline$4.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 4448607 total (0.16%), 4457 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.take
  [ 5] BlockingQueue.take
  [ 6] Channel.take
  [ 7] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 8] ChannelsGrid.lambda$forEachChannel$1
  [ 9] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [10] Dimensions.forEachRowCol
  [11] ChannelsGrid.forEachChannel
  [12] GameOfLife.calculateFrame
  [13] GameOfLife.lambda$calculateFrameBlocking$4
  [14] GameOfLife$$Lambda$53.0x0000000801035268.run
  [15] VirtualThread.run
  [16] VirtualThread$VThreadContinuation.lambda$new$0
  [17] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [18] Continuation.enter0
  [19] Continuation.enter
  [20] Continuation.enterSpecial
  [21] Continuation.run
  [22] VirtualThread.runContinuation
  [23] VirtualThread$$Lambda$51.0x000000080103df08.run
  [24] ForkJoinTask$RunnableExecuteAction.exec
  [25] ForkJoinTask.doExec
  [26] ForkJoinPool$WorkQueue.topLevelExec
  [27] ForkJoinPool.scan
  [28] ForkJoinPool.runWorker
  [29] ForkJoinWorkerThread.run

--- 4339303 total (0.16%), 4355 samples
  [ 0] AbstractOwnableSynchronizer.setExclusiveOwnerThread
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LinkedBlockingQueue.signalNotEmpty
  [ 5] LinkedBlockingQueue.put
  [ 6] BlockingQueue.put
  [ 7] Channel.put
  [ 8] TickPerCell.lambda$tick$0
  [ 9] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [10] ChannelsGrid.lambda$forEachChannel$0
  [11] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [12] Dimensions.forEachRowCol
  [13] ChannelsGrid.forEachChannel
  [14] TickPerCell.tick
  [15] GameOfLife.calculateFrame
  [16] GameOfLife.lambda$calculateFrameBlocking$4
  [17] GameOfLife$$Lambda$53.0x0000000801035268.run
  [18] VirtualThread.run
  [19] VirtualThread$VThreadContinuation.lambda$new$0
  [20] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [21] Continuation.enter0
  [22] Continuation.enter
  [23] Continuation.enterSpecial
  [24] Continuation.run
  [25] VirtualThread.runContinuation
  [26] VirtualThread$$Lambda$51.0x000000080103df08.run
  [27] ForkJoinTask$RunnableExecuteAction.exec
  [28] ForkJoinTask.doExec
  [29] ForkJoinPool$WorkQueue.topLevelExec
  [30] ForkJoinPool.scan
  [31] ForkJoinPool.runWorker
  [32] ForkJoinWorkerThread.run

--- 4291185 total (0.15%), 4297 samples
  [ 0] Sink$ChainedReference.begin
  [ 1] Sink$ChainedReference.begin
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 4281424 total (0.15%), 4224 samples
  [ 0] InstanceKlass::find_method_index(Array<Method*> const*, Symbol const*, Symbol const*, Klass::OverpassLookupMode, Klass::StaticLookupMode, Klass::PrivateLookupMode) [clone .constprop.0]
  [ 1] InstanceKlass::uncached_lookup_method(Symbol const*, Symbol const*, Klass::OverpassLookupMode, Klass::PrivateLookupMode) const
  [ 2] LinkResolver::lookup_method_in_klasses(LinkInfo const&, bool, bool)
  [ 3] LinkResolver::resolve_method(LinkInfo const&, Bytecodes::Code, JavaThread*)
  [ 4] LinkResolver::resolve_continuation_enter(CallInfo&, JavaThread*)
  [ 5] SharedRuntime::find_callee_info_helper(vframeStream&, Bytecodes::Code&, CallInfo&, JavaThread*)
  [ 6] SharedRuntime::find_callee_method(JavaThread*)
  [ 7] SharedRuntime::reresolve_call_site(JavaThread*)
  [ 8] SharedRuntime::handle_wrong_method(JavaThread*)
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 4225773 total (0.15%), 4237 samples
  [ 0] ReentrantLock.lockInterruptibly
  [ 1] LinkedBlockingQueue.put
  [ 2] BlockingQueue.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] Continuation.enterSpecial
  [ 9] Continuation.run
  [10] VirtualThread.runContinuation
  [11] VirtualThread$$Lambda$51.0x000000080103df08.run
  [12] ForkJoinTask$RunnableExecuteAction.exec
  [13] ForkJoinTask.doExec
  [14] ForkJoinPool$WorkQueue.topLevelExec
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 4117868 total (0.15%), 4116 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LinkedBlockingQueue.signalNotFull
  [ 5] LinkedBlockingQueue.take
  [ 6] BlockingQueue.take
  [ 7] Channel.take
  [ 8] TickPerCell.waitTick
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 4114396 total (0.15%), 4112 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LinkedBlockingQueue.take
  [ 3] BlockingQueue.take
  [ 4] Channel.take
  [ 5] TickPerCell.waitTick
  [ 6] Cell.notifyLiveness
  [ 7] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 3999568 total (0.14%), 4013 samples
  [ 0] ReentrantLock.lockInterruptibly
  [ 1] LinkedBlockingQueue.take
  [ 2] BlockingQueue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run

--- 3980594 total (0.14%), 3984 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$3$1.<init>
  [ 2] ReferencePipeline$3.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 3908183 total (0.14%), 3914 samples
  [ 0] ReferencePipeline.map
  [ 1] Cell.calculateNextState
  [ 2] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 3] Iterable.forEach
  [ 4] CellsGroup.run
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 3891495 total (0.14%), 3889 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$60.0x0000000801036300.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 3780164 total (0.14%), 3781 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$AdaptedRunnableAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 3737026 total (0.13%), 3740 samples
  [ 0] ReferencePipeline$3.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 3633419 total (0.13%), 3619 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 3367615 total (0.12%), 3364 samples
  [ 0] LinkedBlockingQueue.dequeue
  [ 1] LinkedBlockingQueue.take
  [ 2] BlockingQueue.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 3308696 total (0.12%), 3307 samples
  [ 0] VirtualThread.getAndClearInterrupt
  [ 1] Thread.interrupted
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] Cell.lambda$notifyLiveness$0
  [ 8] Cell$$Lambda$60.0x0000000801036300.accept
  [ 9] ArrayList.forEach
  [10] Cell.notifyLiveness
  [11] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 3275990 total (0.12%), 3226 samples
  [ 0] update_cfs_group_[k]
  [ 1] dequeue_entity_[k]
  [ 2] dequeue_task_fair_[k]
  [ 3] __schedule_[k]
  [ 4] schedule_[k]
  [ 5] futex_wait_queue_[k]
  [ 6] futex_wait_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] __futex_abstimed_wait_common
  [12] Unsafe.park
  [13] LockSupport.park
  [14] ForkJoinPool.awaitWork
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 3249182 total (0.12%), 3253 samples
  [ 0] ReentrantLock.lockInterruptibly
  [ 1] LinkedBlockingQueue.put
  [ 2] BlockingQueue.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$53.0x0000000801035268.run
  [14] VirtualThread.run
  [15] VirtualThread$VThreadContinuation.lambda$new$0
  [16] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [17] Continuation.enter0
  [18] Continuation.enter
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run

--- 3201079 total (0.12%), 3202 samples
  [ 0] AbstractPipeline.wrapSink
  [ 1] AbstractPipeline.wrapAndCopyInto
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 3144539 total (0.11%), 3144 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.take
  [ 5] BlockingQueue.take
  [ 6] Channel.take
  [ 7] TickPerCell.waitTick
  [ 8] Cell.notifyLiveness
  [ 9] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 3059322 total (0.11%), 3069 samples
  [ 0] LinkedBlockingQueue.take
  [ 1] [unknown_Java]

--- 3053680 total (0.11%), 3054 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 2976830 total (0.11%), 2988 samples
  [ 0] Thread.interrupted
  [ 1] ReentrantLock$Sync.lockInterruptibly
  [ 2] ReentrantLock.lockInterruptibly
  [ 3] LinkedBlockingQueue.take
  [ 4] BlockingQueue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run

--- 2959499 total (0.11%), 2974 samples
  [ 0] AtomicInteger.getAndIncrement
  [ 1] LinkedBlockingQueue.put
  [ 2] BlockingQueue.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$53.0x0000000801035268.run
  [14] VirtualThread.run
  [15] VirtualThread$VThreadContinuation.lambda$new$0
  [16] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [17] Continuation.enter0
  [18] Continuation.enter
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run

--- 2951345 total (0.11%), 2954 samples
  [ 0] Sink$ChainedReference.begin
  [ 1] [unknown_Java]

--- 2711113 total (0.10%), 2714 samples
  [ 0] AtomicInteger.getAndIncrement
  [ 1] LinkedBlockingQueue.put
  [ 2] BlockingQueue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$60.0x0000000801036300.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 2646549 total (0.10%), 2659 samples
  [ 0] AbstractOwnableSynchronizer.getExclusiveOwnerThread
  [ 1] ReentrantLock$Sync.tryRelease
  [ 2] AbstractQueuedSynchronizer.release
  [ 3] ReentrantLock.unlock
  [ 4] LinkedBlockingQueue.signalNotFull
  [ 5] LinkedBlockingQueue.take
  [ 6] BlockingQueue.take
  [ 7] Channel.take
  [ 8] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 9] ReferencePipeline$3$1.accept
  [10] ArrayList$ArrayListSpliterator.forEachRemaining
  [11] AbstractPipeline.copyInto
  [12] AbstractPipeline.wrapAndCopyInto
  [13] ReduceOps$ReduceOp.evaluateSequential
  [14] AbstractPipeline.evaluate
  [15] IntPipeline.reduce
  [16] IntPipeline.sum
  [17] Cell.calculateNextState
  [18] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [19] Iterable.forEach
  [20] CellsGroup.run
  [21] Continuation.enterSpecial
  [22] Continuation.run
  [23] VirtualThread.runContinuation
  [24] VirtualThread$$Lambda$51.0x000000080103df08.run
  [25] ForkJoinTask$RunnableExecuteAction.exec
  [26] ForkJoinTask.doExec
  [27] ForkJoinPool$WorkQueue.topLevelExec
  [28] ForkJoinPool.scan
  [29] ForkJoinPool.runWorker
  [30] ForkJoinWorkerThread.run

--- 2530796 total (0.09%), 2492 samples
  [ 0] __schedule_[k]
  [ 1] schedule_[k]
  [ 2] futex_wait_queue_[k]
  [ 3] futex_wait_[k]
  [ 4] do_futex_[k]
  [ 5] __x64_sys_futex_[k]
  [ 6] do_syscall_64_[k]
  [ 7] entry_SYSCALL_64_after_hwframe_[k]
  [ 8] __futex_abstimed_wait_common
  [ 9] Unsafe.park
  [10] LockSupport.park
  [11] ForkJoinPool.awaitWork
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 2519092 total (0.09%), 2528 samples
  [ 0] VirtualThread.getAndClearInterrupt
  [ 1] Thread.interrupted
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.take
  [ 5] BlockingQueue.take
  [ 6] Channel.take
  [ 7] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 8] ReferencePipeline$3$1.accept
  [ 9] ArrayList$ArrayListSpliterator.forEachRemaining
  [10] AbstractPipeline.copyInto
  [11] AbstractPipeline.wrapAndCopyInto
  [12] ReduceOps$ReduceOp.evaluateSequential
  [13] AbstractPipeline.evaluate
  [14] IntPipeline.reduce
  [15] IntPipeline.sum
  [16] Cell.calculateNextState
  [17] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [18] Iterable.forEach
  [19] CellsGroup.run
  [20] Continuation.enterSpecial
  [21] Continuation.run
  [22] VirtualThread.runContinuation
  [23] VirtualThread$$Lambda$51.0x000000080103df08.run
  [24] ForkJoinTask$RunnableExecuteAction.exec
  [25] ForkJoinTask.doExec
  [26] ForkJoinPool$WorkQueue.topLevelExec
  [27] ForkJoinPool.scan
  [28] ForkJoinPool.runWorker
  [29] ForkJoinWorkerThread.run

--- 2494881 total (0.09%), 2501 samples
  [ 0] LinkedBlockingQueue.put
  [ 1] BlockingQueue.put
  [ 2] Channel.put
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 2429536 total (0.09%), 2419 samples
  [ 0] StreamOpFlag.fromCharacteristics
  [ 1] StreamSupport.stream
  [ 2] Collection.stream
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 2415221 total (0.09%), 2414 samples
  [ 0] LinkedBlockingQueue.put
  [ 1] BlockingQueue.put
  [ 2] Channel.put
  [ 3] Cell.lambda$notifyLiveness$0
  [ 4] Cell$$Lambda$60.0x0000000801036300.accept
  [ 5] ArrayList.forEach
  [ 6] Cell.notifyLiveness
  [ 7] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 2413245 total (0.09%), 2416 samples
  [ 0] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] Continuation.enterSpecial
  [ 4] Continuation.run
  [ 5] VirtualThread.runContinuation
  [ 6] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 7] ForkJoinTask$RunnableExecuteAction.exec
  [ 8] ForkJoinTask.doExec
  [ 9] ForkJoinPool$WorkQueue.topLevelExec
  [10] ForkJoinPool.scan
  [11] ForkJoinPool.runWorker
  [12] ForkJoinWorkerThread.run

--- 2412212 total (0.09%), 2400 samples
  [ 0] StreamOpFlag.fromCharacteristics
  [ 1] StreamSupport.stream
  [ 2] Collection.stream
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 2386229 total (0.09%), 2386 samples
  [ 0] ReferencePipeline$4.opWrapSink
  [ 1] [unknown_Java]

--- 2347750 total (0.08%), 2352 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 2302810 total (0.08%), 2302 samples
  [ 0] AbstractOwnableSynchronizer.setExclusiveOwnerThread
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LinkedBlockingQueue.signalNotEmpty
  [ 5] LinkedBlockingQueue.put
  [ 6] BlockingQueue.put
  [ 7] Channel.put
  [ 8] Cell.lambda$notifyLiveness$0
  [ 9] Cell$$Lambda$60.0x0000000801036300.accept
  [10] ArrayList.forEach
  [11] Cell.notifyLiveness
  [12] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 2300600 total (0.08%), 2305 samples
  [ 0] AbstractQueuedSynchronizer.signalNext
  [ 1] AbstractQueuedSynchronizer.release
  [ 2] ReentrantLock.unlock
  [ 3] LinkedBlockingQueue.put
  [ 4] BlockingQueue.put
  [ 5] Channel.put
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 2300218 total (0.08%), 2304 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 2296948 total (0.08%), 2262 samples
  [ 0] update_curr_[k]
  [ 1] dequeue_entity_[k]
  [ 2] dequeue_task_fair_[k]
  [ 3] __schedule_[k]
  [ 4] schedule_[k]
  [ 5] futex_wait_queue_[k]
  [ 6] futex_wait_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] __futex_abstimed_wait_common
  [12] Unsafe.park
  [13] LockSupport.park
  [14] ForkJoinPool.awaitWork
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 2272212 total (0.08%), 2265 samples
  [ 0] AbstractPipeline.<init>
  [ 1] IntPipeline.<init>
  [ 2] IntPipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$4.<init>
  [ 4] ReferencePipeline.mapToInt
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 2125505 total (0.08%), 2129 samples
  [ 0] AbstractOwnableSynchronizer.setExclusiveOwnerThread
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.take
  [ 5] BlockingQueue.take
  [ 6] Channel.take
  [ 7] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 8] ChannelsGrid.lambda$forEachChannel$1
  [ 9] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [10] Dimensions.forEachRowCol
  [11] ChannelsGrid.forEachChannel
  [12] GameOfLife.calculateFrame
  [13] GameOfLife.lambda$calculateFrameBlocking$4
  [14] GameOfLife$$Lambda$53.0x0000000801035268.run
  [15] VirtualThread.run
  [16] VirtualThread$VThreadContinuation.lambda$new$0
  [17] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [18] Continuation.enter0
  [19] Continuation.enter
  [20] Continuation.enterSpecial
  [21] Continuation.run
  [22] VirtualThread.runContinuation
  [23] VirtualThread$$Lambda$51.0x000000080103df08.run
  [24] ForkJoinTask$RunnableExecuteAction.exec
  [25] ForkJoinTask.doExec
  [26] ForkJoinPool$WorkQueue.topLevelExec
  [27] ForkJoinPool.scan
  [28] ForkJoinPool.runWorker
  [29] ForkJoinWorkerThread.run

--- 2097816 total (0.08%), 2100 samples
  [ 0] AbstractQueuedSynchronizer.getState
  [ 1] ReentrantLock$Sync.tryRelease
  [ 2] AbstractQueuedSynchronizer.release
  [ 3] ReentrantLock.unlock
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] Cell.lambda$notifyLiveness$0
  [ 8] Cell$$Lambda$60.0x0000000801036300.accept
  [ 9] ArrayList.forEach
  [10] Cell.notifyLiveness
  [11] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 2082017 total (0.08%), 2086 samples
  [ 0] ReentrantLock$Sync.isHeldExclusively
  [ 1] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 2] AbstractQueuedSynchronizer$ConditionObject.await
  [ 3] LinkedBlockingQueue.take
  [ 4] BlockingQueue.take
  [ 5] Channel.take
  [ 6] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 7] ChannelsGrid.lambda$forEachChannel$1
  [ 8] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 9] Dimensions.forEachRowCol
  [10] ChannelsGrid.forEachChannel
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$53.0x0000000801035268.run
  [14] VirtualThread.run
  [15] VirtualThread$VThreadContinuation.lambda$new$0
  [16] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [17] Continuation.enter0
  [18] Continuation.enter
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run

--- 1965666 total (0.07%), 1967 samples
  [ 0] AbstractOwnableSynchronizer.setExclusiveOwnerThread
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] Cell.lambda$notifyLiveness$0
  [ 8] Cell$$Lambda$60.0x0000000801036300.accept
  [ 9] ArrayList.forEach
  [10] Cell.notifyLiveness
  [11] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 1942152 total (0.07%), 1946 samples
  [ 0] AbstractQueuedSynchronizer.signalNext
  [ 1] AbstractQueuedSynchronizer.release
  [ 2] ReentrantLock.unlock
  [ 3] LinkedBlockingQueue.take
  [ 4] BlockingQueue.take
  [ 5] Channel.take
  [ 6] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 7] ChannelsGrid.lambda$forEachChannel$1
  [ 8] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 9] Dimensions.forEachRowCol
  [10] ChannelsGrid.forEachChannel
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$53.0x0000000801035268.run
  [14] VirtualThread.run
  [15] VirtualThread$VThreadContinuation.lambda$new$0
  [16] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [17] Continuation.enter0
  [18] Continuation.enter
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run

--- 1939812 total (0.07%), 1943 samples
  [ 0] Cell.calculateNextState
  [ 1] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 1937308 total (0.07%), 1938 samples
  [ 0] ReferencePipeline$3.opWrapSink
  [ 1] [unknown_Java]

--- 1930859 total (0.07%), 1931 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 1] LinkedBlockingQueue.signalNotEmpty
  [ 2] LinkedBlockingQueue.put
  [ 3] BlockingQueue.put
  [ 4] Channel.put
  [ 5] Cell.lambda$notifyLiveness$0
  [ 6] Cell$$Lambda$60.0x0000000801036300.accept
  [ 7] ArrayList.forEach
  [ 8] Cell.notifyLiveness
  [ 9] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 1902426 total (0.07%), 1911 samples
  [ 0] ReentrantLock$Sync.lock
  [ 1] ReentrantLock.lock
  [ 2] LinkedBlockingQueue.signalNotEmpty
  [ 3] LinkedBlockingQueue.put
  [ 4] BlockingQueue.put
  [ 5] Channel.put
  [ 6] TickPerCell.lambda$tick$0
  [ 7] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 8] ChannelsGrid.lambda$forEachChannel$0
  [ 9] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [10] Dimensions.forEachRowCol
  [11] ChannelsGrid.forEachChannel
  [12] TickPerCell.tick
  [13] GameOfLife.calculateFrame
  [14] GameOfLife.lambda$calculateFrameBlocking$4
  [15] GameOfLife$$Lambda$53.0x0000000801035268.run
  [16] VirtualThread.run
  [17] VirtualThread$VThreadContinuation.lambda$new$0
  [18] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [19] Continuation.enter0
  [20] Continuation.enter
  [21] Continuation.enterSpecial
  [22] Continuation.run
  [23] VirtualThread.runContinuation
  [24] VirtualThread$$Lambda$51.0x000000080103df08.run
  [25] ForkJoinTask$RunnableExecuteAction.exec
  [26] ForkJoinTask.doExec
  [27] ForkJoinPool$WorkQueue.topLevelExec
  [28] ForkJoinPool.scan
  [29] ForkJoinPool.runWorker
  [30] ForkJoinWorkerThread.run

--- 1900509 total (0.07%), 1903 samples
  [ 0] AbstractQueuedSynchronizer.setState
  [ 1] ReentrantLock$Sync.tryRelease
  [ 2] AbstractQueuedSynchronizer.release
  [ 3] ReentrantLock.unlock
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] Cell.lambda$notifyLiveness$0
  [ 8] Cell$$Lambda$60.0x0000000801036300.accept
  [ 9] ArrayList.forEach
  [10] Cell.notifyLiveness
  [11] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 1891162 total (0.07%), 1900 samples
  [ 0] ReentrantLock$Sync.lockInterruptibly
  [ 1] ReentrantLock.lockInterruptibly
  [ 2] LinkedBlockingQueue.put
  [ 3] BlockingQueue.put
  [ 4] Channel.put
  [ 5] TickPerCell.lambda$tick$0
  [ 6] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 7] ChannelsGrid.lambda$forEachChannel$0
  [ 8] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [ 9] Dimensions.forEachRowCol
  [10] ChannelsGrid.forEachChannel
  [11] TickPerCell.tick
  [12] GameOfLife.calculateFrame
  [13] GameOfLife.lambda$calculateFrameBlocking$4
  [14] GameOfLife$$Lambda$53.0x0000000801035268.run
  [15] VirtualThread.run
  [16] VirtualThread$VThreadContinuation.lambda$new$0
  [17] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [18] Continuation.enter0
  [19] Continuation.enter
  [20] Continuation.enterSpecial
  [21] Continuation.run
  [22] VirtualThread.runContinuation
  [23] VirtualThread$$Lambda$51.0x000000080103df08.run
  [24] ForkJoinTask$RunnableExecuteAction.exec
  [25] ForkJoinTask.doExec
  [26] ForkJoinPool$WorkQueue.topLevelExec
  [27] ForkJoinPool.scan
  [28] ForkJoinPool.runWorker
  [29] ForkJoinWorkerThread.run

--- 1888334 total (0.07%), 1884 samples
  [ 0] AbstractPipeline.<init>
  [ 1] IntPipeline.<init>
  [ 2] IntPipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$4.<init>
  [ 4] ReferencePipeline.mapToInt
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 1874474 total (0.07%), 1874 samples
  [ 0] AbstractQueuedSynchronizer.setState
  [ 1] ReentrantLock$Sync.tryRelease
  [ 2] AbstractQueuedSynchronizer.release
  [ 3] ReentrantLock.unlock
  [ 4] LinkedBlockingQueue.signalNotEmpty
  [ 5] LinkedBlockingQueue.put
  [ 6] BlockingQueue.put
  [ 7] Channel.put
  [ 8] Cell.lambda$notifyLiveness$0
  [ 9] Cell$$Lambda$60.0x0000000801036300.accept
  [10] ArrayList.forEach
  [11] Cell.notifyLiveness
  [12] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 1855687 total (0.07%), 1856 samples
  [ 0] AbstractQueuedSynchronizer.getState
  [ 1] ReentrantLock$Sync.tryRelease
  [ 2] AbstractQueuedSynchronizer.release
  [ 3] ReentrantLock.unlock
  [ 4] LinkedBlockingQueue.signalNotEmpty
  [ 5] LinkedBlockingQueue.put
  [ 6] BlockingQueue.put
  [ 7] Channel.put
  [ 8] Cell.lambda$notifyLiveness$0
  [ 9] Cell$$Lambda$60.0x0000000801036300.accept
  [10] ArrayList.forEach
  [11] Cell.notifyLiveness
  [12] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 1841437 total (0.07%), 1844 samples
  [ 0] LinkedBlockingQueue.enqueue
  [ 1] LinkedBlockingQueue.put
  [ 2] BlockingQueue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$60.0x0000000801036300.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 1828519 total (0.07%), 1828 samples
  [ 0] Parker::park(bool, long)
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] ForkJoinPool.awaitWork
  [ 5] ForkJoinPool.runWorker
  [ 6] ForkJoinWorkerThread.run

--- 1791314 total (0.06%), 1794 samples
  [ 0] LinkedBlockingQueue.put
  [ 1] BlockingQueue.put
  [ 2] Channel.put
  [ 3] Cell.lambda$notifyLiveness$0
  [ 4] Cell$$Lambda$60.0x0000000801036300.accept
  [ 5] ArrayList.forEach
  [ 6] Cell.notifyLiveness
  [ 7] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 1787033 total (0.06%), 1792 samples
  [ 0] AbstractQueuedSynchronizer.signalNext
  [ 1] AbstractQueuedSynchronizer.release
  [ 2] ReentrantLock.unlock
  [ 3] LinkedBlockingQueue.signalNotEmpty
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] TickPerCell.lambda$tick$0
  [ 8] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 9] ChannelsGrid.lambda$forEachChannel$0
  [10] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [11] Dimensions.forEachRowCol
  [12] ChannelsGrid.forEachChannel
  [13] TickPerCell.tick
  [14] GameOfLife.calculateFrame
  [15] GameOfLife.lambda$calculateFrameBlocking$4
  [16] GameOfLife$$Lambda$53.0x0000000801035268.run
  [17] VirtualThread.run
  [18] VirtualThread$VThreadContinuation.lambda$new$0
  [19] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [20] Continuation.enter0
  [21] Continuation.enter
  [22] Continuation.enterSpecial
  [23] Continuation.run
  [24] VirtualThread.runContinuation
  [25] VirtualThread$$Lambda$51.0x000000080103df08.run
  [26] ForkJoinTask$RunnableExecuteAction.exec
  [27] ForkJoinTask.doExec
  [28] ForkJoinPool$WorkQueue.topLevelExec
  [29] ForkJoinPool.scan
  [30] ForkJoinPool.runWorker
  [31] ForkJoinWorkerThread.run

--- 1778665 total (0.06%), 1784 samples
  [ 0] LinkedBlockingQueue.take
  [ 1] BlockingQueue.take
  [ 2] Channel.take
  [ 3] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 4] ReferencePipeline$3$1.accept
  [ 5] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 6] AbstractPipeline.copyInto
  [ 7] AbstractPipeline.wrapAndCopyInto
  [ 8] ReduceOps$ReduceOp.evaluateSequential
  [ 9] AbstractPipeline.evaluate
  [10] IntPipeline.reduce
  [11] IntPipeline.sum
  [12] Cell.calculateNextState
  [13] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [14] Iterable.forEach
  [15] CellsGroup.run
  [16] Continuation.enterSpecial
  [17] Continuation.run
  [18] VirtualThread.runContinuation
  [19] VirtualThread$$Lambda$51.0x000000080103df08.run
  [20] ForkJoinTask$RunnableExecuteAction.exec
  [21] ForkJoinTask.doExec
  [22] ForkJoinPool$WorkQueue.topLevelExec
  [23] ForkJoinPool.scan
  [24] ForkJoinPool.runWorker
  [25] ForkJoinWorkerThread.run

--- 1772639 total (0.06%), 1776 samples
  [ 0] ReferencePipeline.map
  [ 1] Cell.calculateNextState
  [ 2] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 3] Iterable.forEach
  [ 4] CellsGroup.run
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 1759427 total (0.06%), 1763 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.tryAcquire
  [ 2] AbstractQueuedSynchronizer.acquire
  [ 3] AbstractQueuedSynchronizer$ConditionObject.await
  [ 4] LinkedBlockingQueue.take
  [ 5] BlockingQueue.take
  [ 6] Channel.take
  [ 7] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 8] ChannelsGrid.lambda$forEachChannel$1
  [ 9] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [10] Dimensions.forEachRowCol
  [11] ChannelsGrid.forEachChannel
  [12] GameOfLife.calculateFrame
  [13] GameOfLife.lambda$calculateFrameBlocking$4
  [14] GameOfLife$$Lambda$53.0x0000000801035268.run
  [15] VirtualThread.run
  [16] VirtualThread$VThreadContinuation.lambda$new$0
  [17] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [18] Continuation.enter0
  [19] Continuation.enter
  [20] Continuation.enterSpecial
  [21] Continuation.run
  [22] VirtualThread.runContinuation
  [23] VirtualThread$$Lambda$51.0x000000080103df08.run
  [24] ForkJoinTask$RunnableExecuteAction.exec
  [25] ForkJoinTask.doExec
  [26] ForkJoinPool$WorkQueue.topLevelExec
  [27] ForkJoinPool.scan
  [28] ForkJoinPool.runWorker
  [29] ForkJoinWorkerThread.run

--- 1733979 total (0.06%), 1731 samples
  [ 0] __memset_avx2_unaligned_erms
  [ 1] G1RemSetScanState::G1ClearCardTableTask::do_work(unsigned int)
  [ 2] G1BatchedTask::work(unsigned int)
  [ 3] WorkerThread::run()
  [ 4] Thread::call_run()
  [ 5] thread_native_entry(Thread*)
  [ 6] start_thread

--- 1699450 total (0.06%), 1701 samples
  [ 0] LinkedBlockingQueue.enqueue
  [ 1] LinkedBlockingQueue.put
  [ 2] BlockingQueue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$60.0x0000000801036300.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 1668175 total (0.06%), 1667 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 1653660 total (0.06%), 1655 samples
  [ 0] LinkedBlockingQueue.put
  [ 1] BlockingQueue.put
  [ 2] Channel.put
  [ 3] TickPerCell.lambda$tick$0
  [ 4] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 5] ChannelsGrid.lambda$forEachChannel$0
  [ 6] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] TickPerCell.tick
  [10] GameOfLife.calculateFrame
  [11] GameOfLife.lambda$calculateFrameBlocking$4
  [12] GameOfLife$$Lambda$53.0x0000000801035268.run
  [13] VirtualThread.run
  [14] VirtualThread$VThreadContinuation.lambda$new$0
  [15] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [16] Continuation.enter0
  [17] Continuation.enter
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run

--- 1648401 total (0.06%), 1607 samples
  [ 0] syscall_exit_to_user_mode_[k]
  [ 1] do_syscall_64_[k]
  [ 2] entry_SYSCALL_64_after_hwframe_[k]
  [ 3] __futex_abstimed_wait_common
  [ 4] Unsafe.park
  [ 5] LockSupport.park
  [ 6] ForkJoinPool.awaitWork
  [ 7] ForkJoinPool.runWorker
  [ 8] ForkJoinWorkerThread.run

--- 1639244 total (0.06%), 1643 samples
  [ 0] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] Continuation.enterSpecial
  [ 4] Continuation.run
  [ 5] VirtualThread.runContinuation
  [ 6] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 7] ForkJoinTask$RunnableExecuteAction.exec
  [ 8] ForkJoinTask.doExec
  [ 9] ForkJoinPool$WorkQueue.topLevelExec
  [10] ForkJoinPool.scan
  [11] ForkJoinPool.runWorker
  [12] ForkJoinWorkerThread.run

--- 1624721 total (0.06%), 1618 samples
  [ 0] ArrayList.spliterator
  [ 1] Collection.stream
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 1613159 total (0.06%), 1615 samples
  [ 0] AbstractPipeline.wrapSink
  [ 1] AbstractPipeline.wrapAndCopyInto
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 1597751 total (0.06%), 1572 samples
  [ 0] __update_load_avg_cfs_rq_[k]
  [ 1] update_load_avg_[k]
  [ 2] dequeue_entity_[k]
  [ 3] dequeue_task_fair_[k]
  [ 4] __schedule_[k]
  [ 5] schedule_[k]
  [ 6] futex_wait_queue_[k]
  [ 7] futex_wait_[k]
  [ 8] do_futex_[k]
  [ 9] __x64_sys_futex_[k]
  [10] do_syscall_64_[k]
  [11] entry_SYSCALL_64_after_hwframe_[k]
  [12] __futex_abstimed_wait_common
  [13] Unsafe.park
  [14] LockSupport.park
  [15] ForkJoinPool.awaitWork
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 1596189 total (0.06%), 1596 samples
  [ 0] Channel.put
  [ 1] Cell.lambda$notifyLiveness$0
  [ 2] Cell$$Lambda$60.0x0000000801036300.accept
  [ 3] ArrayList.forEach
  [ 4] Cell.notifyLiveness
  [ 5] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] Continuation.enterSpecial
  [ 9] Continuation.run
  [10] VirtualThread.runContinuation
  [11] VirtualThread$$Lambda$51.0x000000080103df08.run
  [12] ForkJoinTask$RunnableExecuteAction.exec
  [13] ForkJoinTask.doExec
  [14] ForkJoinPool$WorkQueue.topLevelExec
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 1590884 total (0.06%), 1568 samples
  [ 0] reweight_entity_[k]
  [ 1] dequeue_entity_[k]
  [ 2] dequeue_task_fair_[k]
  [ 3] __schedule_[k]
  [ 4] schedule_[k]
  [ 5] futex_wait_queue_[k]
  [ 6] futex_wait_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] __futex_abstimed_wait_common
  [12] Unsafe.park
  [13] LockSupport.park
  [14] ForkJoinPool.awaitWork
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 1574864 total (0.06%), 1582 samples
  [ 0] AbstractQueuedSynchronizer.setState
  [ 1] ReentrantLock$Sync.tryRelease
  [ 2] AbstractQueuedSynchronizer.release
  [ 3] ReentrantLock.unlock
  [ 4] LinkedBlockingQueue.take
  [ 5] BlockingQueue.take
  [ 6] Channel.take
  [ 7] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 8] ReferencePipeline$3$1.accept
  [ 9] ArrayList$ArrayListSpliterator.forEachRemaining
  [10] AbstractPipeline.copyInto
  [11] AbstractPipeline.wrapAndCopyInto
  [12] ReduceOps$ReduceOp.evaluateSequential
  [13] AbstractPipeline.evaluate
  [14] IntPipeline.reduce
  [15] IntPipeline.sum
  [16] Cell.calculateNextState
  [17] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [18] Iterable.forEach
  [19] CellsGroup.run
  [20] Continuation.enterSpecial
  [21] Continuation.run
  [22] VirtualThread.runContinuation
  [23] VirtualThread$$Lambda$51.0x000000080103df08.run
  [24] ForkJoinTask$RunnableExecuteAction.exec
  [25] ForkJoinTask.doExec
  [26] ForkJoinPool$WorkQueue.topLevelExec
  [27] ForkJoinPool.scan
  [28] ForkJoinPool.runWorker
  [29] ForkJoinWorkerThread.run

--- 1571872 total (0.06%), 1579 samples
  [ 0] ReentrantLock$Sync.tryRelease
  [ 1] AbstractQueuedSynchronizer.release
  [ 2] ReentrantLock.unlock
  [ 3] LinkedBlockingQueue.signalNotEmpty
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] TickPerCell.lambda$tick$0
  [ 8] TickPerCell$$Lambda$58.0x0000000801035ec8.accept
  [ 9] ChannelsGrid.lambda$forEachChannel$0
  [10] ChannelsGrid$$Lambda$59.0x00000008010360e0.accept
  [11] Dimensions.forEachRowCol
  [12] ChannelsGrid.forEachChannel
  [13] TickPerCell.tick
  [14] GameOfLife.calculateFrame
  [15] GameOfLife.lambda$calculateFrameBlocking$4
  [16] GameOfLife$$Lambda$53.0x0000000801035268.run
  [17] VirtualThread.run
  [18] VirtualThread$VThreadContinuation.lambda$new$0
  [19] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [20] Continuation.enter0
  [21] Continuation.enter
  [22] Continuation.enterSpecial
  [23] Continuation.run
  [24] VirtualThread.runContinuation
  [25] VirtualThread$$Lambda$51.0x000000080103df08.run
  [26] ForkJoinTask$RunnableExecuteAction.exec
  [27] ForkJoinTask.doExec
  [28] ForkJoinPool$WorkQueue.topLevelExec
  [29] ForkJoinPool.scan
  [30] ForkJoinPool.runWorker
  [31] ForkJoinWorkerThread.run

--- 1563451 total (0.06%), 1568 samples
  [ 0] LinkedBlockingQueue.take
  [ 1] BlockingQueue.take
  [ 2] Channel.take
  [ 3] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 4] ReferencePipeline$3$1.accept
  [ 5] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 6] AbstractPipeline.copyInto
  [ 7] AbstractPipeline.wrapAndCopyInto
  [ 8] ReduceOps$ReduceOp.evaluateSequential
  [ 9] AbstractPipeline.evaluate
  [10] IntPipeline.reduce
  [11] IntPipeline.sum
  [12] Cell.calculateNextState
  [13] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [14] Iterable.forEach
  [15] CellsGroup.run
  [16] Continuation.enterSpecial
  [17] Continuation.run
  [18] VirtualThread.runContinuation
  [19] VirtualThread$$Lambda$51.0x000000080103df08.run
  [20] ForkJoinTask$RunnableExecuteAction.exec
  [21] ForkJoinTask.doExec
  [22] ForkJoinPool$WorkQueue.topLevelExec
  [23] ForkJoinPool.scan
  [24] ForkJoinPool.runWorker
  [25] ForkJoinWorkerThread.run

--- 1531094 total (0.06%), 1529 samples
  [ 0] ReferencePipeline.<init>
  [ 1] ReferencePipeline$StatelessOp.<init>
  [ 2] ReferencePipeline$3.<init>
  [ 3] ReferencePipeline.map
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] Continuation.enterSpecial
  [ 9] Continuation.run
  [10] VirtualThread.runContinuation
  [11] VirtualThread$$Lambda$51.0x000000080103df08.run
  [12] ForkJoinTask$RunnableExecuteAction.exec
  [13] ForkJoinTask.doExec
  [14] ForkJoinPool$WorkQueue.topLevelExec
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 1529845 total (0.06%), 1529 samples
  [ 0] AbstractOwnableSynchronizer.getExclusiveOwnerThread
  [ 1] ReentrantLock$Sync.tryRelease
  [ 2] AbstractQueuedSynchronizer.release
  [ 3] ReentrantLock.unlock
  [ 4] LinkedBlockingQueue.signalNotFull
  [ 5] LinkedBlockingQueue.take
  [ 6] BlockingQueue.take
  [ 7] Channel.take
  [ 8] TickPerCell.waitTick
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 1523454 total (0.05%), 1525 samples
  [ 0] ForkJoinPool$WorkQueue.casSlotToNull
  [ 1] ForkJoinPool.scan
  [ 2] ForkJoinPool.runWorker
  [ 3] ForkJoinWorkerThread.run

--- 1520753 total (0.05%), 1528 samples
  [ 0] ReentrantLock$Sync.lockInterruptibly
  [ 1] ReentrantLock.lockInterruptibly
  [ 2] LinkedBlockingQueue.take
  [ 3] BlockingQueue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run

--- 1520630 total (0.05%), 1520 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] [unknown_Java]

--- 1515973 total (0.05%), 1495 samples
  [ 0] dequeue_task_fair_[k]
  [ 1] __schedule_[k]
  [ 2] schedule_[k]
  [ 3] futex_wait_queue_[k]
  [ 4] futex_wait_[k]
  [ 5] do_futex_[k]
  [ 6] __x64_sys_futex_[k]
  [ 7] do_syscall_64_[k]
  [ 8] entry_SYSCALL_64_after_hwframe_[k]
  [ 9] __futex_abstimed_wait_common
  [10] Unsafe.park
  [11] LockSupport.park
  [12] ForkJoinPool.awaitWork
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 1515167 total (0.05%), 1510 samples
  [ 0] G1CardSet::occupied() const
  [ 1] G1CollectionSet::iterate(HeapRegionClosure*) const
  [ 2] G1RemSetSamplingTask::execute()
  [ 3] G1ServiceThread::run_task(G1ServiceTask*)
  [ 4] G1ServiceThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread

--- 1452998 total (0.05%), 1455 samples
  [ 0] Sink$ChainedReference.begin
  [ 1] Sink$ChainedReference.begin
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 1432073 total (0.05%), 1410 samples
  [ 0] update_load_avg_[k]
  [ 1] dequeue_entity_[k]
  [ 2] dequeue_task_fair_[k]
  [ 3] __schedule_[k]
  [ 4] schedule_[k]
  [ 5] futex_wait_queue_[k]
  [ 6] futex_wait_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] __futex_abstimed_wait_common
  [12] Unsafe.park
  [13] LockSupport.park
  [14] ForkJoinPool.awaitWork
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 1418338 total (0.05%), 1422 samples
  [ 0] AbstractQueuedSynchronizer.acquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LinkedBlockingQueue.take
  [ 3] BlockingQueue.take
  [ 4] Channel.take
  [ 5] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 6] ChannelsGrid.lambda$forEachChannel$1
  [ 7] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] GameOfLife.calculateFrame
  [11] GameOfLife.lambda$calculateFrameBlocking$4
  [12] GameOfLife$$Lambda$53.0x0000000801035268.run
  [13] VirtualThread.run
  [14] VirtualThread$VThreadContinuation.lambda$new$0
  [15] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [16] Continuation.enter0
  [17] Continuation.enter
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run

--- 1405360 total (0.05%), 1407 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.await
  [ 1] LinkedBlockingQueue.take
  [ 2] BlockingQueue.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$53.0x0000000801035268.run
  [12] VirtualThread.run
  [13] VirtualThread$VThreadContinuation.lambda$new$0
  [14] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [15] Continuation.enter0
  [16] Continuation.enter
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run

--- 1396497 total (0.05%), 1400 samples
  [ 0] AbstractOwnableSynchronizer.getExclusiveOwnerThread
  [ 1] ReentrantLock$Sync.tryRelease
  [ 2] AbstractQueuedSynchronizer.release
  [ 3] ReentrantLock.unlock
  [ 4] LinkedBlockingQueue.signalNotEmpty
  [ 5] LinkedBlockingQueue.put
  [ 6] BlockingQueue.put
  [ 7] Channel.put
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 1394887 total (0.05%), 1397 samples
  [ 0] ReferencePipeline$3.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 1380083 total (0.05%), 1383 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LinkedBlockingQueue.take
  [ 3] BlockingQueue.take
  [ 4] Channel.take
  [ 5] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 6] ChannelsGrid.lambda$forEachChannel$1
  [ 7] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] GameOfLife.calculateFrame
  [11] GameOfLife.lambda$calculateFrameBlocking$4
  [12] GameOfLife$$Lambda$53.0x0000000801035268.run
  [13] VirtualThread.run
  [14] VirtualThread$VThreadContinuation.lambda$new$0
  [15] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [16] Continuation.enter0
  [17] Continuation.enter
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run

--- 1375605 total (0.05%), 1357 samples
  [ 0] cpuacct_charge_[k]
  [ 1] update_curr_[k]
  [ 2] dequeue_entity_[k]
  [ 3] dequeue_task_fair_[k]
  [ 4] __schedule_[k]
  [ 5] schedule_[k]
  [ 6] futex_wait_queue_[k]
  [ 7] futex_wait_[k]
  [ 8] do_futex_[k]
  [ 9] __x64_sys_futex_[k]
  [10] do_syscall_64_[k]
  [11] entry_SYSCALL_64_after_hwframe_[k]
  [12] __futex_abstimed_wait_common
  [13] Unsafe.park
  [14] LockSupport.park
  [15] ForkJoinPool.awaitWork
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 1348334 total (0.05%), 1353 samples
  [ 0] AtomicInteger.getAndIncrement
  [ 1] LinkedBlockingQueue.put
  [ 2] BlockingQueue.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] Continuation.enterSpecial
  [ 9] Continuation.run
  [10] VirtualThread.runContinuation
  [11] VirtualThread$$Lambda$51.0x000000080103df08.run
  [12] ForkJoinTask$RunnableExecuteAction.exec
  [13] ForkJoinTask.doExec
  [14] ForkJoinPool$WorkQueue.topLevelExec
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 1337806 total (0.05%), 1339 samples
  [ 0] Object.<init>
  [ 1] PipelineHelper.<init>
  [ 2] AbstractPipeline.<init>
  [ 3] ReferencePipeline.<init>
  [ 4] ReferencePipeline$Head.<init>
  [ 5] StreamSupport.stream
  [ 6] Collection.stream
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 1336766 total (0.05%), 1343 samples
  [ 0] AbstractQueuedSynchronizer.enqueue
  [ 1] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 2] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 3] LinkedBlockingQueue.signalNotEmpty
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 1323600 total (0.05%), 1327 samples
  [ 0] ReentrantLock.lockInterruptibly
  [ 1] LinkedBlockingQueue.take
  [ 2] BlockingQueue.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$53.0x0000000801035268.run
  [12] VirtualThread.run
  [13] VirtualThread$VThreadContinuation.lambda$new$0
  [14] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [15] Continuation.enter0
  [16] Continuation.enter
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run

--- 1320560 total (0.05%), 1324 samples
  [ 0] LinkedBlockingQueue.put
  [ 1] [unknown_Java]

--- 1316410 total (0.05%), 1315 samples
  [ 0] Unsafe_Park
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] ForkJoinPool.awaitWork
  [ 4] ForkJoinPool.runWorker
  [ 5] ForkJoinWorkerThread.run

--- 1297430 total (0.05%), 1300 samples
  [ 0] ForkJoinPool.scan
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run

--- 1285672 total (0.05%), 1288 samples
  [ 0] ArrayList$SubList$1.next
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] Continuation.enterSpecial
  [ 4] Continuation.run
  [ 5] VirtualThread.runContinuation
  [ 6] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 7] ForkJoinTask$RunnableExecuteAction.exec
  [ 8] ForkJoinTask.doExec
  [ 9] ForkJoinPool$WorkQueue.topLevelExec
  [10] ForkJoinPool.scan
  [11] ForkJoinPool.runWorker
  [12] ForkJoinWorkerThread.run

--- 1257018 total (0.05%), 1237 samples
  [ 0] dequeue_entity_[k]
  [ 1] dequeue_task_fair_[k]
  [ 2] __schedule_[k]
  [ 3] schedule_[k]
  [ 4] futex_wait_queue_[k]
  [ 5] futex_wait_[k]
  [ 6] do_futex_[k]
  [ 7] __x64_sys_futex_[k]
  [ 8] do_syscall_64_[k]
  [ 9] entry_SYSCALL_64_after_hwframe_[k]
  [10] __futex_abstimed_wait_common
  [11] Unsafe.park
  [12] LockSupport.park
  [13] ForkJoinPool.awaitWork
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 1227052 total (0.04%), 1231 samples
  [ 0] AbstractQueuedSynchronizer.getState
  [ 1] ReentrantLock$Sync.tryRelease
  [ 2] AbstractQueuedSynchronizer.release
  [ 3] ReentrantLock.unlock
  [ 4] LinkedBlockingQueue.put
  [ 5] BlockingQueue.put
  [ 6] Channel.put
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 1222684 total (0.04%), 1221 samples
  [ 0] __memmove_sse2_unaligned_erms
  [ 1] long* thaw<Config<(oop_kind)0, G1BarrierSet> >(JavaThread*, int)
  [ 2] Cont thaw
  [ 3] [not_walkable_Java]

--- 1215955 total (0.04%), 1215 samples
  [ 0] AbstractPipeline.<init>
  [ 1] IntPipeline.<init>
  [ 2] IntPipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$4.<init>
  [ 4] ReferencePipeline.mapToInt
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 1178746 total (0.04%), 1185 samples
  [ 0] Unsafe.getAndBitwiseAndInt
  [ 1] AbstractQueuedSynchronizer$Node.getAndUnsetStatus
  [ 2] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 3] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 4] LinkedBlockingQueue.signalNotEmpty
  [ 5] LinkedBlockingQueue.put
  [ 6] BlockingQueue.put
  [ 7] Channel.put
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 1172419 total (0.04%), 1177 samples
  [ 0] ___pthread_cond_wait
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] ForkJoinPool.awaitWork
  [ 5] ForkJoinPool.runWorker
  [ 6] ForkJoinWorkerThread.run

--- 1166466 total (0.04%), 1171 samples
  [ 0] VirtualThread.getAndClearInterrupt
  [ 1] Thread.interrupted
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.take
  [ 5] BlockingQueue.take
  [ 6] Channel.take
  [ 7] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 8] ReferencePipeline$3$1.accept
  [ 9] ArrayList$ArrayListSpliterator.forEachRemaining
  [10] AbstractPipeline.copyInto
  [11] AbstractPipeline.wrapAndCopyInto
  [12] ReduceOps$ReduceOp.evaluateSequential
  [13] AbstractPipeline.evaluate
  [14] IntPipeline.reduce
  [15] IntPipeline.sum
  [16] Cell.calculateNextState
  [17] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [18] Iterable.forEach
  [19] CellsGroup.run
  [20] Continuation.enterSpecial
  [21] Continuation.run
  [22] VirtualThread.runContinuation
  [23] VirtualThread$$Lambda$51.0x000000080103df08.run
  [24] ForkJoinTask$RunnableExecuteAction.exec
  [25] ForkJoinTask.doExec
  [26] ForkJoinPool$WorkQueue.topLevelExec
  [27] ForkJoinPool.scan
  [28] ForkJoinPool.runWorker
  [29] ForkJoinWorkerThread.run

--- 1161243 total (0.04%), 1167 samples
  [ 0] AtomicInteger.getAndDecrement
  [ 1] LinkedBlockingQueue.take
  [ 2] BlockingQueue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run

--- 1154043 total (0.04%), 1157 samples
  [ 0] ArrayList.forEach
  [ 1] Cell.notifyLiveness
  [ 2] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 3] Iterable.forEach
  [ 4] CellsGroup.run
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 1134570 total (0.04%), 1117 samples
  [ 0] __update_load_avg_se_[k]
  [ 1] update_load_avg_[k]
  [ 2] dequeue_entity_[k]
  [ 3] dequeue_task_fair_[k]
  [ 4] __schedule_[k]
  [ 5] schedule_[k]
  [ 6] futex_wait_queue_[k]
  [ 7] futex_wait_[k]
  [ 8] do_futex_[k]
  [ 9] __x64_sys_futex_[k]
  [10] do_syscall_64_[k]
  [11] entry_SYSCALL_64_after_hwframe_[k]
  [12] __futex_abstimed_wait_common
  [13] Unsafe.park
  [14] LockSupport.park
  [15] ForkJoinPool.awaitWork
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 1126474 total (0.04%), 1128 samples
  [ 0] ReferencePipeline$4.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 1123392 total (0.04%), 1104 samples
  [ 0] enqueue_entity_[k]
  [ 1] enqueue_task_fair_[k]
  [ 2] enqueue_task_[k]
  [ 3] ttwu_do_activate_[k]
  [ 4] try_to_wake_up_[k]
  [ 5] wake_up_q_[k]
  [ 6] futex_wake_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] ___pthread_cond_signal
  [12] Unsafe.unpark
  [13] LockSupport.unpark
  [14] ForkJoinPool.signalWork
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 1115395 total (0.04%), 1115 samples
  [ 0] ReentrantLock.lockInterruptibly
  [ 1] LinkedBlockingQueue.take
  [ 2] BlockingQueue.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 1100345 total (0.04%), 1099 samples
  [ 0] ArrayList.forEach
  [ 1] Cell.notifyLiveness
  [ 2] CellsGroup$$Lambda$56.0x0000000801035668.accept
  [ 3] Iterable.forEach
  [ 4] CellsGroup.run
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 1099027 total (0.04%), 1102 samples
  [ 0] ForkJoinPool.scan
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run

--- 1097866 total (0.04%), 1102 samples
  [ 0] System$2.setExtentLocalCache
  [ 1] Continuation.run
  [ 2] VirtualThread.runContinuation
  [ 3] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 4] ForkJoinTask$RunnableExecuteAction.exec
  [ 5] ForkJoinTask.doExec
  [ 6] ForkJoinPool$WorkQueue.topLevelExec
  [ 7] ForkJoinPool.scan
  [ 8] ForkJoinPool.runWorker
  [ 9] ForkJoinWorkerThread.run

--- 1073365 total (0.04%), 1075 samples
  [ 0] ReentrantLock$Sync.lock
  [ 1] ReentrantLock.lock
  [ 2] LinkedBlockingQueue.signalNotEmpty
  [ 3] LinkedBlockingQueue.put
  [ 4] BlockingQueue.put
  [ 5] Channel.put
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 1070699 total (0.04%), 1074 samples
  [ 0] LinkedBlockingQueue.take
  [ 1] BlockingQueue.take
  [ 2] Channel.take
  [ 3] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 4] ChannelsGrid.lambda$forEachChannel$1
  [ 5] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 6] Dimensions.forEachRowCol
  [ 7] ChannelsGrid.forEachChannel
  [ 8] GameOfLife.calculateFrame
  [ 9] GameOfLife.lambda$calculateFrameBlocking$4
  [10] GameOfLife$$Lambda$53.0x0000000801035268.run
  [11] VirtualThread.run
  [12] VirtualThread$VThreadContinuation.lambda$new$0
  [13] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [14] Continuation.enter0
  [15] Continuation.enter
  [16] Continuation.enterSpecial
  [17] Continuation.run
  [18] VirtualThread.runContinuation
  [19] VirtualThread$$Lambda$51.0x000000080103df08.run
  [20] ForkJoinTask$RunnableExecuteAction.exec
  [21] ForkJoinTask.doExec
  [22] ForkJoinPool$WorkQueue.topLevelExec
  [23] ForkJoinPool.scan
  [24] ForkJoinPool.runWorker
  [25] ForkJoinWorkerThread.run

--- 1067977 total (0.04%), 1058 samples
  [ 0] __tls_get_addr
  [ 1] vframeStream::vframeStream(JavaThread*, bool, bool, bool)
  [ 2] SharedRuntime::find_callee_method(JavaThread*)
  [ 3] SharedRuntime::reresolve_call_site(JavaThread*)
  [ 4] SharedRuntime::handle_wrong_method(JavaThread*)
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 1054941 total (0.04%), 1040 samples
  [ 0] psi_group_change_[k]
  [ 1] psi_task_change_[k]
  [ 2] enqueue_task_[k]
  [ 3] ttwu_do_activate_[k]
  [ 4] try_to_wake_up_[k]
  [ 5] wake_up_q_[k]
  [ 6] futex_wake_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] ___pthread_cond_signal
  [12] Unsafe.unpark
  [13] LockSupport.unpark
  [14] ForkJoinPool.signalWork
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 1036424 total (0.04%), 1040 samples
  [ 0] ReentrantLock$Sync.tryRelease
  [ 1] AbstractQueuedSynchronizer.release
  [ 2] ReentrantLock.unlock
  [ 3] LinkedBlockingQueue.put
  [ 4] BlockingQueue.put
  [ 5] Channel.put
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 1028510 total (0.04%), 1032 samples
  [ 0] ForkJoinPool.scan
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run

--- 1024520 total (0.04%), 1027 samples
  [ 0] ReentrantLock$Sync.lock
  [ 1] ReentrantLock.lock
  [ 2] LinkedBlockingQueue.signalNotFull
  [ 3] LinkedBlockingQueue.take
  [ 4] BlockingQueue.take
  [ 5] Channel.take
  [ 6] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 7] ChannelsGrid.lambda$forEachChannel$1
  [ 8] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [ 9] Dimensions.forEachRowCol
  [10] ChannelsGrid.forEachChannel
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$53.0x0000000801035268.run
  [14] VirtualThread.run
  [15] VirtualThread$VThreadContinuation.lambda$new$0
  [16] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [17] Continuation.enter0
  [18] Continuation.enter
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run

--- 1009815 total (0.04%), 1011 samples
  [ 0] Unsafe.park
  [ 1] LockSupport.park
  [ 2] ForkJoinPool.awaitWork
  [ 3] ForkJoinPool.runWorker
  [ 4] ForkJoinWorkerThread.run

--- 1006446 total (0.04%), 988 samples
  [ 0] native_sched_clock_[k]
  [ 1] sched_clock_cpu_[k]
  [ 2] update_rq_clock_[k]
  [ 3] __schedule_[k]
  [ 4] schedule_[k]
  [ 5] futex_wait_queue_[k]
  [ 6] futex_wait_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] __futex_abstimed_wait_common
  [12] Unsafe.park
  [13] LockSupport.park
  [14] ForkJoinPool.awaitWork
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 1003166 total (0.04%), 1004 samples
  [ 0] ReentrantLock$Sync.tryRelease
  [ 1] AbstractQueuedSynchronizer.release
  [ 2] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 3] AbstractQueuedSynchronizer$ConditionObject.await
  [ 4] LinkedBlockingQueue.take
  [ 5] BlockingQueue.take
  [ 6] Channel.take
  [ 7] GameOfLife$$Lambda$63.0x0000000801036958.test
  [ 8] ChannelsGrid.lambda$forEachChannel$1
  [ 9] ChannelsGrid$$Lambda$67.0x0000000801037420.accept
  [10] Dimensions.forEachRowCol
  [11] ChannelsGrid.forEachChannel
  [12] GameOfLife.calculateFrame
  [13] GameOfLife.lambda$calculateFrameBlocking$4
  [14] GameOfLife$$Lambda$53.0x0000000801035268.run
  [15] VirtualThread.run
  [16] VirtualThread$VThreadContinuation.lambda$new$0
  [17] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [18] Continuation.enter0
  [19] Continuation.enter
  [20] Continuation.enterSpecial
  [21] Continuation.run
  [22] VirtualThread.runContinuation
  [23] VirtualThread$$Lambda$51.0x000000080103df08.run
  [24] ForkJoinTask$RunnableExecuteAction.exec
  [25] ForkJoinTask.doExec
  [26] ForkJoinPool$WorkQueue.topLevelExec
  [27] ForkJoinPool.scan
  [28] ForkJoinPool.runWorker
  [29] ForkJoinWorkerThread.run

--- 1002805 total (0.04%), 1007 samples
  [ 0] ReentrantLock$Sync.lock
  [ 1] ReentrantLock.lock
  [ 2] LinkedBlockingQueue.signalNotFull
  [ 3] LinkedBlockingQueue.take
  [ 4] BlockingQueue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run

--- 988280 total (0.04%), 991 samples
  [ 0] ArrayList$SubList$1.checkForComodification
  [ 1] ArrayList$SubList$1.next
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 983488 total (0.04%), 970 samples
  [ 0] __memset_avx2_unaligned_erms
  [ 1] MemAllocator::allocate_inside_tlab_slow(MemAllocator::Allocation&) const
  [ 2] MemAllocator::allocate() const
  [ 3] InstanceKlass::allocate_instance(JavaThread*)
  [ 4] OptoRuntime::new_instance_C(Klass*, JavaThread*)
  [ 5] ReduceOps$5ReducingSink.get
  [ 6] ReduceOps$5ReducingSink.get
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 977749 total (0.04%), 981 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$Head.<init>
  [ 3] StreamSupport.stream
  [ 4] Collection.stream
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 968389 total (0.03%), 970 samples
  [ 0] Iterable.forEach
  [ 1] CellsGroup.run
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run

--- 967101 total (0.03%), 972 samples
  [ 0] Thread.clearInterrupt
  [ 1] VirtualThread.getAndClearInterrupt
  [ 2] Thread.interrupted
  [ 3] ReentrantLock$Sync.lockInterruptibly
  [ 4] ReentrantLock.lockInterruptibly
  [ 5] LinkedBlockingQueue.take
  [ 6] BlockingQueue.take
  [ 7] Channel.take
  [ 8] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 9] ReferencePipeline$3$1.accept
  [10] ArrayList$ArrayListSpliterator.forEachRemaining
  [11] AbstractPipeline.copyInto
  [12] AbstractPipeline.wrapAndCopyInto
  [13] ReduceOps$ReduceOp.evaluateSequential
  [14] AbstractPipeline.evaluate
  [15] IntPipeline.reduce
  [16] IntPipeline.sum
  [17] Cell.calculateNextState
  [18] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [19] Iterable.forEach
  [20] CellsGroup.run
  [21] Continuation.enterSpecial
  [22] Continuation.run
  [23] VirtualThread.runContinuation
  [24] VirtualThread$$Lambda$51.0x000000080103df08.run
  [25] ForkJoinTask$RunnableExecuteAction.exec
  [26] ForkJoinTask.doExec
  [27] ForkJoinPool$WorkQueue.topLevelExec
  [28] ForkJoinPool.scan
  [29] ForkJoinPool.runWorker
  [30] ForkJoinWorkerThread.run

--- 966737 total (0.03%), 970 samples
  [ 0] VirtualThread.getAndClearInterrupt
  [ 1] Thread.interrupted
  [ 2] ReentrantLock$Sync.lockInterruptibly
  [ 3] ReentrantLock.lockInterruptibly
  [ 4] LinkedBlockingQueue.take
  [ 5] BlockingQueue.take
  [ 6] Channel.take
  [ 7] Cell$$Lambda$65.0x0000000801036fd0.apply
  [ 8] ReferencePipeline$3$1.accept
  [ 9] ArrayList$ArrayListSpliterator.forEachRemaining
  [10] AbstractPipeline.copyInto
  [11] AbstractPipeline.wrapAndCopyInto
  [12] ReduceOps$ReduceOp.evaluateSequential
  [13] AbstractPipeline.evaluate
  [14] IntPipeline.reduce
  [15] IntPipeline.sum
  [16] Cell.calculateNextState
  [17] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [18] Iterable.forEach
  [19] CellsGroup.run
  [20] Continuation.enterSpecial
  [21] Continuation.run
  [22] VirtualThread.runContinuation
  [23] VirtualThread$$Lambda$51.0x000000080103df08.run
  [24] ForkJoinTask$RunnableExecuteAction.exec
  [25] ForkJoinTask.doExec
  [26] ForkJoinPool$WorkQueue.topLevelExec
  [27] ForkJoinPool.scan
  [28] ForkJoinPool.runWorker
  [29] ForkJoinWorkerThread.run

--- 964752 total (0.03%), 968 samples
  [ 0] LinkedBlockingQueue.put
  [ 1] BlockingQueue.put
  [ 2] Channel.put
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 963754 total (0.03%), 938 samples
  [ 0] fpregs_restore_userregs_[k]
  [ 1] exit_to_user_mode_prepare_[k]
  [ 2] syscall_exit_to_user_mode_[k]
  [ 3] do_syscall_64_[k]
  [ 4] entry_SYSCALL_64_after_hwframe_[k]
  [ 5] __futex_abstimed_wait_common
  [ 6] Unsafe.park
  [ 7] LockSupport.park
  [ 8] ForkJoinPool.awaitWork
  [ 9] ForkJoinPool.runWorker
  [10] ForkJoinWorkerThread.run

--- 958822 total (0.03%), 942 samples
  [ 0] update_rq_clock_[k]
  [ 1] __schedule_[k]
  [ 2] schedule_[k]
  [ 3] futex_wait_queue_[k]
  [ 4] futex_wait_[k]
  [ 5] do_futex_[k]
  [ 6] __x64_sys_futex_[k]
  [ 7] do_syscall_64_[k]
  [ 8] entry_SYSCALL_64_after_hwframe_[k]
  [ 9] __futex_abstimed_wait_common
  [10] Unsafe.park
  [11] LockSupport.park
  [12] ForkJoinPool.awaitWork
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 954206 total (0.03%), 951 samples
  [ 0] Cell.calculateNextState
  [ 1] CellsGroup$$Lambda$62.0x0000000801036740.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

       total  percent  samples  top
  ----------  -------  -------  ---
   545442002   19.65%   545388  ReduceOps$5ReducingSink.get
   438192502   15.79%   438742  Thread.interrupted
   245782601    8.85%   245904  Cell.lambda$notifyLiveness$0
   214117733    7.71%   214606  AbstractQueuedSynchronizer.release
   206115446    7.43%   206499  AbstractQueuedSynchronizer.compareAndSetState
   127381298    4.59%   127182  AbstractPipeline.<init>
    80788017    2.91%    81058  LinkedBlockingQueue.take
    68305041    2.46%    68153  StreamOpFlag.fromCharacteristics
    53676454    1.93%    53857  LinkedBlockingQueue.put
    43824293    1.58%    43874  Sink$ChainedReference.<init>
    36999510    1.33%    37015  ReferencePipeline$4.opWrapSink
    36074779    1.30%    36188  ReentrantLock.lockInterruptibly
    34074758    1.23%    34117  ReferencePipeline$3.opWrapSink
    33540429    1.21%    33546  vtable stub
    28630284    1.03%    28719  AbstractOwnableSynchronizer.setExclusiveOwnerThread
    23850335    0.86%    23931  LinkedBlockingQueue.enqueue
    23341664    0.84%    23336  Cell$$Lambda$60.0x0000000801036300.accept
    23254325    0.84%    23323  LinkedBlockingQueue.dequeue
    18920157    0.68%    18976  Dimensions.forEachRowCol
    18367479    0.66%    18389  Sink$ChainedReference.begin
    18120363    0.65%    17725  vframeStream::vframeStream(JavaThread*, bool, bool, bool)
    17970756    0.65%    18003  AbstractOwnableSynchronizer.getExclusiveOwnerThread
    16423245    0.59%    16454  AbstractQueuedSynchronizer.signalNext
    13550529    0.49%    13579  VirtualThread.getAndClearInterrupt
    10621343    0.38%    10656  ReentrantLock$Sync.tryRelease
    10452728    0.38%    10471  ArrayList$ArrayListSpliterator.<init>
     9984686    0.36%    10009  AbstractQueuedSynchronizer.setState
     9702966    0.35%     9698  StreamSupport.stream
     9054567    0.33%     8911  psi_group_change_[k]
     7038922    0.25%     7061  AtomicInteger.getAndIncrement
     6823531    0.25%     6836  AbstractQueuedSynchronizer.getState
     6686062    0.24%     6564  __update_load_avg_cfs_rq_[k]
     6315280    0.23%     6334  ForkJoinPool.scan
     6085964    0.22%     5992  update_cfs_group_[k]
     5781610    0.21%     5791  ReferencePipeline.map
     5520811    0.20%     5537  ReentrantLock$Sync.lock
     5168953    0.19%     5187  ReentrantLock$Sync.isHeldExclusively
     4845185    0.17%     4848  AbstractPipeline.wrapSink
     4838406    0.17%     4847  AbstractQueuedSynchronizer$ConditionObject.signal
     4818792    0.17%     4785  __memset_avx2_unaligned_erms
     4746464    0.17%     4652  update_blocked_averages_[k]
     4534133    0.16%     4553  ReentrantLock$Sync.lockInterruptibly
     4406454    0.16%     4347  InstanceKlass::find_method_index(Array<Method*> const*, Symbol const*, Symbol const*, Klass::OverpassLookupMode, Klass::StaticLookupMode, Klass::PrivateLookupMode) [clone .constprop.0]
     4134004    0.15%     4145  AbstractQueuedSynchronizer.acquire
     4129021    0.15%     4068  update_load_avg_[k]
     4074059    0.15%     4075  ArrayList.forEach
     3742152    0.13%     3688  reweight_entity_[k]
     3715875    0.13%     3644  syscall_exit_to_user_mode_[k]
     3700343    0.13%     3646  update_curr_[k]
     3636372    0.13%     3643  ArrayList$SubList$1.next
     3571595    0.13%     3578  Iterable.forEach
     3425546    0.12%     3434  LinkedBlockingQueue.signalNotFull
     3189659    0.11%     3142  __update_load_avg_se_[k]
     3164802    0.11%     3165  Cell.calculateNextState
     3108347    0.11%     3063  enqueue_entity_[k]
     2973580    0.11%     2968  __tls_get_addr
     2973172    0.11%     2983  LinkedBlockingQueue.signalNotEmpty
     2940525    0.11%     2895  __schedule_[k]
     2914404    0.10%     2921  AbstractQueuedSynchronizer$ConditionObject.enableWait
     2641717    0.10%     2654  ForkJoinPool$WorkQueue.push
     2485523    0.09%     2490  Channel.take
     2473753    0.09%     2479  CellsGroup$$Lambda$62.0x0000000801036740.accept
     2466793    0.09%     2424  __entry_text_start_[k]
     2458471    0.09%     2422  enqueue_task_fair_[k]
     2432427    0.09%     2432  Object.<init>
     2417166    0.09%     2420  CellsGroup$$Lambda$56.0x0000000801035668.accept
     2301594    0.08%     2309  ___pthread_cond_wait
     2175126    0.08%     2177  Parker::park(bool, long)
     2139403    0.08%     2147  AtomicInteger.get
     2107857    0.08%     2075  _raw_spin_lock_[k]
     2090006    0.08%     2092  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<286822ul, G1BarrierSet>, (AccessInternal::BarrierType)1, 286822ul>::oop_access_barrier(oopDesc*, long, oopDesc*)
     2057212    0.07%     2020  check_preemption_disabled_[k]
     2003514    0.07%     1990  G1CardSet::occupied() const
     1995649    0.07%     2001  ChannelsGrid.getChannel
     1987447    0.07%     1990  AbstractQueuedSynchronizer$ConditionObject.await
     1926072    0.07%     1924  __memmove_sse2_unaligned_erms
     1882070    0.07%     1890  AbstractQueuedSynchronizer.enqueue
     1851105    0.07%     1861  Unsafe.getAndBitwiseAndInt
     1762508    0.06%     1768  ForkJoinPool.awaitWork
     1744200    0.06%     1743  Unsafe_Park
     1729183    0.06%     1706  dequeue_task_fair_[k]
     1697497    0.06%     1675  cpuacct_charge_[k]
     1673734    0.06%     1680  AtomicInteger.getAndDecrement
     1670260    0.06%     1642  native_sched_clock_[k]
     1657234    0.06%     1663  Thread.clearInterrupt
     1629747    0.06%     1623  ArrayList.spliterator
     1629334    0.06%     1603  update_rq_clock_[k]
     1596189    0.06%     1596  Channel.put
     1535057    0.06%     1533  ReferencePipeline.<init>
     1532395    0.06%     1534  ForkJoinPool$WorkQueue.casSlotToNull
     1507683    0.05%     1507  Cell.notifyLiveness
     1435284    0.05%     1440  Unsafe.park
     1371635    0.05%     1379  MemAllocator::allocate() const
     1369560    0.05%     1348  dequeue_entity_[k]
     1366599    0.05%     1370  VirtualThread.runContinuation
     1351632    0.05%     1355  ReentrantLock.lock
     1319993    0.05%     1323  __condvar_dec_grefs
     1281561    0.05%     1283  G1ParScanThreadState::trim_queue_to_threshold(unsigned int)
     1267686    0.05%     1250  select_task_rq_fair_[k]
     1250108    0.05%     1224  rb_next_[k]
     1222538    0.04%     1190  fpregs_restore_userregs_[k]
     1209248    0.04%     1212  ReentrantLock.unlock
     1208668    0.04%     1212  VirtualThread.compareAndSetState
     1184909    0.04%     1186  Continuation.yield0
     1176954    0.04%     1182  VirtualThread.unpark
     1160620    0.04%     1164  VirtualThread.unmount
     1156668    0.04%     1141  available_idle_cpu_[k]
     1155397    0.04%     1135  rcu_sched_clock_irq_[k]
     1149406    0.04%     1155  AbstractQueuedSynchronizer$ConditionObject.doSignal
     1138729    0.04%     1143  System$2.setExtentLocalCache
     1137307    0.04%     1143  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<548964ul, G1BarrierSet>, (AccessInternal::BarrierType)2, 548964ul>::oop_access_barrier(void*)
     1120198    0.04%     1123  ArrayList$SubList$1.checkForComodification
     1114765    0.04%     1087  syscall_return_via_sysret_[k]
     1052639    0.04%     1054  G1CollectedHeap::requires_barriers(stackChunkOopDesc*) const
     1046468    0.04%     1034  psi_task_change_[k]
     1039775    0.04%     1030  G1Analytics::predict_scan_card_num(unsigned long, bool) const
     1038851    0.04%     1022  G1Policy::preventive_collection_required(unsigned int)
      996140    0.04%      976  timerqueue_add_[k]
      985563    0.04%      964  __hrtimer_run_queues_[k]
      976745    0.04%      960  iterate_groups_[k]
      973281    0.04%      979  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<1335398ul, G1BarrierSet>, (AccessInternal::BarrierType)1, 1335398ul>::oop_access_barrier(oopDesc*, long, oopDesc*)
      967705    0.03%      973  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<286822ul, G1BarrierSet>, (AccessInternal::BarrierType)3, 286822ul>::oop_access_barrier(oopDesc*, long)
      965638    0.03%      952  __calc_delta_[k]
      946007    0.03%      950  ForkJoinPool.signalWork
      941069    0.03%      914  restore_fpregs_from_fpstate_[k]
      938498    0.03%      924  preempt_count_add_[k]
      934418    0.03%      913  error_entry_[k]
      928361    0.03%      913  G1Allocator::unsafe_max_tlab_alloc()
      913718    0.03%      901  __get_user_nocheck_4_[k]
      913386    0.03%      903  HeapRegionManager::allocate_free_region(HeapRegionType, unsigned int)
      889370    0.03%      892  Unsafe.getAndBitwiseOrInt
      884156    0.03%      871  update_min_vruntime_[k]
      873353    0.03%      862  update_irq_load_avg_[k]
      868532    0.03%      868  ArrayList.elementAt
      862024    0.03%      849  futex_q_lock_[k]
      848763    0.03%      835  __perf_event_task_sched_out_[k]
      847955    0.03%      850  pthread_mutex_trylock@@GLIBC_2.34
      843873    0.03%      848  ObjArrayAllocator::initialize(HeapWordImpl**) const
      836751    0.03%      835  LinkResolver::check_method_loader_constraints(LinkInfo const&, methodHandle const&, char const*, JavaThread*)
      809203    0.03%      793  __softirqentry_text_start_[k]
      808291    0.03%      811  int freeze<Config<(oop_kind)0, G1BarrierSet> >(JavaThread*, long*)
      802369    0.03%      801  Thaw<Config<(oop_kind)0, G1BarrierSet> >::thaw_fast(stackChunkOopDesc*)
      801225    0.03%      805  Sink$ChainedReference.end
      800191    0.03%      802  update_register_map1(ImmutableOopMap const*, frame const*, RegisterMap*)
      784771    0.03%      786  VirtualThread.afterYield
      784762    0.03%      771  preempt_count_sub_[k]
      765961    0.03%      767  LinkResolver::resolve_continuation_enter(CallInfo&, JavaThread*)
      763539    0.03%      768  ObjArrayKlass::multi_allocate(int, int*, JavaThread*)
      759004    0.03%      744  AbsSeq::davg() const
      755355    0.03%      754  oopDesc::address_field(int) const
      751123    0.03%      753  AbstractQueuedSynchronizer.casTail
      748928    0.03%      749  FreezeBase::freeze_fast_copy(stackChunkOopDesc*, int)
      748322    0.03%      747  G1FromCardCache::clear(unsigned int)
      737863    0.03%      739  AbsSeq::dsd() const
      734301    0.03%      731  __GI___pthread_mutex_lock
      726411    0.03%      713  trigger_load_balance_[k]
      699236    0.03%      701  BlockingQueue.take
      698642    0.03%      697  IntPipeline$StatelessOp.<init>
      694590    0.03%      696  SafepointMechanism::update_poll_values(JavaThread*)
      691139    0.02%      680  psi_task_switch_[k]
      667516    0.02%      659  RegisterMap::RegisterMap(JavaThread*, bool, bool, bool)
      665248    0.02%      666  ObjArrayKlass::allocate(int, JavaThread*)
      663861    0.02%      655  futex_wake_[k]
      646368    0.02%      634  resched_curr_[k]
      641411    0.02%      642  long* thaw<Config<(oop_kind)0, G1BarrierSet> >(JavaThread*, int)
      637467    0.02%      620  __get_user_8_[k]
      633494    0.02%      621  nohz_balance_exit_idle_[k]
      621358    0.02%      625  TypeArrayKlass::multi_allocate(int, int*, JavaThread*)
      616594    0.02%      619  __pthread_mutex_unlock_usercnt
      612890    0.02%      606  G1CollectedHeap::attempt_allocation_slow(unsigned long)
      606648    0.02%      610  ___pthread_cond_signal
      606305    0.02%      598  task_tick_fair_[k]
      597731    0.02%      594  __tls_get_addr@plt
      595684    0.02%      584  timekeeping_advance_[k]
      581952    0.02%      587  VirtualThread.start
      581118    0.02%      579  OptoRuntime::new_instance_C(Klass*, JavaThread*)
      574249    0.02%      576  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<544868ul, G1BarrierSet>, (AccessInternal::BarrierType)2, 544868ul>::oop_access_barrier(void*)
      573289    0.02%      573  PipelineHelper.<init>
      571978    0.02%      574  OopMapStream::find_next() [clone .part.0]
      567330    0.02%      555  _raw_spin_lock_irqsave_[k]
      556062    0.02%      559  MemAllocator::Allocation::notify_allocation_jvmti_sampler()
      546167    0.02%      546  G1Analytics::predict_card_merge_time_ms(unsigned long, bool) const
      537884    0.02%      536  LinkResolver::resolve_method(LinkInfo const&, Bytecodes::Code, JavaThread*)
      530426    0.02%      523  __cgroup_account_cputime_[k]
      522454    0.02%      524  ThreadPoolExecutor$Worker.tryRelease
      519683    0.02%      521  __vdso_clock_gettime
      514595    0.02%      515  FreeListAllocator::reset()
      510757    0.02%      512  freeze_epilog(JavaThread*, ContinuationWrapper&, freeze_result) [clone .part.0] [clone .isra.0]
      509870    0.02%      512  ForkJoinPool$WorkQueue.topLevelExec
      502271    0.02%      495  schedule_[k]
      498651    0.02%      500  java_lang_Thread::set_thread_status(oopDesc*, JavaThreadStatus)
      497566    0.02%      495  ObjectSampler::is_created()
      496737    0.02%      489  try_to_wake_up_[k]
      493281    0.02%      494  GameOfLife.calculateFrameBlocking
      492246    0.02%      481  sync_regs_[k]
      488501    0.02%      481  newidle_balance_[k]
      487709    0.02%      479  account_user_time_[k]
      481958    0.02%      471  asm_sysvec_apic_timer_interrupt_[k]
      473388    0.02%      472  InstanceKlass::uncached_lookup_method(Symbol const*, Symbol const*, Klass::OverpassLookupMode, Klass::PrivateLookupMode) const
      464435    0.02%      466  native_write_msr_[k]
