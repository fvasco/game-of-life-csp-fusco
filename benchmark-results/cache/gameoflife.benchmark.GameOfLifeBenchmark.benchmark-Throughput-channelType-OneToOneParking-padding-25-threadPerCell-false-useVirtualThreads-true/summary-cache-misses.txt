--- Execution profile ---
Total samples       : 4734913
not_walkable_not_Java: 1 (0.00%)
unknown_Java        : 33843 (0.71%)
not_walkable_Java   : 5514 (0.12%)
deoptimization      : 3 (0.00%)
skipped             : 1 (0.00%)

--- 1599651460 total (33.78%), 1598567 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 413364295 total (8.73%), 414972 samples
  [ 0] OneToOneParkingSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$66.0x0000000801036fc8.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 166322141 total (3.51%), 166707 samples
  [ 0] Cell$$Lambda$66.0x0000000801036fc8.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 146034528 total (3.08%), 146206 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$60.0x0000000801036300.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$55.0x0000000801035668.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 134950315 total (2.85%), 135204 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$4$1.<init>
  [ 2] ReferencePipeline$4.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 125284127 total (2.65%), 125502 samples
  [ 0] OneToOneParkingSingleValue.put
  [ 1] Channel.put
  [ 2] Cell.lambda$notifyLiveness$0
  [ 3] Cell$$Lambda$60.0x0000000801036300.accept
  [ 4] ArrayList.forEach
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$55.0x0000000801035668.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 113998360 total (2.41%), 113774 samples
  [ 0] StreamSupport.stream
  [ 1] Collection.stream
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 108648478 total (2.29%), 108926 samples
  [ 0] Dimensions.forEachRowCol
  [ 1] ChannelsGrid.forEachChannel
  [ 2] TickPerCell.tick
  [ 3] GameOfLife.calculateFrame
  [ 4] GameOfLife.lambda$calculateFrameBlocking$4
  [ 5] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 6] VirtualThread.run
  [ 7] VirtualThread$VThreadContinuation.lambda$new$0
  [ 8] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 9] Continuation.enter0
  [10] Continuation.enter
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 93011801 total (1.96%), 93043 samples
  [ 0] ReferencePipeline$4.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 90276818 total (1.91%), 90322 samples
  [ 0] vtable stub
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 88713954 total (1.87%), 88809 samples
  [ 0] StreamSupport.stream
  [ 1] Collection.stream
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 84593027 total (1.79%), 84868 samples
  [ 0] OneToOneParkingSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$66.0x0000000801036fc8.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 71807519 total (1.52%), 71873 samples
  [ 0] ReferencePipeline$3.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 64312838 total (1.36%), 64118 samples
  [ 0] Objects.requireNonNull
  [ 1] ReferencePipeline.map
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 63136946 total (1.33%), 63296 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$3$1.<init>
  [ 2] ReferencePipeline$3.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 62406784 total (1.32%), 62340 samples
  [ 0] Collection.stream
  [ 1] Cell.calculateNextState
  [ 2] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 3] Iterable.forEach
  [ 4] CellsGroup.run
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 58579825 total (1.24%), 58384 samples
  [ 0] ArrayList$ArrayListSpliterator.<init>
  [ 1] ArrayList.spliterator
  [ 2] Collection.stream
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 52166099 total (1.10%), 52034 samples
  [ 0] Objects.requireNonNull
  [ 1] StreamSupport.stream
  [ 2] Collection.stream
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 43351498 total (0.92%), 43245 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 37221678 total (0.79%), 37261 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 31530124 total (0.67%), 31550 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$3$1.<init>
  [ 2] ReferencePipeline$3.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 29555458 total (0.62%), 29633 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 29246348 total (0.62%), 29324 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 29072408 total (0.61%), 28992 samples
  [ 0] StreamSupport.stream
  [ 1] Collection.stream
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 26385887 total (0.56%), 26414 samples
  [ 0] Sink$ChainedReference.begin
  [ 1] Sink$ChainedReference.begin
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 22640623 total (0.48%), 22568 samples
  [ 0] ReferencePipeline.map
  [ 1] Cell.calculateNextState
  [ 2] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 3] Iterable.forEach
  [ 4] CellsGroup.run
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 20994083 total (0.44%), 21069 samples
  [ 0] OneToOneParkingSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$66.0x0000000801036fc8.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 17547643 total (0.37%), 17552 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$Head.<init>
  [ 3] StreamSupport.stream
  [ 4] Collection.stream
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 17151037 total (0.36%), 17206 samples
  [ 0] OneToOneParkingSingleValue.take
  [ 1] Channel.take
  [ 2] GameOfLife$$Lambda$62.0x0000000801036740.test
  [ 3] ChannelsGrid.lambda$forEachChannel$1
  [ 4] ChannelsGrid$$Lambda$63.0x0000000801036978.accept
  [ 5] Dimensions.forEachRowCol
  [ 6] ChannelsGrid.forEachChannel
  [ 7] GameOfLife.calculateFrame
  [ 8] GameOfLife.lambda$calculateFrameBlocking$4
  [ 9] GameOfLife$$Lambda$53.0x0000000801035268.run
  [10] VirtualThread.run
  [11] VirtualThread$VThreadContinuation.lambda$new$0
  [12] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [13] Continuation.enter0
  [14] Continuation.enter
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 16779755 total (0.35%), 16848 samples
  [ 0] Cell$$Lambda$66.0x0000000801036fc8.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 16252759 total (0.34%), 16261 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$4$1.<init>
  [ 2] ReferencePipeline$4.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 16046341 total (0.34%), 16061 samples
  [ 0] ReferencePipeline$4.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 15808046 total (0.33%), 15828 samples
  [ 0] OneToOneParkingSingleValue.take
  [ 1] Channel.take
  [ 2] TickPerCell.waitTick
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$55.0x0000000801035668.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 14925054 total (0.32%), 14891 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 14380572 total (0.30%), 14439 samples
  [ 0] ReferencePipeline$4$1.accept
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 14075355 total (0.30%), 14134 samples
  [ 0] ReferencePipeline$4$1.accept
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 13886026 total (0.29%), 13933 samples
  [ 0] OneToOneParkingSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$66.0x0000000801036fc8.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 13781985 total (0.29%), 13840 samples
  [ 0] Cell$$Lambda$69.0x0000000801037640.applyAsInt
  [ 1] ReferencePipeline$4$1.accept
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 13723727 total (0.29%), 13781 samples
  [ 0] ReferencePipeline$4$1.accept
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 13703124 total (0.29%), 13760 samples
  [ 0] ReduceOps$5ReducingSink.accept
  [ 1] ReferencePipeline$4$1.accept
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 13588590 total (0.29%), 13584 samples
  [ 0] PipelineHelper.<init>
  [ 1] AbstractPipeline.<init>
  [ 2] ReferencePipeline.<init>
  [ 3] ReferencePipeline$StatelessOp.<init>
  [ 4] ReferencePipeline$3.<init>
  [ 5] ReferencePipeline.map
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 13168754 total (0.28%), 13224 samples
  [ 0] ReduceOps$5ReducingSink.accept
  [ 1] ReferencePipeline$4$1.accept
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 13088296 total (0.28%), 13097 samples
  [ 0] Sink$ChainedReference.begin
  [ 1] Sink$ChainedReference.begin
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 13012127 total (0.27%), 13013 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$Head.<init>
  [ 3] StreamSupport.stream
  [ 4] Collection.stream
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 12619285 total (0.27%), 12631 samples
  [ 0] AbstractPipeline.wrapSink
  [ 1] AbstractPipeline.wrapAndCopyInto
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 12059291 total (0.25%), 12024 samples
  [ 0] Cell.calculateNextState
  [ 1] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 12050170 total (0.25%), 12062 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 11876813 total (0.25%), 11877 samples
  [ 0] AbstractPipeline.wrapSink
  [ 1] AbstractPipeline.wrapAndCopyInto
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 11444974 total (0.24%), 11452 samples
  [ 0] ReferencePipeline$3.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 10572059 total (0.22%), 10565 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$AdaptedRunnableAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 10084661 total (0.21%), 10090 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 9741355 total (0.21%), 9581 samples
  [ 0] vframeStream::vframeStream(JavaThread*, bool, bool, bool)
  [ 1] SharedRuntime::find_callee_method(JavaThread*)
  [ 2] SharedRuntime::reresolve_call_site(JavaThread*)
  [ 3] SharedRuntime::handle_wrong_method(JavaThread*)
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 9482597 total (0.20%), 9466 samples
  [ 0] IntPipeline.<init>
  [ 1] IntPipeline$StatelessOp.<init>
  [ 2] ReferencePipeline$4.<init>
  [ 3] ReferencePipeline.mapToInt
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] Continuation.enterSpecial
  [ 9] Continuation.run
  [10] VirtualThread.runContinuation
  [11] VirtualThread$$Lambda$51.0x000000080103df08.run
  [12] ForkJoinTask$RunnableExecuteAction.exec
  [13] ForkJoinTask.doExec
  [14] ForkJoinPool$WorkQueue.topLevelExec
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 9055265 total (0.19%), 9095 samples
  [ 0] OneToOneParkingSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$66.0x0000000801036fc8.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 8926594 total (0.19%), 8953 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$66.0x0000000801036fc8.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 8608499 total (0.18%), 8615 samples
  [ 0] Sink$ChainedReference.begin
  [ 1] [unknown_Java]

--- 8414518 total (0.18%), 8405 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 8407575 total (0.18%), 8433 samples
  [ 0] OneToOneParkingSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$66.0x0000000801036fc8.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 8067341 total (0.17%), 8071 samples
  [ 0] ReferencePipeline$4.opWrapSink
  [ 1] [unknown_Java]

--- 7707636 total (0.16%), 7713 samples
  [ 0] ReferencePipeline$3.opWrapSink
  [ 1] [unknown_Java]

--- 7088948 total (0.15%), 7071 samples
  [ 0] PipelineHelper.<init>
  [ 1] AbstractPipeline.<init>
  [ 2] ReferencePipeline.<init>
  [ 3] ReferencePipeline$Head.<init>
  [ 4] StreamSupport.stream
  [ 5] Collection.stream
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 7025284 total (0.15%), 7040 samples
  [ 0] OneToOneParkingSingleValue.put
  [ 1] Channel.put
  [ 2] Cell.lambda$notifyLiveness$0
  [ 3] Cell$$Lambda$60.0x0000000801036300.accept
  [ 4] ArrayList.forEach
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$55.0x0000000801035668.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 6811285 total (0.14%), 6795 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$Head.<init>
  [ 3] StreamSupport.stream
  [ 4] Collection.stream
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 6355965 total (0.13%), 6363 samples
  [ 0] StreamOpFlag.fromCharacteristics
  [ 1] StreamSupport.stream
  [ 2] Collection.stream
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 6307581 total (0.13%), 6300 samples
  [ 0] StreamSupport.stream
  [ 1] Collection.stream
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 5328852 total (0.11%), 5334 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] [unknown_Java]

--- 5275812 total (0.11%), 5282 samples
  [ 0] ReferencePipeline$4.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 5104007 total (0.11%), 5019 samples
  [ 0] psi_group_change_[k]
  [ 1] psi_task_switch_[k]
  [ 2] __schedule_[k]
  [ 3] schedule_[k]
  [ 4] futex_wait_queue_[k]
  [ 5] futex_wait_[k]
  [ 6] do_futex_[k]
  [ 7] __x64_sys_futex_[k]
  [ 8] do_syscall_64_[k]
  [ 9] entry_SYSCALL_64_after_hwframe_[k]
  [10] __futex_abstimed_wait_common
  [11] Unsafe.park
  [12] LockSupport.park
  [13] ForkJoinPool.awaitWork
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 5055338 total (0.11%), 5066 samples
  [ 0] Channel.take
  [ 1] GameOfLife$$Lambda$62.0x0000000801036740.test
  [ 2] ChannelsGrid.lambda$forEachChannel$1
  [ 3] ChannelsGrid$$Lambda$63.0x0000000801036978.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] GameOfLife.calculateFrame
  [ 7] GameOfLife.lambda$calculateFrameBlocking$4
  [ 8] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 9] VirtualThread.run
  [10] VirtualThread$VThreadContinuation.lambda$new$0
  [11] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [12] Continuation.enter0
  [13] Continuation.enter
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 4851820 total (0.10%), 4740 samples
  [ 0] InstanceKlass::find_method_index(Array<Method*> const*, Symbol const*, Symbol const*, Klass::OverpassLookupMode, Klass::StaticLookupMode, Klass::PrivateLookupMode) [clone .constprop.0]
  [ 1] InstanceKlass::uncached_lookup_method(Symbol const*, Symbol const*, Klass::OverpassLookupMode, Klass::PrivateLookupMode) const
  [ 2] LinkResolver::lookup_method_in_klasses(LinkInfo const&, bool, bool)
  [ 3] LinkResolver::resolve_method(LinkInfo const&, Bytecodes::Code, JavaThread*)
  [ 4] LinkResolver::resolve_continuation_enter(CallInfo&, JavaThread*)
  [ 5] SharedRuntime::find_callee_info_helper(vframeStream&, Bytecodes::Code&, CallInfo&, JavaThread*)
  [ 6] SharedRuntime::find_callee_method(JavaThread*)
  [ 7] SharedRuntime::reresolve_call_site(JavaThread*)
  [ 8] SharedRuntime::handle_wrong_method(JavaThread*)
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 4780292 total (0.10%), 4784 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 4767612 total (0.10%), 4762 samples
  [ 0] AbstractPipeline.<init>
  [ 1] IntPipeline.<init>
  [ 2] IntPipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$4.<init>
  [ 4] ReferencePipeline.mapToInt
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 4490355 total (0.09%), 4494 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 4402004 total (0.09%), 4384 samples
  [ 0] ArrayList$ArrayListSpliterator.<init>
  [ 1] ArrayList.spliterator
  [ 2] Collection.stream
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 4226798 total (0.09%), 4230 samples
  [ 0] ReferencePipeline$3.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 4214534 total (0.09%), 4217 samples
  [ 0] Sink$ChainedReference.begin
  [ 1] Sink$ChainedReference.begin
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 4196222 total (0.09%), 4196 samples
  [ 0] Cell.calculateNextState
  [ 1] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 3944408 total (0.08%), 3936 samples
  [ 0] __memset_avx2_unaligned_erms
  [ 1] G1RemSetScanState::G1ClearCardTableTask::do_work(unsigned int)
  [ 2] G1BatchedTask::work(unsigned int)
  [ 3] WorkerThread::run()
  [ 4] Thread::call_run()
  [ 5] thread_native_entry(Thread*)
  [ 6] start_thread

--- 3903278 total (0.08%), 3906 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 3868074 total (0.08%), 3873 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 3813664 total (0.08%), 3759 samples
  [ 0] update_cfs_group_[k]
  [ 1] dequeue_entity_[k]
  [ 2] dequeue_task_fair_[k]
  [ 3] __schedule_[k]
  [ 4] schedule_[k]
  [ 5] futex_wait_queue_[k]
  [ 6] futex_wait_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] __futex_abstimed_wait_common
  [12] Unsafe.park
  [13] LockSupport.park
  [14] ForkJoinPool.awaitWork
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 3635590 total (0.08%), 3642 samples
  [ 0] Channel.put
  [ 1] Cell.lambda$notifyLiveness$0
  [ 2] Cell$$Lambda$60.0x0000000801036300.accept
  [ 3] ArrayList.forEach
  [ 4] Cell.notifyLiveness
  [ 5] CellsGroup$$Lambda$55.0x0000000801035668.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] Continuation.enterSpecial
  [ 9] Continuation.run
  [10] VirtualThread.runContinuation
  [11] VirtualThread$$Lambda$51.0x000000080103df08.run
  [12] ForkJoinTask$RunnableExecuteAction.exec
  [13] ForkJoinTask.doExec
  [14] ForkJoinPool$WorkQueue.topLevelExec
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 3460437 total (0.07%), 3463 samples
  [ 0] Sink$ChainedReference.begin
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 3452528 total (0.07%), 3460 samples
  [ 0] ArrayList.elementAt
  [ 1] ArrayList.forEach
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$55.0x0000000801035668.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 3422982 total (0.07%), 3440 samples
  [ 0] MemAllocator::allocate() const
  [ 1] TypeArrayKlass::multi_allocate(int, int*, JavaThread*)
  [ 2] ObjArrayKlass::multi_allocate(int, int*, JavaThread*)
  [ 3] OptoRuntime::multianewarray2_C(Klass*, int, int, JavaThread*)
  [ 4] GameOfLife.calculateFrame
  [ 5] GameOfLife.lambda$calculateFrameBlocking$4
  [ 6] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 7] VirtualThread.run
  [ 8] VirtualThread$VThreadContinuation.lambda$new$0
  [ 9] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [10] Continuation.enter0
  [11] Continuation.enter
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 3331761 total (0.07%), 3337 samples
  [ 0] Channel.put
  [ 1] Cell.lambda$notifyLiveness$0
  [ 2] Cell$$Lambda$60.0x0000000801036300.accept
  [ 3] ArrayList.forEach
  [ 4] Cell.notifyLiveness
  [ 5] CellsGroup$$Lambda$55.0x0000000801035668.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] Continuation.enterSpecial
  [ 9] Continuation.run
  [10] VirtualThread.runContinuation
  [11] VirtualThread$$Lambda$51.0x000000080103df08.run
  [12] ForkJoinTask$RunnableExecuteAction.exec
  [13] ForkJoinTask.doExec
  [14] ForkJoinPool$WorkQueue.topLevelExec
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 3232398 total (0.07%), 3228 samples
  [ 0] Cell.calculateNextState
  [ 1] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 3197106 total (0.07%), 3149 samples
  [ 0] update_curr_[k]
  [ 1] dequeue_entity_[k]
  [ 2] dequeue_task_fair_[k]
  [ 3] __schedule_[k]
  [ 4] schedule_[k]
  [ 5] futex_wait_queue_[k]
  [ 6] futex_wait_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] __futex_abstimed_wait_common
  [12] Unsafe.park
  [13] LockSupport.park
  [14] ForkJoinPool.awaitWork
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 3011602 total (0.06%), 2965 samples
  [ 0] __memset_avx2_unaligned_erms
  [ 1] MemAllocator::allocate_inside_tlab_slow(MemAllocator::Allocation&) const
  [ 2] MemAllocator::allocate() const
  [ 3] InstanceKlass::allocate_instance(JavaThread*)
  [ 4] OptoRuntime::new_instance_C(Klass*, JavaThread*)
  [ 5] ReduceOps$5ReducingSink.get
  [ 6] ReduceOps$5ReducingSink.get
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 2978698 total (0.06%), 2984 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 2969828 total (0.06%), 2986 samples
  [ 0] AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<1335398ul, G1BarrierSet>, (AccessInternal::BarrierType)1, 1335398ul>::oop_access_barrier(oopDesc*, long, oopDesc*)
  [ 1] ObjArrayKlass::multi_allocate(int, int*, JavaThread*)
  [ 2] OptoRuntime::multianewarray2_C(Klass*, int, int, JavaThread*)
  [ 3] GameOfLife.calculateFrame
  [ 4] GameOfLife.lambda$calculateFrameBlocking$4
  [ 5] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 6] VirtualThread.run
  [ 7] VirtualThread$VThreadContinuation.lambda$new$0
  [ 8] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 9] Continuation.enter0
  [10] Continuation.enter
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 2960801 total (0.06%), 2965 samples
  [ 0] Dimensions.forEachRowCol
  [ 1] ChannelsGrid.forEachChannel
  [ 2] TickPerCell.tick
  [ 3] GameOfLife.calculateFrame
  [ 4] GameOfLife.lambda$calculateFrameBlocking$4
  [ 5] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 6] VirtualThread.run
  [ 7] VirtualThread$VThreadContinuation.lambda$new$0
  [ 8] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 9] Continuation.enter0
  [10] Continuation.enter
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 2855932 total (0.06%), 2865 samples
  [ 0] Dimensions.forEachRowCol
  [ 1] ChannelsGrid.forEachChannel
  [ 2] TickPerCell.tick
  [ 3] GameOfLife.calculateFrame
  [ 4] GameOfLife.lambda$calculateFrameBlocking$4
  [ 5] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 6] VirtualThread.run
  [ 7] VirtualThread$VThreadContinuation.lambda$new$0
  [ 8] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 9] Continuation.enter0
  [10] Continuation.enter
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 2834613 total (0.06%), 2841 samples
  [ 0] Dimensions.forEachRowCol
  [ 1] ChannelsGrid.forEachChannel
  [ 2] TickPerCell.tick
  [ 3] GameOfLife.calculateFrame
  [ 4] GameOfLife.lambda$calculateFrameBlocking$4
  [ 5] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 6] VirtualThread.run
  [ 7] VirtualThread$VThreadContinuation.lambda$new$0
  [ 8] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 9] Continuation.enter0
  [10] Continuation.enter
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 2806340 total (0.06%), 2818 samples
  [ 0] OneToOneParkingSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$66.0x0000000801036fc8.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$AdaptedRunnableAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 2724735 total (0.06%), 2732 samples
  [ 0] OneToOneParkingSingleValue.take
  [ 1] Channel.take
  [ 2] GameOfLife$$Lambda$62.0x0000000801036740.test
  [ 3] ChannelsGrid.lambda$forEachChannel$1
  [ 4] ChannelsGrid$$Lambda$63.0x0000000801036978.accept
  [ 5] Dimensions.forEachRowCol
  [ 6] ChannelsGrid.forEachChannel
  [ 7] GameOfLife.calculateFrame
  [ 8] GameOfLife.lambda$calculateFrameBlocking$4
  [ 9] GameOfLife$$Lambda$53.0x0000000801035268.run
  [10] VirtualThread.run
  [11] VirtualThread$VThreadContinuation.lambda$new$0
  [12] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [13] Continuation.enter0
  [14] Continuation.enter
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$AdaptedRunnableAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 2648418 total (0.06%), 2647 samples
  [ 0] Iterable.forEach
  [ 1] CellsGroup.run
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run

--- 2610272 total (0.06%), 2614 samples
  [ 0] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] Continuation.enterSpecial
  [ 4] Continuation.run
  [ 5] VirtualThread.runContinuation
  [ 6] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 7] ForkJoinTask$RunnableExecuteAction.exec
  [ 8] ForkJoinTask.doExec
  [ 9] ForkJoinPool$WorkQueue.topLevelExec
  [10] ForkJoinPool.scan
  [11] ForkJoinPool.runWorker
  [12] ForkJoinWorkerThread.run

--- 2609861 total (0.06%), 2610 samples
  [ 0] OneToOneParkingSingleValue.take
  [ 1] Channel.take
  [ 2] TickPerCell.waitTick
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$55.0x0000000801035668.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] Continuation.enterSpecial
  [ 8] Continuation.run
  [ 9] VirtualThread.runContinuation
  [10] VirtualThread$$Lambda$51.0x000000080103df08.run
  [11] ForkJoinTask$RunnableExecuteAction.exec
  [12] ForkJoinTask.doExec
  [13] ForkJoinPool$WorkQueue.topLevelExec
  [14] ForkJoinPool.scan
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 2407709 total (0.05%), 2408 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 2362920 total (0.05%), 2356 samples
  [ 0] ReferencePipeline.mapToInt
  [ 1] Cell.calculateNextState
  [ 2] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 3] Iterable.forEach
  [ 4] CellsGroup.run
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 2327564 total (0.05%), 2333 samples
  [ 0] Sink$ChainedReference.end
  [ 1] Sink$ChainedReference.end
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 2299203 total (0.05%), 2263 samples
  [ 0] update_load_avg_[k]
  [ 1] dequeue_entity_[k]
  [ 2] dequeue_task_fair_[k]
  [ 3] __schedule_[k]
  [ 4] schedule_[k]
  [ 5] futex_wait_queue_[k]
  [ 6] futex_wait_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] __futex_abstimed_wait_common
  [12] Unsafe.park
  [13] LockSupport.park
  [14] ForkJoinPool.awaitWork
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 2282221 total (0.05%), 2248 samples
  [ 0] __schedule_[k]
  [ 1] schedule_[k]
  [ 2] futex_wait_queue_[k]
  [ 3] futex_wait_[k]
  [ 4] do_futex_[k]
  [ 5] __x64_sys_futex_[k]
  [ 6] do_syscall_64_[k]
  [ 7] entry_SYSCALL_64_after_hwframe_[k]
  [ 8] __futex_abstimed_wait_common
  [ 9] Unsafe.park
  [10] LockSupport.park
  [11] ForkJoinPool.awaitWork
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 2265331 total (0.05%), 2231 samples
  [ 0] __update_load_avg_cfs_rq_[k]
  [ 1] update_load_avg_[k]
  [ 2] dequeue_entity_[k]
  [ 3] dequeue_task_fair_[k]
  [ 4] __schedule_[k]
  [ 5] schedule_[k]
  [ 6] futex_wait_queue_[k]
  [ 7] futex_wait_[k]
  [ 8] do_futex_[k]
  [ 9] __x64_sys_futex_[k]
  [10] do_syscall_64_[k]
  [11] entry_SYSCALL_64_after_hwframe_[k]
  [12] __futex_abstimed_wait_common
  [13] Unsafe.park
  [14] LockSupport.park
  [15] ForkJoinPool.awaitWork
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 2114116 total (0.04%), 2116 samples
  [ 0] AbstractPipeline.copyInto
  [ 1] AbstractPipeline.wrapAndCopyInto
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 2004486 total (0.04%), 1975 samples
  [ 0] __update_load_avg_se_[k]
  [ 1] update_load_avg_[k]
  [ 2] dequeue_entity_[k]
  [ 3] dequeue_task_fair_[k]
  [ 4] __schedule_[k]
  [ 5] schedule_[k]
  [ 6] futex_wait_queue_[k]
  [ 7] futex_wait_[k]
  [ 8] do_futex_[k]
  [ 9] __x64_sys_futex_[k]
  [10] do_syscall_64_[k]
  [11] entry_SYSCALL_64_after_hwframe_[k]
  [12] __futex_abstimed_wait_common
  [13] Unsafe.park
  [14] LockSupport.park
  [15] ForkJoinPool.awaitWork
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 1924819 total (0.04%), 1927 samples
  [ 0] AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<286822ul, G1BarrierSet>, (AccessInternal::BarrierType)1, 286822ul>::oop_access_barrier(oopDesc*, long, oopDesc*)
  [ 1] int freeze<Config<(oop_kind)0, G1BarrierSet> >(JavaThread*, long*)
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run

--- 1898600 total (0.04%), 1906 samples
  [ 0] TypeArrayKlass::multi_allocate(int, int*, JavaThread*)
  [ 1] ObjArrayKlass::multi_allocate(int, int*, JavaThread*)
  [ 2] OptoRuntime::multianewarray2_C(Klass*, int, int, JavaThread*)
  [ 3] GameOfLife.calculateFrame
  [ 4] GameOfLife.lambda$calculateFrameBlocking$4
  [ 5] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 6] VirtualThread.run
  [ 7] VirtualThread$VThreadContinuation.lambda$new$0
  [ 8] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 9] Continuation.enter0
  [10] Continuation.enter
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 1851471 total (0.04%), 1857 samples
  [ 0] ChannelsGrid.getChannel
  [ 1] ChannelsGrid.lambda$forEachChannel$1
  [ 2] ChannelsGrid$$Lambda$63.0x0000000801036978.accept
  [ 3] Dimensions.forEachRowCol
  [ 4] ChannelsGrid.forEachChannel
  [ 5] GameOfLife.calculateFrame
  [ 6] GameOfLife.lambda$calculateFrameBlocking$4
  [ 7] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 8] VirtualThread.run
  [ 9] VirtualThread$VThreadContinuation.lambda$new$0
  [10] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [11] Continuation.enter0
  [12] Continuation.enter
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 1807769 total (0.04%), 1809 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 1788299 total (0.04%), 1762 samples
  [ 0] dequeue_task_fair_[k]
  [ 1] __schedule_[k]
  [ 2] schedule_[k]
  [ 3] futex_wait_queue_[k]
  [ 4] futex_wait_[k]
  [ 5] do_futex_[k]
  [ 6] __x64_sys_futex_[k]
  [ 7] do_syscall_64_[k]
  [ 8] entry_SYSCALL_64_after_hwframe_[k]
  [ 9] __futex_abstimed_wait_common
  [10] Unsafe.park
  [11] LockSupport.park
  [12] ForkJoinPool.awaitWork
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 1751714 total (0.04%), 1729 samples
  [ 0] reweight_entity_[k]
  [ 1] dequeue_entity_[k]
  [ 2] dequeue_task_fair_[k]
  [ 3] __schedule_[k]
  [ 4] schedule_[k]
  [ 5] futex_wait_queue_[k]
  [ 6] futex_wait_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] __futex_abstimed_wait_common
  [12] Unsafe.park
  [13] LockSupport.park
  [14] ForkJoinPool.awaitWork
  [15] ForkJoinPool.runWorker
  [16] ForkJoinWorkerThread.run

--- 1748591 total (0.04%), 1747 samples
  [ 0] Cell.calculateNextState
  [ 1] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 1744080 total (0.04%), 1739 samples
  [ 0] Parker::park(bool, long)
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] ForkJoinPool.awaitWork
  [ 5] ForkJoinPool.runWorker
  [ 6] ForkJoinWorkerThread.run

--- 1743607 total (0.04%), 1746 samples
  [ 0] Objects.requireNonNull
  [ 1] ReferencePipeline.mapToInt
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 1708144 total (0.04%), 1713 samples
  [ 0] ForkJoinTask.doExec
  [ 1] ForkJoinPool$WorkQueue.topLevelExec
  [ 2] ForkJoinPool.scan
  [ 3] ForkJoinPool.runWorker
  [ 4] ForkJoinWorkerThread.run

--- 1706946 total (0.04%), 1683 samples
  [ 0] cpuacct_charge_[k]
  [ 1] update_curr_[k]
  [ 2] dequeue_entity_[k]
  [ 3] dequeue_task_fair_[k]
  [ 4] __schedule_[k]
  [ 5] schedule_[k]
  [ 6] futex_wait_queue_[k]
  [ 7] futex_wait_[k]
  [ 8] do_futex_[k]
  [ 9] __x64_sys_futex_[k]
  [10] do_syscall_64_[k]
  [11] entry_SYSCALL_64_after_hwframe_[k]
  [12] __futex_abstimed_wait_common
  [13] Unsafe.park
  [14] LockSupport.park
  [15] ForkJoinPool.awaitWork
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 1691591 total (0.04%), 1693 samples
  [ 0] ArrayList$SubList$1.next
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] Continuation.enterSpecial
  [ 4] Continuation.run
  [ 5] VirtualThread.runContinuation
  [ 6] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 7] ForkJoinTask$RunnableExecuteAction.exec
  [ 8] ForkJoinTask.doExec
  [ 9] ForkJoinPool$WorkQueue.topLevelExec
  [10] ForkJoinPool.scan
  [11] ForkJoinPool.runWorker
  [12] ForkJoinWorkerThread.run

--- 1679599 total (0.04%), 1686 samples
  [ 0] ObjArrayAllocator::initialize(HeapWordImpl**) const
  [ 1] MemAllocator::allocate() const
  [ 2] TypeArrayKlass::multi_allocate(int, int*, JavaThread*)
  [ 3] ObjArrayKlass::multi_allocate(int, int*, JavaThread*)
  [ 4] OptoRuntime::multianewarray2_C(Klass*, int, int, JavaThread*)
  [ 5] GameOfLife.calculateFrame
  [ 6] GameOfLife.lambda$calculateFrameBlocking$4
  [ 7] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 8] VirtualThread.run
  [ 9] VirtualThread$VThreadContinuation.lambda$new$0
  [10] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [11] Continuation.enter0
  [12] Continuation.enter
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 1620183 total (0.03%), 1629 samples
  [ 0] ObjArrayKlass::multi_allocate(int, int*, JavaThread*)
  [ 1] OptoRuntime::multianewarray2_C(Klass*, int, int, JavaThread*)
  [ 2] GameOfLife.calculateFrame
  [ 3] GameOfLife.lambda$calculateFrameBlocking$4
  [ 4] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 5] VirtualThread.run
  [ 6] VirtualThread$VThreadContinuation.lambda$new$0
  [ 7] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 8] Continuation.enter0
  [ 9] Continuation.enter
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 1611335 total (0.03%), 1615 samples
  [ 0] ForkJoinPool$WorkQueue.topLevelExec
  [ 1] ForkJoinPool.scan
  [ 2] ForkJoinPool.runWorker
  [ 3] ForkJoinWorkerThread.run

--- 1537560 total (0.03%), 1540 samples
  [ 0] Iterable.forEach
  [ 1] CellsGroup.run
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run

--- 1515102 total (0.03%), 1517 samples
  [ 0] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 1] [unknown_Java]

--- 1506351 total (0.03%), 1501 samples
  [ 0] G1CardSet::occupied() const
  [ 1] G1CollectionSet::iterate(HeapRegionClosure*) const
  [ 2] G1RemSetSamplingTask::execute()
  [ 3] G1ServiceThread::run_task(G1ServiceTask*)
  [ 4] G1ServiceThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread

--- 1446143 total (0.03%), 1449 samples
  [ 0] ArrayList$SubList$1.next
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] Continuation.enterSpecial
  [ 4] Continuation.run
  [ 5] VirtualThread.runContinuation
  [ 6] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 7] ForkJoinTask$RunnableExecuteAction.exec
  [ 8] ForkJoinTask.doExec
  [ 9] ForkJoinPool$WorkQueue.topLevelExec
  [10] ForkJoinPool.scan
  [11] ForkJoinPool.runWorker
  [12] ForkJoinWorkerThread.run

--- 1421799 total (0.03%), 1424 samples
  [ 0] Iterable.forEach
  [ 1] CellsGroup.run
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run

--- 1415533 total (0.03%), 1415 samples
  [ 0] AbstractPipeline.<init>
  [ 1] IntPipeline.<init>
  [ 2] IntPipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$4.<init>
  [ 4] ReferencePipeline.mapToInt
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 1412188 total (0.03%), 1418 samples
  [ 0] ChannelsGrid$$Lambda$63.0x0000000801036978.accept
  [ 1] Dimensions.forEachRowCol
  [ 2] ChannelsGrid.forEachChannel
  [ 3] GameOfLife.calculateFrame
  [ 4] GameOfLife.lambda$calculateFrameBlocking$4
  [ 5] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 6] VirtualThread.run
  [ 7] VirtualThread$VThreadContinuation.lambda$new$0
  [ 8] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 9] Continuation.enter0
  [10] Continuation.enter
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 1390969 total (0.03%), 1399 samples
  [ 0] AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<286822ul, G1BarrierSet>, (AccessInternal::BarrierType)3, 286822ul>::oop_access_barrier(oopDesc*, long)
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] ForkJoinPool.awaitWork
  [ 5] ForkJoinPool.runWorker
  [ 6] ForkJoinWorkerThread.run

--- 1363126 total (0.03%), 1366 samples
  [ 0] ArrayList$SubList$1.next
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] Continuation.enterSpecial
  [ 4] Continuation.run
  [ 5] VirtualThread.runContinuation
  [ 6] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 7] ForkJoinTask$RunnableExecuteAction.exec
  [ 8] ForkJoinTask.doExec
  [ 9] ForkJoinPool$WorkQueue.topLevelExec
  [10] ForkJoinPool.scan
  [11] ForkJoinPool.runWorker
  [12] ForkJoinWorkerThread.run

--- 1353953 total (0.03%), 1335 samples
  [ 0] dequeue_entity_[k]
  [ 1] dequeue_task_fair_[k]
  [ 2] __schedule_[k]
  [ 3] schedule_[k]
  [ 4] futex_wait_queue_[k]
  [ 5] futex_wait_[k]
  [ 6] do_futex_[k]
  [ 7] __x64_sys_futex_[k]
  [ 8] do_syscall_64_[k]
  [ 9] entry_SYSCALL_64_after_hwframe_[k]
  [10] __futex_abstimed_wait_common
  [11] Unsafe.park
  [12] LockSupport.park
  [13] ForkJoinPool.awaitWork
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 1342517 total (0.03%), 1347 samples
  [ 0] ChannelsGrid$$Lambda$63.0x0000000801036978.accept
  [ 1] Dimensions.forEachRowCol
  [ 2] ChannelsGrid.forEachChannel
  [ 3] GameOfLife.calculateFrame
  [ 4] GameOfLife.lambda$calculateFrameBlocking$4
  [ 5] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 6] VirtualThread.run
  [ 7] VirtualThread$VThreadContinuation.lambda$new$0
  [ 8] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 9] Continuation.enter0
  [10] Continuation.enter
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 1340127 total (0.03%), 1342 samples
  [ 0] Iterable.forEach
  [ 1] CellsGroup.run
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run

--- 1331911 total (0.03%), 1335 samples
  [ 0] ArrayList$SubList$1.checkForComodification
  [ 1] ArrayList$SubList$1.next
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 1320143 total (0.03%), 1314 samples
  [ 0] Unsafe_Park
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] ForkJoinPool.awaitWork
  [ 4] ForkJoinPool.runWorker
  [ 5] ForkJoinWorkerThread.run

--- 1295346 total (0.03%), 1297 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 1266240 total (0.03%), 1235 samples
  [ 0] syscall_exit_to_user_mode_[k]
  [ 1] do_syscall_64_[k]
  [ 2] entry_SYSCALL_64_after_hwframe_[k]
  [ 3] __futex_abstimed_wait_common
  [ 4] Unsafe.park
  [ 5] LockSupport.park
  [ 6] ForkJoinPool.awaitWork
  [ 7] ForkJoinPool.runWorker
  [ 8] ForkJoinWorkerThread.run

--- 1260374 total (0.03%), 1262 samples
  [ 0] Unsafe.park
  [ 1] LockSupport.park
  [ 2] ForkJoinPool.awaitWork
  [ 3] ForkJoinPool.runWorker
  [ 4] ForkJoinWorkerThread.run

--- 1219779 total (0.03%), 1222 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$Head.<init>
  [ 3] StreamSupport.stream
  [ 4] Collection.stream
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 1194980 total (0.03%), 1197 samples
  [ 0] FreeListAllocator::reset()
  [ 1] HeapRegionRemSet::clear_locked(bool)
  [ 2] HeapRegion::hr_clear(bool)
  [ 3] G1CollectedHeap::free_region(HeapRegion*, FreeRegionList*)
  [ 4] FreeCSetClosure::do_heap_region(HeapRegion*)
  [ 5] G1CollectedHeap::par_iterate_regions_array(HeapRegionClosure*, HeapRegionClaimer*, unsigned int const*, unsigned long, unsigned int) const
  [ 6] G1PostEvacuateCollectionSetCleanupTask2::FreeCollectionSetTask::do_work(unsigned int)
  [ 7] G1BatchedTask::work(unsigned int)
  [ 8] WorkerThread::run()
  [ 9] Thread::call_run()
  [10] thread_native_entry(Thread*)
  [11] start_thread

--- 1173446 total (0.02%), 1176 samples
  [ 0] Cell$$Lambda$66.0x0000000801036fc8.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$AdaptedRunnableAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 1168241 total (0.02%), 1170 samples
  [ 0] Object.<init>
  [ 1] PipelineHelper.<init>
  [ 2] AbstractPipeline.<init>
  [ 3] ReferencePipeline.<init>
  [ 4] ReferencePipeline$Head.<init>
  [ 5] StreamSupport.stream
  [ 6] Collection.stream
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 1164571 total (0.02%), 1166 samples
  [ 0] Sink$ChainedReference.begin
  [ 1] Sink$ChainedReference.begin
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 1152701 total (0.02%), 1156 samples
  [ 0] ForkJoinPool.scan
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run

--- 1146375 total (0.02%), 1135 samples
  [ 0] psi_group_change_[k]
  [ 1] psi_task_change_[k]
  [ 2] enqueue_task_[k]
  [ 3] ttwu_do_activate_[k]
  [ 4] try_to_wake_up_[k]
  [ 5] wake_up_q_[k]
  [ 6] futex_wake_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] ___pthread_cond_signal
  [12] Unsafe.unpark
  [13] LockSupport.unpark
  [14] ForkJoinPool.signalWork
  [15] ForkJoinPool$WorkQueue.push
  [16] ForkJoinPool.poolSubmit
  [17] ForkJoinPool.execute
  [18] VirtualThread.submitRunContinuation
  [19] VirtualThread.submitRunContinuation
  [20] VirtualThread.unpark
  [21] System$2.unparkVirtualThread
  [22] VirtualThreads.unpark
  [23] LockSupport.unpark
  [24] OneToOneParkingSingleValue.put
  [25] Channel.put
  [26] Cell.calculateNextState
  [27] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [28] Iterable.forEach
  [29] CellsGroup.run
  [30] Continuation.enterSpecial
  [31] Continuation.run
  [32] VirtualThread.runContinuation
  [33] VirtualThread$$Lambda$51.0x000000080103df08.run
  [34] ForkJoinTask$RunnableExecuteAction.exec
  [35] ForkJoinTask.doExec
  [36] ForkJoinPool$WorkQueue.topLevelExec
  [37] ForkJoinPool.scan
  [38] ForkJoinPool.runWorker
  [39] ForkJoinWorkerThread.run

--- 1124272 total (0.02%), 1123 samples
  [ 0] __memmove_sse2_unaligned_erms
  [ 1] long* thaw<Config<(oop_kind)0, G1BarrierSet> >(JavaThread*, int)
  [ 2] Cont thaw
  [ 3] [not_walkable_Java]

--- 1118681 total (0.02%), 1119 samples
  [ 0] G1CollectedHeap::requires_barriers(stackChunkOopDesc*) const
  [ 1] Cont thaw
  [ 2] [not_walkable_Java]

--- 1105859 total (0.02%), 1108 samples
  [ 0] Cell.notifyLiveness
  [ 1] CellsGroup$$Lambda$55.0x0000000801035668.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 1085793 total (0.02%), 1089 samples
  [ 0] System$2.setExtentLocalCache
  [ 1] Continuation.run
  [ 2] VirtualThread.runContinuation
  [ 3] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 4] ForkJoinTask$RunnableExecuteAction.exec
  [ 5] ForkJoinTask.doExec
  [ 6] ForkJoinPool$WorkQueue.topLevelExec
  [ 7] ForkJoinPool.scan
  [ 8] ForkJoinPool.runWorker
  [ 9] ForkJoinWorkerThread.run

--- 1081168 total (0.02%), 1082 samples
  [ 0] CellsGroup$$Lambda$55.0x0000000801035668.accept
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] Continuation.enterSpecial
  [ 4] Continuation.run
  [ 5] VirtualThread.runContinuation
  [ 6] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 7] ForkJoinTask$RunnableExecuteAction.exec
  [ 8] ForkJoinTask.doExec
  [ 9] ForkJoinPool$WorkQueue.topLevelExec
  [10] ForkJoinPool.scan
  [11] ForkJoinPool.runWorker
  [12] ForkJoinWorkerThread.run

--- 1076632 total (0.02%), 1063 samples
  [ 0] enqueue_entity_[k]
  [ 1] enqueue_task_fair_[k]
  [ 2] enqueue_task_[k]
  [ 3] ttwu_do_activate_[k]
  [ 4] try_to_wake_up_[k]
  [ 5] wake_up_q_[k]
  [ 6] futex_wake_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] ___pthread_cond_signal
  [12] Unsafe.unpark
  [13] LockSupport.unpark
  [14] ForkJoinPool.signalWork
  [15] ForkJoinPool$WorkQueue.push
  [16] ForkJoinPool.poolSubmit
  [17] ForkJoinPool.execute
  [18] VirtualThread.submitRunContinuation
  [19] VirtualThread.submitRunContinuation
  [20] VirtualThread.unpark
  [21] System$2.unparkVirtualThread
  [22] VirtualThreads.unpark
  [23] LockSupport.unpark
  [24] OneToOneParkingSingleValue.put
  [25] Channel.put
  [26] Cell.calculateNextState
  [27] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [28] Iterable.forEach
  [29] CellsGroup.run
  [30] Continuation.enterSpecial
  [31] Continuation.run
  [32] VirtualThread.runContinuation
  [33] VirtualThread$$Lambda$51.0x000000080103df08.run
  [34] ForkJoinTask$RunnableExecuteAction.exec
  [35] ForkJoinTask.doExec
  [36] ForkJoinPool$WorkQueue.topLevelExec
  [37] ForkJoinPool.scan
  [38] ForkJoinPool.runWorker
  [39] ForkJoinWorkerThread.run

--- 1060320 total (0.02%), 1045 samples
  [ 0] syscall_exit_to_user_mode_[k]
  [ 1] do_syscall_64_[k]
  [ 2] entry_SYSCALL_64_after_hwframe_[k]
  [ 3] __futex_abstimed_wait_common
  [ 4] Unsafe.park
  [ 5] LockSupport.park
  [ 6] OneToOneParkingSingleValue.take
  [ 7] Channel.take
  [ 8] GameOfLife.calculateFrameBlocking
  [ 9] GameOfLifeBenchmark.benchmark
  [10] GameOfLifeBenchmark_benchmark_jmhTest.benchmark_thrpt_jmhStub
  [11] GameOfLifeBenchmark_benchmark_jmhTest.benchmark_Throughput
  [12] DirectMethodHandle$Holder.invokeSpecial
  [13] LambdaForm$MH.0x000000080102e000.invoke
  [14] LambdaForm$MH.0x000000080102e400.invokeExact_MT
  [15] DirectMethodHandleAccessor.invokeImpl
  [16] DirectMethodHandleAccessor.invoke
  [17] Method.invoke
  [18] BenchmarkHandler$BenchmarkTask.call
  [19] BenchmarkHandler$BenchmarkTask.call
  [20] FutureTask.run
  [21] Executors$RunnableAdapter.call
  [22] FutureTask.run
  [23] ThreadPoolExecutor.runWorker
  [24] ThreadPoolExecutor$Worker.run
  [25] Thread.run

--- 1007140 total (0.02%), 993 samples
  [ 0] enqueue_entity_[k]
  [ 1] enqueue_task_fair_[k]
  [ 2] enqueue_task_[k]
  [ 3] ttwu_do_activate_[k]
  [ 4] try_to_wake_up_[k]
  [ 5] wake_up_q_[k]
  [ 6] futex_wake_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] ___pthread_cond_signal
  [12] Unsafe.unpark
  [13] LockSupport.unpark
  [14] ForkJoinPool.signalWork
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 1003303 total (0.02%), 998 samples
  [ 0] ___pthread_cond_wait
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] ForkJoinPool.awaitWork
  [ 4] ForkJoinPool.runWorker
  [ 5] ForkJoinWorkerThread.run

--- 998676 total (0.02%), 1002 samples
  [ 0] ForkJoinPool.scan
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run

--- 986122 total (0.02%), 987 samples
  [ 0] AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<548964ul, G1BarrierSet>, (AccessInternal::BarrierType)2, 548964ul>::oop_access_barrier(void*)
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] ForkJoinPool.awaitWork
  [ 4] ForkJoinPool.runWorker
  [ 5] ForkJoinWorkerThread.run

--- 974076 total (0.02%), 975 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 967485 total (0.02%), 971 samples
  [ 0] ___pthread_cond_wait
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] ForkJoinPool.awaitWork
  [ 5] ForkJoinPool.runWorker
  [ 6] ForkJoinWorkerThread.run

--- 966706 total (0.02%), 971 samples
  [ 0] __memset_avx2_unaligned_erms
  [ 1] MemAllocator::allocate() const
  [ 2] TypeArrayKlass::multi_allocate(int, int*, JavaThread*)
  [ 3] ObjArrayKlass::multi_allocate(int, int*, JavaThread*)
  [ 4] OptoRuntime::multianewarray2_C(Klass*, int, int, JavaThread*)
  [ 5] GameOfLife.calculateFrame
  [ 6] GameOfLife.lambda$calculateFrameBlocking$4
  [ 7] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 8] VirtualThread.run
  [ 9] VirtualThread$VThreadContinuation.lambda$new$0
  [10] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [11] Continuation.enter0
  [12] Continuation.enter
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 963794 total (0.02%), 950 samples
  [ 0] __calc_delta_[k]
  [ 1] update_curr_[k]
  [ 2] dequeue_entity_[k]
  [ 3] dequeue_task_fair_[k]
  [ 4] __schedule_[k]
  [ 5] schedule_[k]
  [ 6] futex_wait_queue_[k]
  [ 7] futex_wait_[k]
  [ 8] do_futex_[k]
  [ 9] __x64_sys_futex_[k]
  [10] do_syscall_64_[k]
  [11] entry_SYSCALL_64_after_hwframe_[k]
  [12] __futex_abstimed_wait_common
  [13] Unsafe.park
  [14] LockSupport.park
  [15] ForkJoinPool.awaitWork
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 920690 total (0.02%), 909 samples
  [ 0] __condvar_dec_grefs
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] ForkJoinPool.awaitWork
  [ 4] ForkJoinPool.runWorker
  [ 5] ForkJoinWorkerThread.run

--- 916134 total (0.02%), 904 samples
  [ 0] enqueue_task_fair_[k]
  [ 1] enqueue_task_[k]
  [ 2] ttwu_do_activate_[k]
  [ 3] try_to_wake_up_[k]
  [ 4] wake_up_q_[k]
  [ 5] futex_wake_[k]
  [ 6] do_futex_[k]
  [ 7] __x64_sys_futex_[k]
  [ 8] do_syscall_64_[k]
  [ 9] entry_SYSCALL_64_after_hwframe_[k]
  [10] ___pthread_cond_signal
  [11] Unsafe.unpark
  [12] LockSupport.unpark
  [13] ForkJoinPool.signalWork
  [14] ForkJoinPool$WorkQueue.push
  [15] ForkJoinPool.poolSubmit
  [16] ForkJoinPool.execute
  [17] VirtualThread.submitRunContinuation
  [18] VirtualThread.submitRunContinuation
  [19] VirtualThread.unpark
  [20] System$2.unparkVirtualThread
  [21] VirtualThreads.unpark
  [22] LockSupport.unpark
  [23] OneToOneParkingSingleValue.put
  [24] Channel.put
  [25] Cell.calculateNextState
  [26] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [27] Iterable.forEach
  [28] CellsGroup.run
  [29] Continuation.enterSpecial
  [30] Continuation.run
  [31] VirtualThread.runContinuation
  [32] VirtualThread$$Lambda$51.0x000000080103df08.run
  [33] ForkJoinTask$RunnableExecuteAction.exec
  [34] ForkJoinTask.doExec
  [35] ForkJoinPool$WorkQueue.topLevelExec
  [36] ForkJoinPool.scan
  [37] ForkJoinPool.runWorker
  [38] ForkJoinWorkerThread.run

--- 913633 total (0.02%), 918 samples
  [ 0] ForkJoinPool.scan
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run

--- 898574 total (0.02%), 900 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 893599 total (0.02%), 895 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$4$1.<init>
  [ 2] ReferencePipeline$4.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$AdaptedRunnableAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 891786 total (0.02%), 878 samples
  [ 0] iterate_groups_[k]
  [ 1] psi_task_switch_[k]
  [ 2] __schedule_[k]
  [ 3] schedule_[k]
  [ 4] futex_wait_queue_[k]
  [ 5] futex_wait_[k]
  [ 6] do_futex_[k]
  [ 7] __x64_sys_futex_[k]
  [ 8] do_syscall_64_[k]
  [ 9] entry_SYSCALL_64_after_hwframe_[k]
  [10] __futex_abstimed_wait_common
  [11] Unsafe.park
  [12] LockSupport.park
  [13] ForkJoinPool.awaitWork
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 876375 total (0.02%), 878 samples
  [ 0] ForkJoinPool$WorkQueue.push
  [ 1] ForkJoinPool.poolSubmit
  [ 2] ForkJoinPool.lazySubmit
  [ 3] VirtualThread.submitRunContinuation
  [ 4] VirtualThread.lazySubmitRunContinuation
  [ 5] VirtualThread.afterYield
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run

--- 855854 total (0.02%), 841 samples
  [ 0] update_rq_clock_[k]
  [ 1] __schedule_[k]
  [ 2] schedule_[k]
  [ 3] futex_wait_queue_[k]
  [ 4] futex_wait_[k]
  [ 5] do_futex_[k]
  [ 6] __x64_sys_futex_[k]
  [ 7] do_syscall_64_[k]
  [ 8] entry_SYSCALL_64_after_hwframe_[k]
  [ 9] __futex_abstimed_wait_common
  [10] Unsafe.park
  [11] LockSupport.park
  [12] ForkJoinPool.awaitWork
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 849444 total (0.02%), 845 samples
  [ 0] LinkResolver::resolve_continuation_enter(CallInfo&, JavaThread*)
  [ 1] SharedRuntime::find_callee_info_helper(vframeStream&, Bytecodes::Code&, CallInfo&, JavaThread*)
  [ 2] SharedRuntime::find_callee_method(JavaThread*)
  [ 3] SharedRuntime::reresolve_call_site(JavaThread*)
  [ 4] SharedRuntime::handle_wrong_method(JavaThread*)
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 841196 total (0.02%), 829 samples
  [ 0] update_cfs_group_[k]
  [ 1] enqueue_entity_[k]
  [ 2] enqueue_task_fair_[k]
  [ 3] enqueue_task_[k]
  [ 4] ttwu_do_activate_[k]
  [ 5] try_to_wake_up_[k]
  [ 6] wake_up_q_[k]
  [ 7] futex_wake_[k]
  [ 8] do_futex_[k]
  [ 9] __x64_sys_futex_[k]
  [10] do_syscall_64_[k]
  [11] entry_SYSCALL_64_after_hwframe_[k]
  [12] ___pthread_cond_signal
  [13] Unsafe.unpark
  [14] LockSupport.unpark
  [15] ForkJoinPool.signalWork
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run

--- 835470 total (0.02%), 838 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 831063 total (0.02%), 831 samples
  [ 0] Iterable.forEach
  [ 1] CellsGroup.run
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run

--- 830335 total (0.02%), 823 samples
  [ 0] G1Policy::preventive_collection_required(unsigned int)
  [ 1] G1CollectedHeap::attempt_allocation_slow(unsigned long)
  [ 2] G1CollectedHeap::allocate_new_tlab(unsigned long, unsigned long, unsigned long*)
  [ 3] MemAllocator::allocate_inside_tlab_slow(MemAllocator::Allocation&) const
  [ 4] MemAllocator::allocate() const
  [ 5] InstanceKlass::allocate_instance(JavaThread*)
  [ 6] OptoRuntime::new_instance_C(Klass*, JavaThread*)
  [ 7] ReduceOps$5ReducingSink.get
  [ 8] ReduceOps$5ReducingSink.get
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run

--- 819435 total (0.02%), 821 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$66.0x0000000801036fc8.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 809203 total (0.02%), 812 samples
  [ 0] GameOfLife$$Lambda$62.0x0000000801036740.test
  [ 1] ChannelsGrid.lambda$forEachChannel$1
  [ 2] ChannelsGrid$$Lambda$63.0x0000000801036978.accept
  [ 3] Dimensions.forEachRowCol
  [ 4] ChannelsGrid.forEachChannel
  [ 5] GameOfLife.calculateFrame
  [ 6] GameOfLife.lambda$calculateFrameBlocking$4
  [ 7] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 8] VirtualThread.run
  [ 9] VirtualThread$VThreadContinuation.lambda$new$0
  [10] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [11] Continuation.enter0
  [12] Continuation.enter
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 800202 total (0.02%), 787 samples
  [ 0] futex_q_lock_[k]
  [ 1] futex_wait_setup_[k]
  [ 2] futex_wait_[k]
  [ 3] do_futex_[k]
  [ 4] __x64_sys_futex_[k]
  [ 5] do_syscall_64_[k]
  [ 6] entry_SYSCALL_64_after_hwframe_[k]
  [ 7] __futex_abstimed_wait_common
  [ 8] Unsafe.park
  [ 9] LockSupport.park
  [10] ForkJoinPool.awaitWork
  [11] ForkJoinPool.runWorker
  [12] ForkJoinWorkerThread.run

--- 794762 total (0.02%), 779 samples
  [ 0] __entry_text_start_[k]
  [ 1] __futex_abstimed_wait_common
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] ForkJoinPool.awaitWork
  [ 5] ForkJoinPool.runWorker
  [ 6] ForkJoinWorkerThread.run

--- 793304 total (0.02%), 795 samples
  [ 0] ChannelsGrid.lambda$forEachChannel$1
  [ 1] ChannelsGrid$$Lambda$63.0x0000000801036978.accept
  [ 2] Dimensions.forEachRowCol
  [ 3] ChannelsGrid.forEachChannel
  [ 4] GameOfLife.calculateFrame
  [ 5] GameOfLife.lambda$calculateFrameBlocking$4
  [ 6] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 7] VirtualThread.run
  [ 8] VirtualThread$VThreadContinuation.lambda$new$0
  [ 9] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [10] Continuation.enter0
  [11] Continuation.enter
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run

--- 781346 total (0.02%), 780 samples
  [ 0] Thaw<Config<(oop_kind)0, G1BarrierSet> >::thaw_fast(stackChunkOopDesc*)
  [ 1] long* thaw<Config<(oop_kind)0, G1BarrierSet> >(JavaThread*, int)
  [ 2] Cont thaw
  [ 3] [not_walkable_Java]

--- 775900 total (0.02%), 762 samples
  [ 0] update_blocked_averages_[k]
  [ 1] run_rebalance_domains_[k]
  [ 2] __softirqentry_text_start_[k]
  [ 3] __irq_exit_rcu_[k]
  [ 4] sysvec_apic_timer_interrupt_[k]
  [ 5] asm_sysvec_apic_timer_interrupt_[k]
  [ 6] ReduceOps$5ReducingSink.get
  [ 7] ReduceOps$5ReducingSink.get
  [ 8] ReduceOps$ReduceOp.evaluateSequential
  [ 9] AbstractPipeline.evaluate
  [10] IntPipeline.reduce
  [11] IntPipeline.sum
  [12] Cell.calculateNextState
  [13] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [14] Iterable.forEach
  [15] CellsGroup.run
  [16] Continuation.enterSpecial
  [17] Continuation.run
  [18] VirtualThread.runContinuation
  [19] VirtualThread$$Lambda$51.0x000000080103df08.run
  [20] ForkJoinTask$RunnableExecuteAction.exec
  [21] ForkJoinTask.doExec
  [22] ForkJoinPool$WorkQueue.topLevelExec
  [23] ForkJoinPool.scan
  [24] ForkJoinPool.runWorker
  [25] ForkJoinWorkerThread.run

--- 768388 total (0.02%), 771 samples
  [ 0] Integer.intValue
  [ 1] ChannelsGrid.lambda$forEachChannel$1
  [ 2] ChannelsGrid$$Lambda$63.0x0000000801036978.accept
  [ 3] Dimensions.forEachRowCol
  [ 4] ChannelsGrid.forEachChannel
  [ 5] GameOfLife.calculateFrame
  [ 6] GameOfLife.lambda$calculateFrameBlocking$4
  [ 7] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 8] VirtualThread.run
  [ 9] VirtualThread$VThreadContinuation.lambda$new$0
  [10] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [11] Continuation.enter0
  [12] Continuation.enter
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run

--- 767501 total (0.02%), 762 samples
  [ 0] __tls_get_addr
  [ 1] vframeStream::vframeStream(JavaThread*, bool, bool, bool)
  [ 2] SharedRuntime::find_callee_method(JavaThread*)
  [ 3] SharedRuntime::reresolve_call_site(JavaThread*)
  [ 4] SharedRuntime::handle_wrong_method(JavaThread*)
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 763668 total (0.02%), 750 samples
  [ 0] select_task_rq_fair_[k]
  [ 1] try_to_wake_up_[k]
  [ 2] wake_up_q_[k]
  [ 3] futex_wake_[k]
  [ 4] do_futex_[k]
  [ 5] __x64_sys_futex_[k]
  [ 6] do_syscall_64_[k]
  [ 7] entry_SYSCALL_64_after_hwframe_[k]
  [ 8] ___pthread_cond_signal
  [ 9] Unsafe.unpark
  [10] LockSupport.unpark
  [11] ForkJoinPool.signalWork
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run

--- 763244 total (0.02%), 768 samples
  [ 0] TypeArrayKlass::multi_allocate(int, int*, JavaThread*)
  [ 1] OptoRuntime::multianewarray2_C(Klass*, int, int, JavaThread*)
  [ 2] GameOfLife.calculateFrame
  [ 3] GameOfLife.lambda$calculateFrameBlocking$4
  [ 4] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 5] VirtualThread.run
  [ 6] VirtualThread$VThreadContinuation.lambda$new$0
  [ 7] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 8] Continuation.enter0
  [ 9] Continuation.enter
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 762131 total (0.02%), 734 samples
  [ 0] syscall_return_via_sysret_[k]
  [ 1] __futex_abstimed_wait_common
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] ForkJoinPool.awaitWork
  [ 5] ForkJoinPool.runWorker
  [ 6] ForkJoinWorkerThread.run

--- 755867 total (0.02%), 746 samples
  [ 0] psi_group_change_[k]
  [ 1] psi_task_change_[k]
  [ 2] enqueue_task_[k]
  [ 3] ttwu_do_activate_[k]
  [ 4] try_to_wake_up_[k]
  [ 5] wake_up_q_[k]
  [ 6] futex_wake_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] ___pthread_cond_signal
  [12] Unsafe.unpark
  [13] LockSupport.unpark
  [14] ForkJoinPool.signalWork
  [15] ForkJoinPool.scan
  [16] ForkJoinPool.runWorker
  [17] ForkJoinWorkerThread.run

--- 753060 total (0.02%), 741 samples
  [ 0] __memset_avx2_unaligned_erms
  [ 1] MemAllocator::allocate_inside_tlab_slow(MemAllocator::Allocation&) const
  [ 2] MemAllocator::allocate() const
  [ 3] InstanceKlass::allocate_instance(JavaThread*)
  [ 4] OptoRuntime::new_instance_C(Klass*, JavaThread*)
  [ 5] AbstractPipeline.<init>
  [ 6] ReferencePipeline.<init>
  [ 7] ReferencePipeline$Head.<init>
  [ 8] StreamSupport.stream
  [ 9] Collection.stream
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 736186 total (0.02%), 739 samples
  [ 0] Dimensions.forEachRowCol
  [ 1] ChannelsGrid.forEachChannel
  [ 2] TickPerCell.tick
  [ 3] GameOfLife.calculateFrame
  [ 4] GameOfLife.lambda$calculateFrameBlocking$4
  [ 5] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 6] VirtualThread.run
  [ 7] VirtualThread$VThreadContinuation.lambda$new$0
  [ 8] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 9] Continuation.enter0
  [10] Continuation.enter
  [11] Continuation.enterSpecial
  [12] Continuation.run
  [13] VirtualThread.runContinuation
  [14] VirtualThread$$Lambda$51.0x000000080103df08.run
  [15] ForkJoinTask$RunnableExecuteAction.exec
  [16] ForkJoinTask.doExec
  [17] ForkJoinPool$WorkQueue.topLevelExec
  [18] ForkJoinPool.scan
  [19] ForkJoinPool.runWorker
  [20] ForkJoinWorkerThread.run

--- 734485 total (0.02%), 737 samples
  [ 0] ForkJoinPool$WorkQueue.push
  [ 1] ForkJoinPool.poolSubmit
  [ 2] ForkJoinPool.execute
  [ 3] VirtualThread.submitRunContinuation
  [ 4] VirtualThread.submitRunContinuation
  [ 5] VirtualThread.unpark
  [ 6] System$2.unparkVirtualThread
  [ 7] VirtualThreads.unpark
  [ 8] LockSupport.unpark
  [ 9] OneToOneParkingSingleValue.put
  [10] Channel.put
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 733416 total (0.02%), 732 samples
  [ 0] StreamSupport.stream
  [ 1] Collection.stream
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$AdaptedRunnableAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run

--- 724246 total (0.02%), 727 samples
  [ 0] VirtualThread.unpark
  [ 1] System$2.unparkVirtualThread
  [ 2] VirtualThreads.unpark
  [ 3] LockSupport.unpark
  [ 4] OneToOneParkingSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$64.0x0000000801036b98.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 723734 total (0.02%), 725 samples
  [ 0] Dimensions.forEachRowCol
  [ 1] ChannelsGrid.forEachChannel
  [ 2] GameOfLife.calculateFrame
  [ 3] GameOfLife.lambda$calculateFrameBlocking$4
  [ 4] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 5] VirtualThread.run
  [ 6] VirtualThread$VThreadContinuation.lambda$new$0
  [ 7] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [ 8] Continuation.enter0
  [ 9] Continuation.enter
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run

--- 720784 total (0.02%), 722 samples
  [ 0] Channel.take
  [ 1] GameOfLife$$Lambda$62.0x0000000801036740.test
  [ 2] ChannelsGrid.lambda$forEachChannel$1
  [ 3] ChannelsGrid$$Lambda$63.0x0000000801036978.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] GameOfLife.calculateFrame
  [ 7] GameOfLife.lambda$calculateFrameBlocking$4
  [ 8] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 9] VirtualThread.run
  [10] VirtualThread$VThreadContinuation.lambda$new$0
  [11] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [12] Continuation.enter0
  [13] Continuation.enter
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$AdaptedRunnableAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run

--- 711377 total (0.02%), 712 samples
  [ 0] ChannelsGrid$$Lambda$63.0x0000000801036978.accept
  [ 1] [unknown_Java]

--- 706891 total (0.01%), 697 samples
  [ 0] __entry_text_start_[k]
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] ForkJoinPool.awaitWork
  [ 4] ForkJoinPool.runWorker
  [ 5] ForkJoinWorkerThread.run

--- 703441 total (0.01%), 703 samples
  [ 0] Continuation::prepare_thaw(JavaThread*, bool)
  [ 1] Cont thaw
  [ 2] [not_walkable_Java]

--- 691150 total (0.01%), 694 samples
  [ 0] OneToOneParkingSingleValue.take
  [ 1] Channel.take
  [ 2] GameOfLife$$Lambda$62.0x0000000801036740.test
  [ 3] ChannelsGrid.lambda$forEachChannel$1
  [ 4] ChannelsGrid$$Lambda$63.0x0000000801036978.accept
  [ 5] Dimensions.forEachRowCol
  [ 6] ChannelsGrid.forEachChannel
  [ 7] GameOfLife.calculateFrame
  [ 8] GameOfLife.lambda$calculateFrameBlocking$4
  [ 9] GameOfLife$$Lambda$53.0x0000000801035268.run
  [10] VirtualThread.run
  [11] VirtualThread$VThreadContinuation.lambda$new$0
  [12] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [13] Continuation.enter0
  [14] Continuation.enter
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run

--- 687450 total (0.01%), 689 samples
  [ 0] ForkJoinPool.awaitWork
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run

--- 686410 total (0.01%), 665 samples
  [ 0] fpregs_restore_userregs_[k]
  [ 1] exit_to_user_mode_prepare_[k]
  [ 2] syscall_exit_to_user_mode_[k]
  [ 3] do_syscall_64_[k]
  [ 4] entry_SYSCALL_64_after_hwframe_[k]
  [ 5] __futex_abstimed_wait_common
  [ 6] Unsafe.park
  [ 7] LockSupport.park
  [ 8] ForkJoinPool.awaitWork
  [ 9] ForkJoinPool.runWorker
  [10] ForkJoinWorkerThread.run

       total  percent  samples  top
  ----------  -------  -------  ---
  1610247516   34.01%  1609156  ReduceOps$5ReducingSink.get
   596914037   12.61%   599094  OneToOneParkingSingleValue.take
   247470987    5.23%   247914  Sink$ChainedReference.<init>
   239695262    5.06%   239477  StreamSupport.stream
   184363047    3.89%   184819  Cell$$Lambda$66.0x0000000801036fc8.apply
   147177291    3.11%   147350  Cell.lambda$notifyLiveness$0
   133070903    2.81%   133305  OneToOneParkingSingleValue.put
   123154760    2.60%   123211  ReferencePipeline$4.opWrapSink
   120275099    2.54%   120579  Dimensions.forEachRowCol
   119383677    2.52%   119057  Objects.requireNonNull
   114057224    2.41%   113892  AbstractPipeline.<init>
    95761274    2.02%    95843  ReferencePipeline$3.opWrapSink
    93600266    1.98%    93691  ArrayList$ArrayListSpliterator.forEachRemaining
    90867782    1.92%    90913  vtable stub
    63398252    1.34%    63183  ArrayList$ArrayListSpliterator.<init>
    62855306    1.33%    62788  Collection.stream
    61171305    1.29%    61331  ReferencePipeline$3$1.accept
    57231001    1.21%    57281  Sink$ChainedReference.begin
    42923818    0.91%    43100  ReferencePipeline$4$1.accept
    27205696    0.57%    27319  ReduceOps$5ReducingSink.accept
    24666333    0.52%    24678  AbstractPipeline.wrapSink
    22788067    0.48%    22715  ReferencePipeline.map
    21364807    0.45%    21323  Cell.calculateNextState
    20824708    0.44%    20802  PipelineHelper.<init>
    16218000    0.34%    16259  Channel.take
    13878657    0.29%    13937  Cell$$Lambda$69.0x0000000801037640.applyAsInt
    10189070    0.22%    10113  __memset_avx2_unaligned_erms
     9926366    0.21%     9765  vframeStream::vframeStream(JavaThread*, bool, bool, bool)
     9544696    0.20%     9528  IntPipeline.<init>
     9195194    0.19%     9070  psi_group_change_[k]
     8334460    0.18%     8338  Iterable.forEach
     7417111    0.16%     7317  update_cfs_group_[k]
     7281262    0.15%     7294  Channel.put
     7206595    0.15%     7095  __update_load_avg_cfs_rq_[k]
     6684453    0.14%     6688  ArrayList$SubList$1.next
     6591354    0.14%     6599  StreamOpFlag.fromCharacteristics
     5932344    0.13%     5848  update_load_avg_[k]
     5762174    0.12%     5777  ChannelsGrid$$Lambda$63.0x0000000801036978.accept
     5103177    0.11%     5030  update_curr_[k]
     5040587    0.11%     4925  InstanceKlass::find_method_index(Array<Method*> const*, Symbol const*, Symbol const*, Klass::OverpassLookupMode, Klass::StaticLookupMode, Klass::PrivateLookupMode) [clone .constprop.0]
     5000118    0.11%     5014  ForkJoinPool.scan
     4873794    0.10%     4786  update_blocked_averages_[k]
     4841085    0.10%     4774  __update_load_avg_se_[k]
     4504967    0.10%     4525  MemAllocator::allocate() const
     4142286    0.09%     4148  CellsGroup$$Lambda$64.0x0000000801036b98.accept
     3990841    0.08%     3941  reweight_entity_[k]
     3983057    0.08%     3994  Sink$ChainedReference.end
     3850513    0.08%     3786  syscall_exit_to_user_mode_[k]
     3461473    0.07%     3469  ArrayList.elementAt
     3367846    0.07%     3327  enqueue_entity_[k]
     3322692    0.07%     3340  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<1335398ul, G1BarrierSet>, (AccessInternal::BarrierType)1, 1335398ul>::oop_access_barrier(oopDesc*, long, oopDesc*)
     3223746    0.07%     3233  ChannelsGrid.getChannel
     2896288    0.06%     2898  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<286822ul, G1BarrierSet>, (AccessInternal::BarrierType)1, 286822ul>::oop_access_barrier(oopDesc*, long, oopDesc*)
     2850065    0.06%     2857  ForkJoinPool$WorkQueue.topLevelExec
     2713810    0.06%     2711  __tls_get_addr
     2691983    0.06%     2649  __entry_text_start_[k]
     2661844    0.06%     2674  TypeArrayKlass::multi_allocate(int, int*, JavaThread*)
     2633398    0.06%     2643  ForkJoinPool$WorkQueue.push
     2530631    0.05%     2494  __schedule_[k]
     2379984    0.05%     2373  ReferencePipeline.mapToInt
     2350726    0.05%     2360  ObjArrayAllocator::initialize(HeapWordImpl**) const
     2320588    0.05%     2291  enqueue_task_fair_[k]
     2253272    0.05%     2257  Cell.notifyLiveness
     2235821    0.05%     2221  G1CardSet::occupied() const
     2130068    0.04%     2132  AbstractPipeline.copyInto
     2108058    0.04%     2113  ForkJoinPool.awaitWork
     2097678    0.04%     2103  CellsGroup$$Lambda$55.0x0000000801035668.accept
     2076390    0.04%     2042  check_preemption_disabled_[k]
     2060893    0.04%     2059  ___pthread_cond_wait
     2046792    0.04%     2042  Parker::park(bool, long)
     2039716    0.04%     2037  ArrayList$SubList$1.checkForComodification
     1991026    0.04%     1964  cpuacct_charge_[k]
     1970005    0.04%     1942  dequeue_task_fair_[k]
     1960034    0.04%     1974  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<286822ul, G1BarrierSet>, (AccessInternal::BarrierType)3, 286822ul>::oop_access_barrier(oopDesc*, long)
     1953432    0.04%     1926  _raw_spin_lock_[k]
     1900181    0.04%     1911  ObjArrayKlass::multi_allocate(int, int*, JavaThread*)
     1843785    0.04%     1838  Unsafe_Park
     1840580    0.04%     1819  select_task_rq_fair_[k]
     1838296    0.04%     1838  G1CollectedHeap::requires_barriers(stackChunkOopDesc*) const
     1763776    0.04%     1768  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<548964ul, G1BarrierSet>, (AccessInternal::BarrierType)2, 548964ul>::oop_access_barrier(void*)
     1740100    0.04%     1740  __memmove_sse2_unaligned_erms
     1713151    0.04%     1718  ForkJoinTask.doExec
     1672286    0.04%     1644  futex_wake_[k]
     1620820    0.03%     1624  ChannelsGrid.lambda$forEachChannel$1
     1616640    0.03%     1620  Unsafe.park
     1607624    0.03%     1610  Object.<init>
     1607077    0.03%     1611  VirtualThread.unmount
     1569175    0.03%     1548  __calc_delta_[k]
     1520032    0.03%     1496  update_rq_clock_[k]
     1444534    0.03%     1425  dequeue_entity_[k]
     1418422    0.03%     1424  VirtualThread.unpark
     1400331    0.03%     1401  int freeze<Config<(oop_kind)0, G1BarrierSet> >(JavaThread*, long*)
     1338519    0.03%     1319  native_sched_clock_[k]
     1338508    0.03%     1327  G1Policy::preventive_collection_required(unsigned int)
     1335929    0.03%     1338  Continuation.yield0
     1325285    0.03%     1299  rb_next_[k]
     1321523    0.03%     1325  System$2.setExtentLocalCache
     1307284    0.03%     1311  pthread_mutex_trylock@@GLIBC_2.34
     1279381    0.03%     1268  __condvar_dec_grefs
     1194980    0.03%     1197  FreeListAllocator::reset()
     1187748    0.03%     1170  update_min_vruntime_[k]
     1170581    0.02%     1149  rcu_sched_clock_irq_[k]
     1152159    0.02%     1155  VirtualThread.runContinuation
     1090449    0.02%     1086  LinkResolver::resolve_continuation_enter(CallInfo&, JavaThread*)
     1079152    0.02%     1063  futex_q_lock_[k]
     1059591    0.02%     1050  available_idle_cpu_[k]
     1032851    0.02%      992  fpregs_restore_userregs_[k]
     1006137    0.02%      987  __hrtimer_run_queues_[k]
     1002259    0.02%      992  psi_task_change_[k]
      989944    0.02%      994  MemAllocator::Allocation::notify_allocation_jvmti_sampler()
      988673    0.02%      992  Integer.intValue
      984143    0.02%      970  preempt_count_add_[k]
      967186    0.02%      970  GameOfLife$$Lambda$62.0x0000000801036740.test
      955303    0.02%      941  iterate_groups_[k]
      942663    0.02%      908  syscall_return_via_sysret_[k]
      938085    0.02%      939  Continuation::prepare_thaw(JavaThread*, bool)
      931591    0.02%      928  __GI___pthread_mutex_lock
      921882    0.02%      921  GameOfLifeBenchmark_benchmark_jmhTest.benchmark_thrpt_jmhStub
      911061    0.02%      905  HeapRegionManager::allocate_free_region(HeapRegionType, unsigned int)
      884412    0.02%      856  restore_fpregs_from_fpstate_[k]
      875167    0.02%      862  try_to_wake_up_[k]
      874933    0.02%      878  SafepointMechanism::update_poll_values(JavaThread*)
      866058    0.02%      870  Klass::check_array_allocation_length(int, int, JavaThread*)
      850284    0.02%      839  update_irq_load_avg_[k]
      845419    0.02%      831  timerqueue_add_[k]
      842472    0.02%      847  java_lang_Thread::set_thread_status(oopDesc*, JavaThreadStatus)
      802278    0.02%      801  Thaw<Config<(oop_kind)0, G1BarrierSet> >::thaw_fast(stackChunkOopDesc*)
      800237    0.02%      798  __pthread_mutex_unlock_usercnt
      792865    0.02%      791  G1Analytics::predict_scan_card_num(unsigned long, bool) const
      777984    0.02%      778  AbsSeq::dsd() const
      762473    0.02%      764  MemAllocator::Allocation::check_out_of_memory()
      762280    0.02%      767  ___pthread_cond_signal
      760403    0.02%      750  futex_wake_mark_[k]
      737823    0.02%      736  VirtualThread.submitRunContinuation
      720941    0.02%      720  LinkResolver::check_method_loader_constraints(LinkInfo const&, methodHandle const&, char const*, JavaThread*)
      716629    0.02%      717  long* thaw<Config<(oop_kind)0, G1BarrierSet> >(JavaThread*, int)
      707055    0.01%      695  __softirqentry_text_start_[k]
      703880    0.01%      698  GameOfLife.calculateFrameBlocking
      700735    0.01%      695  G1MonitoringSupport::update_eden_size()
      690790    0.01%      677  _raw_spin_lock_irqsave_[k]
      682191    0.01%      680  oopDesc::address_field(int) const
      680619    0.01%      680  G1FromCardCache::clear(unsigned int)
      678323    0.01%      668  AbsSeq::davg() const
      671867    0.01%      665  G1Allocator::unsafe_max_tlab_alloc()
      671763    0.01%      672  update_register_map1(ImmutableOopMap const*, frame const*, RegisterMap*)
      668540    0.01%      657  native_read_msr_[k]
      661549    0.01%      621  __get_user_8_[k]
      652207    0.01%      644  __perf_event_task_sched_out_[k]
      647423    0.01%      638  resched_curr_[k]
      632022    0.01%      634  DirectMethodHandle$Holder.newInvokeSpecial
      627454    0.01%      616  preempt_count_sub_[k]
      624859    0.01%      617  __get_user_nocheck_4_[k]
      624025    0.01%      622  InstanceKlass::allocate_instance(JavaThread*)
      618259    0.01%      612  __pthread_mutex_cond_lock
      615564    0.01%      608  G1CollectedHeap::attempt_allocation_slow(unsigned long)
      601655    0.01%      593  __cgroup_account_cputime_[k]
      598908    0.01%      601  MemAllocator::Allocation::notify_allocation_jfr_sampler()
      598607    0.01%      590  psi_task_switch_[k]
      595461    0.01%      594  __futex_abstimed_wait_common
      595294    0.01%      593  __tls_get_addr@plt
      594270    0.01%      595  FreezeBase::freeze_fast_copy(stackChunkOopDesc*, int)
      591486    0.01%      583  task_tick_fair_[k]
      579334    0.01%      579  CardTableBarrierSet::on_slowpath_allocation_exit(JavaThread*, oopDesc*)
      576615    0.01%      566  timekeeping_advance_[k]
      574673    0.01%      576  VirtualThread.compareAndSetState
      571690    0.01%      568  G1CardSet::clear()
      568719    0.01%      571  OptoRuntime::multianewarray2_C(Klass*, int, int, JavaThread*)
      562328    0.01%      565  G1RemSetScanState::G1ClearCardTableTask::do_work(unsigned int)
      556182    0.01%      558  ForkJoinPool.signalWork
      555644    0.01%      559  VirtualThread.park
      552598    0.01%      547  update_sd_lb_stats.constprop.0_[k]
      551051    0.01%      545  newidle_balance_[k]
      547916    0.01%      539  asm_sysvec_apic_timer_interrupt_[k]
      547035    0.01%      546  ArrayList.forEach
      542820    0.01%      541  JavaThread::threadObj() const
      541740    0.01%      543  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<544868ul, G1BarrierSet>, (AccessInternal::BarrierType)2, 544868ul>::oop_access_barrier(void*)
      537123    0.01%      537  OptoRuntime::new_instance_C(Klass*, JavaThread*)
      533646    0.01%      529  Unsafe.unpark
      532267    0.01%      494  exit_to_user_mode_prepare_[k]
      525939    0.01%      520  rebalance_domains_[k]
      521734    0.01%      525  native_write_msr_[k]
      514067    0.01%      505  irq_work_tick_[k]
      513673    0.01%      515  __vdso_clock_gettime
      510154    0.01%      508  ObjAllocator::initialize(HeapWordImpl**) const
      504391    0.01%      504  Unsafe_Unpark
      503029    0.01%      502  JfrObjectAllocationSample::send_event(Klass const*, unsigned long, bool, Thread*)
      500612    0.01%      498  InstanceKlass::uncached_lookup_method(Symbol const*, Symbol const*, Klass::OverpassLookupMode, Klass::PrivateLookupMode) const
      496728    0.01%      496  os::vm_page_size()
      496445    0.01%      497  G1Analytics::predict_card_merge_time_ms(unsigned long, bool) const
      484914    0.01%      483  G1SegmentedArray::num_segments() const
      457920    0.01%      446  futex_wait_[k]
      455018    0.01%      454  LinkResolver::lookup_method_in_klasses(LinkInfo const&, bool, bool)
      448139    0.01%      450  ForkJoinPool.compareAndExchangeCtl
      443365    0.01%      443  MemAllocator::allocate_inside_tlab_slow(MemAllocator::Allocation&) const
      441513    0.01%      439  G1YoungRemSetSamplingClosure::do_heap_region(HeapRegion*)
      437934    0.01%      439  __memcpy_sse2_unaligned
      437632    0.01%      439  LockSupport.park
      435240    0.01%      436  ForkJoinTask$AdaptedRunnableAction.<init>
      432625    0.01%      429  ThreadLocalStorage::is_initialized()
      431544    0.01%      430  ThreadLocalAllocBuffer::retire_before_allocation()
