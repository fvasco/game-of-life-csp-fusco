--- Execution profile ---
Total samples       : 5842297
not_walkable_not_Java: 6 (0.00%)
unknown_Java        : 21460 (0.37%)
not_walkable_Java   : 187 (0.00%)
deoptimization      : 2201 (0.04%)
skipped             : 568 (0.01%)

--- 1164387286 total (19.93%), 1163920 samples
  [ 0] Unsafe.park
  [ 1] LockSupport.park
  [ 2] AbstractQueuedSynchronizer$ConditionNode.block
  [ 3] ForkJoinPool.unmanagedBlock
  [ 4] ForkJoinPool.managedBlock
  [ 5] AbstractQueuedSynchronizer$ConditionObject.await
  [ 6] LockedSingleValue.take
  [ 7] Channel.take
  [ 8] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 9] ReferencePipeline$3$1.accept
  [10] ArrayList$ArrayListSpliterator.forEachRemaining
  [11] AbstractPipeline.copyInto
  [12] AbstractPipeline.wrapAndCopyInto
  [13] ReduceOps$ReduceOp.evaluateSequential
  [14] AbstractPipeline.evaluate
  [15] IntPipeline.reduce
  [16] IntPipeline.sum
  [17] Cell.calculateNextState
  [18] Cell.run
  [19] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [20] ThreadPoolExecutor.runWorker
  [21] ThreadPoolExecutor$Worker.run
  [22] Thread.run

--- 879747028 total (15.06%), 876415 samples
  [ 0] Unsafe.park
  [ 1] LockSupport.park
  [ 2] AbstractQueuedSynchronizer$ConditionNode.block
  [ 3] ForkJoinPool.unmanagedBlock
  [ 4] ForkJoinPool.managedBlock
  [ 5] AbstractQueuedSynchronizer$ConditionObject.await
  [ 6] LockedSingleValue.take
  [ 7] Channel.take
  [ 8] TickPerCell.waitTick
  [ 9] Cell.notifyLiveness
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 593785143 total (10.16%), 593801 samples
  [ 0] Unsafe.unpark
  [ 1] LockSupport.unpark
  [ 2] AbstractQueuedSynchronizer.signalNext
  [ 3] AbstractQueuedSynchronizer.release
  [ 4] ReentrantLock.unlock
  [ 5] LockedSingleValue.put
  [ 6] Channel.put
  [ 7] TickPerCell.lambda$tick$0
  [ 8] TickPerCell$$Lambda$47.0x0000000801035678.accept
  [ 9] ChannelsGrid.lambda$forEachChannel$0
  [10] ChannelsGrid$$Lambda$48.0x0000000801035890.accept
  [11] Dimensions.forEachRowCol
  [12] ChannelsGrid.forEachChannel
  [13] TickPerCell.tick
  [14] GameOfLife.calculateFrame
  [15] GameOfLife.lambda$calculateFrameBlocking$4
  [16] GameOfLife$$Lambda$46.0x0000000801035468.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

--- 348183065 total (5.96%), 349339 samples
  [ 0] Unsafe.unpark
  [ 1] LockSupport.unpark
  [ 2] AbstractQueuedSynchronizer.signalNext
  [ 3] AbstractQueuedSynchronizer.release
  [ 4] ReentrantLock.unlock
  [ 5] LockedSingleValue.put
  [ 6] Channel.put
  [ 7] Cell.lambda$notifyLiveness$0
  [ 8] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 9] ArrayList.forEach
  [10] Cell.notifyLiveness
  [11] Cell.run
  [12] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 174618140 total (2.99%), 175101 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] Cell.run
  [ 5] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 75377912 total (1.29%), 75585 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] Cell.run
  [ 8] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 73285607 total (1.25%), 73486 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] Cell.run
  [ 5] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 60170918 total (1.03%), 60364 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] Cell.run
  [17] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 52735587 total (0.90%), 53076 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 43858307 total (0.75%), 43733 samples
  [ 0] Unsafe_Park
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] Cell$$Lambda$61.0x0000000801036dd0.apply
  [10] ReferencePipeline$3$1.accept
  [11] ArrayList$ArrayListSpliterator.forEachRemaining
  [12] AbstractPipeline.copyInto
  [13] AbstractPipeline.wrapAndCopyInto
  [14] ReduceOps$ReduceOp.evaluateSequential
  [15] AbstractPipeline.evaluate
  [16] IntPipeline.reduce
  [17] IntPipeline.sum
  [18] Cell.calculateNextState
  [19] Cell.run
  [20] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [21] ThreadPoolExecutor.runWorker
  [22] ThreadPoolExecutor$Worker.run
  [23] Thread.run

--- 42661729 total (0.73%), 42172 samples
  [ 0] restore_fpregs_from_fpstate_[k]
  [ 1] fpregs_restore_userregs_[k]
  [ 2] exit_to_user_mode_prepare_[k]
  [ 3] syscall_exit_to_user_mode_[k]
  [ 4] do_syscall_64_[k]
  [ 5] entry_SYSCALL_64_after_hwframe_[k]
  [ 6] __futex_abstimed_wait_common
  [ 7] Unsafe.park
  [ 8] LockSupport.park
  [ 9] AbstractQueuedSynchronizer$ConditionNode.block
  [10] ForkJoinPool.unmanagedBlock
  [11] ForkJoinPool.managedBlock
  [12] AbstractQueuedSynchronizer$ConditionObject.await
  [13] LockedSingleValue.take
  [14] Channel.take
  [15] Cell$$Lambda$61.0x0000000801036dd0.apply
  [16] ReferencePipeline$3$1.accept
  [17] ArrayList$ArrayListSpliterator.forEachRemaining
  [18] AbstractPipeline.copyInto
  [19] AbstractPipeline.wrapAndCopyInto
  [20] ReduceOps$ReduceOp.evaluateSequential
  [21] AbstractPipeline.evaluate
  [22] IntPipeline.reduce
  [23] IntPipeline.sum
  [24] Cell.calculateNextState
  [25] Cell.run
  [26] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [27] ThreadPoolExecutor.runWorker
  [28] ThreadPoolExecutor$Worker.run
  [29] Thread.run

--- 41626273 total (0.71%), 41003 samples
  [ 0] restore_fpregs_from_fpstate_[k]
  [ 1] fpregs_restore_userregs_[k]
  [ 2] exit_to_user_mode_prepare_[k]
  [ 3] syscall_exit_to_user_mode_[k]
  [ 4] do_syscall_64_[k]
  [ 5] entry_SYSCALL_64_after_hwframe_[k]
  [ 6] __futex_abstimed_wait_common
  [ 7] Unsafe.park
  [ 8] LockSupport.park
  [ 9] AbstractQueuedSynchronizer$ConditionNode.block
  [10] ForkJoinPool.unmanagedBlock
  [11] ForkJoinPool.managedBlock
  [12] AbstractQueuedSynchronizer$ConditionObject.await
  [13] LockedSingleValue.take
  [14] Channel.take
  [15] TickPerCell.waitTick
  [16] Cell.notifyLiveness
  [17] Cell.run
  [18] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [19] ThreadPoolExecutor.runWorker
  [20] ThreadPoolExecutor$Worker.run
  [21] Thread.run

--- 35655576 total (0.61%), 35482 samples
  [ 0] Unsafe_Park
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] TickPerCell.waitTick
  [10] Cell.notifyLiveness
  [11] Cell.run
  [12] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 35249733 total (0.60%), 35342 samples
  [ 0] AbstractQueuedSynchronizer.signalNext
  [ 1] AbstractQueuedSynchronizer.release
  [ 2] ReentrantLock.unlock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] Cell.run
  [16] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

--- 31835722 total (0.54%), 31847 samples
  [ 0] Parker::park(bool, long)
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] Cell$$Lambda$61.0x0000000801036dd0.apply
  [11] ReferencePipeline$3$1.accept
  [12] ArrayList$ArrayListSpliterator.forEachRemaining
  [13] AbstractPipeline.copyInto
  [14] AbstractPipeline.wrapAndCopyInto
  [15] ReduceOps$ReduceOp.evaluateSequential
  [16] AbstractPipeline.evaluate
  [17] IntPipeline.reduce
  [18] IntPipeline.sum
  [19] Cell.calculateNextState
  [20] Cell.run
  [21] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 30274682 total (0.52%), 30209 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 1] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$47.0x0000000801035678.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$48.0x0000000801035890.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$46.0x0000000801035468.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 28072673 total (0.48%), 28001 samples
  [ 0] Unsafe.park
  [ 1] LockSupport.park
  [ 2] AbstractQueuedSynchronizer$ConditionNode.block
  [ 3] ForkJoinPool.unmanagedBlock
  [ 4] ForkJoinPool.managedBlock
  [ 5] AbstractQueuedSynchronizer$ConditionObject.await
  [ 6] LockedSingleValue.take
  [ 7] Channel.take
  [ 8] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 9] ReferencePipeline$3$1.accept
  [10] ArrayList$ArrayListSpliterator.forEachRemaining
  [11] AbstractPipeline.copyInto
  [12] AbstractPipeline.wrapAndCopyInto
  [13] ReduceOps$ReduceOp.evaluateSequential
  [14] AbstractPipeline.evaluate
  [15] IntPipeline.reduce
  [16] IntPipeline.sum
  [17] Cell.calculateNextState
  [18] Cell.run
  [19] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [20] ThreadPoolExecutor.runWorker
  [21] ThreadPoolExecutor$Worker.run
  [22] Thread.run

--- 27280430 total (0.47%), 27143 samples
  [ 0] __condvar_dec_grefs
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] TickPerCell.waitTick
  [10] Cell.notifyLiveness
  [11] Cell.run
  [12] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 26432841 total (0.45%), 26312 samples
  [ 0] Parker::park(bool, long)
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] TickPerCell.waitTick
  [11] Cell.notifyLiveness
  [12] Cell.run
  [13] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 26111412 total (0.45%), 26181 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.tryAcquire
  [ 2] AbstractQueuedSynchronizer.acquire
  [ 3] AbstractQueuedSynchronizer$ConditionObject.await
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] Cell.run
  [17] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 25860738 total (0.44%), 25979 samples
  [ 0] futex_wake_[k]
  [ 1] do_futex_[k]
  [ 2] __x64_sys_futex_[k]
  [ 3] do_syscall_64_[k]
  [ 4] entry_SYSCALL_64_after_hwframe_[k]
  [ 5] ___pthread_cond_signal
  [ 6] Unsafe.unpark
  [ 7] LockSupport.unpark
  [ 8] AbstractQueuedSynchronizer.signalNext
  [ 9] AbstractQueuedSynchronizer.release
  [10] ReentrantLock.unlock
  [11] LockedSingleValue.put
  [12] Channel.put
  [13] Cell.lambda$notifyLiveness$0
  [14] Cell$$Lambda$51.0x0000000801035cd0.accept
  [15] ArrayList.forEach
  [16] Cell.notifyLiveness
  [17] Cell.run
  [18] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [19] ThreadPoolExecutor.runWorker
  [20] ThreadPoolExecutor$Worker.run
  [21] Thread.run

--- 25640976 total (0.44%), 25721 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] Cell.run
  [17] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 25086028 total (0.43%), 25156 samples
  [ 0] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 24861959 total (0.43%), 24861 samples
  [ 0] TickPerCell.lambda$tick$0
  [ 1] TickPerCell$$Lambda$47.0x0000000801035678.accept
  [ 2] ChannelsGrid.lambda$forEachChannel$0
  [ 3] ChannelsGrid$$Lambda$48.0x0000000801035890.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] TickPerCell.tick
  [ 7] GameOfLife.calculateFrame
  [ 8] GameOfLife.lambda$calculateFrameBlocking$4
  [ 9] GameOfLife$$Lambda$46.0x0000000801035468.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 24812083 total (0.42%), 24795 samples
  [ 0] StreamSupport.stream
  [ 1] Collection.stream
  [ 2] Cell.calculateNextState
  [ 3] Cell.run
  [ 4] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 5] ThreadPoolExecutor.runWorker
  [ 6] ThreadPoolExecutor$Worker.run
  [ 7] Thread.run

--- 24687901 total (0.42%), 24786 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] Cell.run
  [ 8] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 22431922 total (0.38%), 22576 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 22023378 total (0.38%), 22069 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 21474146 total (0.37%), 21506 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 21340324 total (0.37%), 21278 samples
  [ 0] __condvar_dec_grefs
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] Cell$$Lambda$61.0x0000000801036dd0.apply
  [10] ReferencePipeline$3$1.accept
  [11] ArrayList$ArrayListSpliterator.forEachRemaining
  [12] AbstractPipeline.copyInto
  [13] AbstractPipeline.wrapAndCopyInto
  [14] ReduceOps$ReduceOp.evaluateSequential
  [15] AbstractPipeline.evaluate
  [16] IntPipeline.reduce
  [17] IntPipeline.sum
  [18] Cell.calculateNextState
  [19] Cell.run
  [20] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [21] ThreadPoolExecutor.runWorker
  [22] ThreadPoolExecutor$Worker.run
  [23] Thread.run

--- 21161610 total (0.36%), 21168 samples
  [ 0] AbstractQueuedSynchronizer.enqueue
  [ 1] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 2] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 3] LockedSingleValue.put
  [ 4] Channel.put
  [ 5] TickPerCell.lambda$tick$0
  [ 6] TickPerCell$$Lambda$47.0x0000000801035678.accept
  [ 7] ChannelsGrid.lambda$forEachChannel$0
  [ 8] ChannelsGrid$$Lambda$48.0x0000000801035890.accept
  [ 9] Dimensions.forEachRowCol
  [10] ChannelsGrid.forEachChannel
  [11] TickPerCell.tick
  [12] GameOfLife.calculateFrame
  [13] GameOfLife.lambda$calculateFrameBlocking$4
  [14] GameOfLife$$Lambda$46.0x0000000801035468.run
  [15] ThreadPoolExecutor.runWorker
  [16] ThreadPoolExecutor$Worker.run
  [17] Thread.run

--- 21123732 total (0.36%), 21130 samples
  [ 0] AbstractQueuedSynchronizer.acquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 20927015 total (0.36%), 20933 samples
  [ 0] syscall_exit_to_user_mode_[k]
  [ 1] do_syscall_64_[k]
  [ 2] entry_SYSCALL_64_after_hwframe_[k]
  [ 3] __futex_abstimed_wait_common
  [ 4] Unsafe.park
  [ 5] LockSupport.park
  [ 6] AbstractQueuedSynchronizer$ConditionNode.block
  [ 7] ForkJoinPool.unmanagedBlock
  [ 8] ForkJoinPool.managedBlock
  [ 9] AbstractQueuedSynchronizer$ConditionObject.await
  [10] LockedSingleValue.take
  [11] Channel.take
  [12] Cell$$Lambda$61.0x0000000801036dd0.apply
  [13] ReferencePipeline$3$1.accept
  [14] ArrayList$ArrayListSpliterator.forEachRemaining
  [15] AbstractPipeline.copyInto
  [16] AbstractPipeline.wrapAndCopyInto
  [17] ReduceOps$ReduceOp.evaluateSequential
  [18] AbstractPipeline.evaluate
  [19] IntPipeline.reduce
  [20] IntPipeline.sum
  [21] Cell.calculateNextState
  [22] Cell.run
  [23] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [24] ThreadPoolExecutor.runWorker
  [25] ThreadPoolExecutor$Worker.run
  [26] Thread.run

--- 20244855 total (0.35%), 20188 samples
  [ 0] Channel.take
  [ 1] GameOfLife$$Lambda$116.0x0000000801080658.test
  [ 2] ChannelsGrid.lambda$forEachChannel$1
  [ 3] ChannelsGrid$$Lambda$117.0x0000000801080890.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] GameOfLife.calculateFrame
  [ 7] GameOfLife.lambda$calculateFrameBlocking$4
  [ 8] GameOfLife$$Lambda$46.0x0000000801035468.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 20199519 total (0.35%), 20076 samples
  [ 0] __get_user_8_[k]
  [ 1] __rseq_handle_notify_resume_[k]
  [ 2] exit_to_user_mode_prepare_[k]
  [ 3] syscall_exit_to_user_mode_[k]
  [ 4] do_syscall_64_[k]
  [ 5] entry_SYSCALL_64_after_hwframe_[k]
  [ 6] __futex_abstimed_wait_common
  [ 7] Unsafe.park
  [ 8] LockSupport.park
  [ 9] AbstractQueuedSynchronizer$ConditionNode.block
  [10] ForkJoinPool.unmanagedBlock
  [11] ForkJoinPool.managedBlock
  [12] AbstractQueuedSynchronizer$ConditionObject.await
  [13] LockedSingleValue.take
  [14] Channel.take
  [15] TickPerCell.waitTick
  [16] Cell.notifyLiveness
  [17] Cell.run
  [18] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [19] ThreadPoolExecutor.runWorker
  [20] ThreadPoolExecutor$Worker.run
  [21] Thread.run

--- 19522798 total (0.33%), 19475 samples
  [ 0] AbstractQueuedSynchronizer.acquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] Cell.run
  [ 7] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 19367145 total (0.33%), 19378 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] TickPerCell.lambda$tick$0
  [ 7] TickPerCell$$Lambda$47.0x0000000801035678.accept
  [ 8] ChannelsGrid.lambda$forEachChannel$0
  [ 9] ChannelsGrid$$Lambda$48.0x0000000801035890.accept
  [10] Dimensions.forEachRowCol
  [11] ChannelsGrid.forEachChannel
  [12] TickPerCell.tick
  [13] GameOfLife.calculateFrame
  [14] GameOfLife.lambda$calculateFrameBlocking$4
  [15] GameOfLife$$Lambda$46.0x0000000801035468.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 18862519 total (0.32%), 18735 samples
  [ 0] AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<286822ul, G1BarrierSet>, (AccessInternal::BarrierType)3, 286822ul>::oop_access_barrier(oopDesc*, long)
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] Cell$$Lambda$61.0x0000000801036dd0.apply
  [11] ReferencePipeline$3$1.accept
  [12] ArrayList$ArrayListSpliterator.forEachRemaining
  [13] AbstractPipeline.copyInto
  [14] AbstractPipeline.wrapAndCopyInto
  [15] ReduceOps$ReduceOp.evaluateSequential
  [16] AbstractPipeline.evaluate
  [17] IntPipeline.reduce
  [18] IntPipeline.sum
  [19] Cell.calculateNextState
  [20] Cell.run
  [21] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 18471404 total (0.32%), 18519 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.tryAcquire
  [ 2] AbstractQueuedSynchronizer.acquire
  [ 3] AbstractQueuedSynchronizer$ConditionObject.await
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] TickPerCell.waitTick
  [ 7] Cell.notifyLiveness
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 18425773 total (0.32%), 18476 samples
  [ 0] AbstractOwnableSynchronizer.setExclusiveOwnerThread
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] TickPerCell.waitTick
  [ 7] Cell.notifyLiveness
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 18152677 total (0.31%), 18200 samples
  [ 0] futex_wake_[k]
  [ 1] do_futex_[k]
  [ 2] __x64_sys_futex_[k]
  [ 3] do_syscall_64_[k]
  [ 4] entry_SYSCALL_64_after_hwframe_[k]
  [ 5] __lll_lock_wake
  [ 6] Unsafe_Park
  [ 7] Unsafe.park
  [ 8] LockSupport.park
  [ 9] AbstractQueuedSynchronizer$ConditionNode.block
  [10] ForkJoinPool.unmanagedBlock
  [11] ForkJoinPool.managedBlock
  [12] AbstractQueuedSynchronizer$ConditionObject.await
  [13] LockedSingleValue.take
  [14] Channel.take
  [15] Cell$$Lambda$61.0x0000000801036dd0.apply
  [16] ReferencePipeline$3$1.accept
  [17] ArrayList$ArrayListSpliterator.forEachRemaining
  [18] AbstractPipeline.copyInto
  [19] AbstractPipeline.wrapAndCopyInto
  [20] ReduceOps$ReduceOp.evaluateSequential
  [21] AbstractPipeline.evaluate
  [22] IntPipeline.reduce
  [23] IntPipeline.sum
  [24] Cell.calculateNextState
  [25] Cell.run
  [26] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [27] ThreadPoolExecutor.runWorker
  [28] ThreadPoolExecutor$Worker.run
  [29] Thread.run

--- 18046099 total (0.31%), 18026 samples
  [ 0] ReferencePipeline$4$1.accept
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 17558577 total (0.30%), 17546 samples
  [ 0] Unsafe.getAndBitwiseAndInt
  [ 1] AbstractQueuedSynchronizer$Node.getAndUnsetStatus
  [ 2] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 3] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] TickPerCell.lambda$tick$0
  [ 7] TickPerCell$$Lambda$47.0x0000000801035678.accept
  [ 8] ChannelsGrid.lambda$forEachChannel$0
  [ 9] ChannelsGrid$$Lambda$48.0x0000000801035890.accept
  [10] Dimensions.forEachRowCol
  [11] ChannelsGrid.forEachChannel
  [12] TickPerCell.tick
  [13] GameOfLife.calculateFrame
  [14] GameOfLife.lambda$calculateFrameBlocking$4
  [15] GameOfLife$$Lambda$46.0x0000000801035468.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 16659765 total (0.29%), 16677 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] GameOfLife$$Lambda$116.0x0000000801080658.test
  [ 6] ChannelsGrid.lambda$forEachChannel$1
  [ 7] ChannelsGrid$$Lambda$117.0x0000000801080890.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] GameOfLife.calculateFrame
  [11] GameOfLife.lambda$calculateFrameBlocking$4
  [12] GameOfLife$$Lambda$46.0x0000000801035468.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 16545061 total (0.28%), 16591 samples
  [ 0] futex_wake_[k]
  [ 1] do_futex_[k]
  [ 2] __x64_sys_futex_[k]
  [ 3] do_syscall_64_[k]
  [ 4] entry_SYSCALL_64_after_hwframe_[k]
  [ 5] __lll_lock_wake
  [ 6] Unsafe_Park
  [ 7] Unsafe.park
  [ 8] LockSupport.park
  [ 9] AbstractQueuedSynchronizer$ConditionNode.block
  [10] ForkJoinPool.unmanagedBlock
  [11] ForkJoinPool.managedBlock
  [12] AbstractQueuedSynchronizer$ConditionObject.await
  [13] LockedSingleValue.take
  [14] Channel.take
  [15] TickPerCell.waitTick
  [16] Cell.notifyLiveness
  [17] Cell.run
  [18] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [19] ThreadPoolExecutor.runWorker
  [20] ThreadPoolExecutor$Worker.run
  [21] Thread.run

--- 16016710 total (0.27%), 16008 samples
  [ 0] AbstractOwnableSynchronizer.setExclusiveOwnerThread
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] TickPerCell.waitTick
  [ 7] Cell.notifyLiveness
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 15384381 total (0.26%), 15412 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 1] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 15366695 total (0.26%), 15367 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] TickPerCell.waitTick
  [ 3] Cell.notifyLiveness
  [ 4] Cell.run
  [ 5] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 15271236 total (0.26%), 15114 samples
  [ 0] AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<286822ul, G1BarrierSet>, (AccessInternal::BarrierType)3, 286822ul>::oop_access_barrier(oopDesc*, long)
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] TickPerCell.waitTick
  [11] Cell.notifyLiveness
  [12] Cell.run
  [13] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 15183309 total (0.26%), 15234 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 2] AbstractQueuedSynchronizer$ConditionObject.await
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] Cell.run
  [16] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

--- 15061238 total (0.26%), 14990 samples
  [ 0] __get_user_8_[k]
  [ 1] __rseq_handle_notify_resume_[k]
  [ 2] exit_to_user_mode_prepare_[k]
  [ 3] syscall_exit_to_user_mode_[k]
  [ 4] do_syscall_64_[k]
  [ 5] entry_SYSCALL_64_after_hwframe_[k]
  [ 6] __futex_abstimed_wait_common
  [ 7] Unsafe.park
  [ 8] LockSupport.park
  [ 9] AbstractQueuedSynchronizer$ConditionNode.block
  [10] ForkJoinPool.unmanagedBlock
  [11] ForkJoinPool.managedBlock
  [12] AbstractQueuedSynchronizer$ConditionObject.await
  [13] LockedSingleValue.take
  [14] Channel.take
  [15] Cell$$Lambda$61.0x0000000801036dd0.apply
  [16] ReferencePipeline$3$1.accept
  [17] ArrayList$ArrayListSpliterator.forEachRemaining
  [18] AbstractPipeline.copyInto
  [19] AbstractPipeline.wrapAndCopyInto
  [20] ReduceOps$ReduceOp.evaluateSequential
  [21] AbstractPipeline.evaluate
  [22] IntPipeline.reduce
  [23] IntPipeline.sum
  [24] Cell.calculateNextState
  [25] Cell.run
  [26] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [27] ThreadPoolExecutor.runWorker
  [28] ThreadPoolExecutor$Worker.run
  [29] Thread.run

--- 14962194 total (0.26%), 14996 samples
  [ 0] AbstractQueuedSynchronizer.signalNext
  [ 1] AbstractQueuedSynchronizer.release
  [ 2] ReentrantLock.unlock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] Cell.run
  [16] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

--- 14826135 total (0.25%), 14777 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.await
  [ 1] LockedSingleValue.take
  [ 2] Channel.take
  [ 3] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 4] ReferencePipeline$3$1.accept
  [ 5] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 6] AbstractPipeline.copyInto
  [ 7] AbstractPipeline.wrapAndCopyInto
  [ 8] ReduceOps$ReduceOp.evaluateSequential
  [ 9] AbstractPipeline.evaluate
  [10] IntPipeline.reduce
  [11] IntPipeline.sum
  [12] Cell.calculateNextState
  [13] Cell.run
  [14] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [15] ThreadPoolExecutor.runWorker
  [16] ThreadPoolExecutor$Worker.run
  [17] Thread.run

--- 14521289 total (0.25%), 14585 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 14046468 total (0.24%), 14079 samples
  [ 0] AbstractOwnableSynchronizer.setExclusiveOwnerThread
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] GameOfLife$$Lambda$116.0x0000000801080658.test
  [ 7] ChannelsGrid.lambda$forEachChannel$1
  [ 8] ChannelsGrid$$Lambda$117.0x0000000801080890.accept
  [ 9] Dimensions.forEachRowCol
  [10] ChannelsGrid.forEachChannel
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$46.0x0000000801035468.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 13320222 total (0.23%), 13378 samples
  [ 0] AbstractQueuedSynchronizer.enqueue
  [ 1] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 2] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 3] LockedSingleValue.put
  [ 4] Channel.put
  [ 5] Cell.lambda$notifyLiveness$0
  [ 6] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 7] ArrayList.forEach
  [ 8] Cell.notifyLiveness
  [ 9] Cell.run
  [10] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 12980283 total (0.22%), 12845 samples
  [ 0] AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<548964ul, G1BarrierSet>, (AccessInternal::BarrierType)2, 548964ul>::oop_access_barrier(void*)
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] TickPerCell.waitTick
  [10] Cell.notifyLiveness
  [11] Cell.run
  [12] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 12508919 total (0.21%), 12483 samples
  [ 0] fpregs_restore_userregs_[k]
  [ 1] exit_to_user_mode_prepare_[k]
  [ 2] syscall_exit_to_user_mode_[k]
  [ 3] do_syscall_64_[k]
  [ 4] entry_SYSCALL_64_after_hwframe_[k]
  [ 5] __futex_abstimed_wait_common
  [ 6] Unsafe.park
  [ 7] LockSupport.park
  [ 8] AbstractQueuedSynchronizer$ConditionNode.block
  [ 9] ForkJoinPool.unmanagedBlock
  [10] ForkJoinPool.managedBlock
  [11] AbstractQueuedSynchronizer$ConditionObject.await
  [12] LockedSingleValue.take
  [13] Channel.take
  [14] Cell$$Lambda$61.0x0000000801036dd0.apply
  [15] ReferencePipeline$3$1.accept
  [16] ArrayList$ArrayListSpliterator.forEachRemaining
  [17] AbstractPipeline.copyInto
  [18] AbstractPipeline.wrapAndCopyInto
  [19] ReduceOps$ReduceOp.evaluateSequential
  [20] AbstractPipeline.evaluate
  [21] IntPipeline.reduce
  [22] IntPipeline.sum
  [23] Cell.calculateNextState
  [24] Cell.run
  [25] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [26] ThreadPoolExecutor.runWorker
  [27] ThreadPoolExecutor$Worker.run
  [28] Thread.run

--- 12177145 total (0.21%), 12146 samples
  [ 0] Unsafe.park
  [ 1] LockSupport.park
  [ 2] AbstractQueuedSynchronizer$ConditionNode.block
  [ 3] ForkJoinPool.unmanagedBlock
  [ 4] ForkJoinPool.managedBlock
  [ 5] AbstractQueuedSynchronizer$ConditionObject.await
  [ 6] LockedSingleValue.take
  [ 7] Channel.take
  [ 8] TickPerCell.waitTick
  [ 9] Cell.notifyLiveness
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 11622269 total (0.20%), 11652 samples
  [ 0] __schedule_[k]
  [ 1] schedule_[k]
  [ 2] futex_wait_queue_[k]
  [ 3] futex_wait_[k]
  [ 4] do_futex_[k]
  [ 5] __x64_sys_futex_[k]
  [ 6] do_syscall_64_[k]
  [ 7] entry_SYSCALL_64_after_hwframe_[k]
  [ 8] __futex_abstimed_wait_common
  [ 9] Unsafe.park
  [10] LockSupport.park
  [11] AbstractQueuedSynchronizer$ConditionNode.block
  [12] ForkJoinPool.unmanagedBlock
  [13] ForkJoinPool.managedBlock
  [14] AbstractQueuedSynchronizer$ConditionObject.await
  [15] LockedSingleValue.take
  [16] Channel.take
  [17] Cell$$Lambda$61.0x0000000801036dd0.apply
  [18] ReferencePipeline$3$1.accept
  [19] ArrayList$ArrayListSpliterator.forEachRemaining
  [20] AbstractPipeline.copyInto
  [21] AbstractPipeline.wrapAndCopyInto
  [22] ReduceOps$ReduceOp.evaluateSequential
  [23] AbstractPipeline.evaluate
  [24] IntPipeline.reduce
  [25] IntPipeline.sum
  [26] Cell.calculateNextState
  [27] Cell.run
  [28] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [29] ThreadPoolExecutor.runWorker
  [30] ThreadPoolExecutor$Worker.run
  [31] Thread.run

--- 11584270 total (0.20%), 11607 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 11564258 total (0.20%), 11538 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] Cell.run
  [10] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 11493170 total (0.20%), 11541 samples
  [ 0] select_task_rq_fair_[k]
  [ 1] try_to_wake_up_[k]
  [ 2] wake_up_q_[k]
  [ 3] futex_wake_[k]
  [ 4] do_futex_[k]
  [ 5] __x64_sys_futex_[k]
  [ 6] do_syscall_64_[k]
  [ 7] entry_SYSCALL_64_after_hwframe_[k]
  [ 8] ___pthread_cond_signal
  [ 9] Unsafe.unpark
  [10] LockSupport.unpark
  [11] AbstractQueuedSynchronizer.signalNext
  [12] AbstractQueuedSynchronizer.release
  [13] ReentrantLock.unlock
  [14] LockedSingleValue.put
  [15] Channel.put
  [16] Cell.lambda$notifyLiveness$0
  [17] Cell$$Lambda$51.0x0000000801035cd0.accept
  [18] ArrayList.forEach
  [19] Cell.notifyLiveness
  [20] Cell.run
  [21] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 11436408 total (0.20%), 11464 samples
  [ 0] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 11346631 total (0.19%), 11382 samples
  [ 0] ___pthread_cond_wait
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] Cell$$Lambda$61.0x0000000801036dd0.apply
  [10] ReferencePipeline$3$1.accept
  [11] ArrayList$ArrayListSpliterator.forEachRemaining
  [12] AbstractPipeline.copyInto
  [13] AbstractPipeline.wrapAndCopyInto
  [14] ReduceOps$ReduceOp.evaluateSequential
  [15] AbstractPipeline.evaluate
  [16] IntPipeline.reduce
  [17] IntPipeline.sum
  [18] Cell.calculateNextState
  [19] Cell.run
  [20] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [21] ThreadPoolExecutor.runWorker
  [22] ThreadPoolExecutor$Worker.run
  [23] Thread.run

--- 11318319 total (0.19%), 11263 samples
  [ 0] __GI___pthread_disable_asynccancel
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] TickPerCell.waitTick
  [10] Cell.notifyLiveness
  [11] Cell.run
  [12] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 11234158 total (0.19%), 11263 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.tryAcquire
  [ 2] AbstractQueuedSynchronizer.acquire
  [ 3] AbstractQueuedSynchronizer$ConditionObject.await
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] Cell.run
  [17] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 11215867 total (0.19%), 11200 samples
  [ 0] AbstractQueuedSynchronizer.acquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] Cell.run
  [ 7] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 10820527 total (0.19%), 10726 samples
  [ 0] AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<548964ul, G1BarrierSet>, (AccessInternal::BarrierType)2, 548964ul>::oop_access_barrier(void*)
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] Cell$$Lambda$61.0x0000000801036dd0.apply
  [10] ReferencePipeline$3$1.accept
  [11] ArrayList$ArrayListSpliterator.forEachRemaining
  [12] AbstractPipeline.copyInto
  [13] AbstractPipeline.wrapAndCopyInto
  [14] ReduceOps$ReduceOp.evaluateSequential
  [15] AbstractPipeline.evaluate
  [16] IntPipeline.reduce
  [17] IntPipeline.sum
  [18] Cell.calculateNextState
  [19] Cell.run
  [20] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [21] ThreadPoolExecutor.runWorker
  [22] ThreadPoolExecutor$Worker.run
  [23] Thread.run

--- 10416478 total (0.18%), 10450 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] Cell.run
  [13] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 10416318 total (0.18%), 10440 samples
  [ 0] __rseq_handle_notify_resume_[k]
  [ 1] exit_to_user_mode_prepare_[k]
  [ 2] syscall_exit_to_user_mode_[k]
  [ 3] do_syscall_64_[k]
  [ 4] entry_SYSCALL_64_after_hwframe_[k]
  [ 5] __futex_abstimed_wait_common
  [ 6] Unsafe.park
  [ 7] LockSupport.park
  [ 8] AbstractQueuedSynchronizer$ConditionNode.block
  [ 9] ForkJoinPool.unmanagedBlock
  [10] ForkJoinPool.managedBlock
  [11] AbstractQueuedSynchronizer$ConditionObject.await
  [12] LockedSingleValue.take
  [13] Channel.take
  [14] TickPerCell.waitTick
  [15] Cell.notifyLiveness
  [16] Cell.run
  [17] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 10380053 total (0.18%), 10401 samples
  [ 0] plist_add_[k]
  [ 1] __futex_queue_[k]
  [ 2] futex_wait_queue_[k]
  [ 3] futex_wait_[k]
  [ 4] do_futex_[k]
  [ 5] __x64_sys_futex_[k]
  [ 6] do_syscall_64_[k]
  [ 7] entry_SYSCALL_64_after_hwframe_[k]
  [ 8] __futex_abstimed_wait_common
  [ 9] Unsafe.park
  [10] LockSupport.park
  [11] AbstractQueuedSynchronizer$ConditionNode.block
  [12] ForkJoinPool.unmanagedBlock
  [13] ForkJoinPool.managedBlock
  [14] AbstractQueuedSynchronizer$ConditionObject.await
  [15] LockedSingleValue.take
  [16] Channel.take
  [17] Cell$$Lambda$61.0x0000000801036dd0.apply
  [18] ReferencePipeline$3$1.accept
  [19] ArrayList$ArrayListSpliterator.forEachRemaining
  [20] AbstractPipeline.copyInto
  [21] AbstractPipeline.wrapAndCopyInto
  [22] ReduceOps$ReduceOp.evaluateSequential
  [23] AbstractPipeline.evaluate
  [24] IntPipeline.reduce
  [25] IntPipeline.sum
  [26] Cell.calculateNextState
  [27] Cell.run
  [28] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [29] ThreadPoolExecutor.runWorker
  [30] ThreadPoolExecutor$Worker.run
  [31] Thread.run

--- 10324009 total (0.18%), 10328 samples
  [ 0] AbstractQueuedSynchronizer$ConditionNode.isReleasable
  [ 1] AbstractQueuedSynchronizer$ConditionNode.block
  [ 2] ForkJoinPool.unmanagedBlock
  [ 3] ForkJoinPool.managedBlock
  [ 4] AbstractQueuedSynchronizer$ConditionObject.await
  [ 5] LockedSingleValue.take
  [ 6] Channel.take
  [ 7] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 8] ReferencePipeline$3$1.accept
  [ 9] ArrayList$ArrayListSpliterator.forEachRemaining
  [10] AbstractPipeline.copyInto
  [11] AbstractPipeline.wrapAndCopyInto
  [12] ReduceOps$ReduceOp.evaluateSequential
  [13] AbstractPipeline.evaluate
  [14] IntPipeline.reduce
  [15] IntPipeline.sum
  [16] Cell.calculateNextState
  [17] Cell.run
  [18] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [19] ThreadPoolExecutor.runWorker
  [20] ThreadPoolExecutor$Worker.run
  [21] Thread.run

--- 10222546 total (0.17%), 10181 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] Cell.run
  [ 7] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 10085811 total (0.17%), 10122 samples
  [ 0] __entry_text_start_[k]
  [ 1] __futex_abstimed_wait_common
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] Cell$$Lambda$61.0x0000000801036dd0.apply
  [11] ReferencePipeline$3$1.accept
  [12] ArrayList$ArrayListSpliterator.forEachRemaining
  [13] AbstractPipeline.copyInto
  [14] AbstractPipeline.wrapAndCopyInto
  [15] ReduceOps$ReduceOp.evaluateSequential
  [16] AbstractPipeline.evaluate
  [17] IntPipeline.reduce
  [18] IntPipeline.sum
  [19] Cell.calculateNextState
  [20] Cell.run
  [21] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 10020208 total (0.17%), 10029 samples
  [ 0] AbstractQueuedSynchronizer.acquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 9595505 total (0.16%), 9595 samples
  [ 0] syscall_exit_to_user_mode_[k]
  [ 1] do_syscall_64_[k]
  [ 2] entry_SYSCALL_64_after_hwframe_[k]
  [ 3] __futex_abstimed_wait_common
  [ 4] Unsafe.park
  [ 5] LockSupport.park
  [ 6] AbstractQueuedSynchronizer$ConditionNode.block
  [ 7] ForkJoinPool.unmanagedBlock
  [ 8] ForkJoinPool.managedBlock
  [ 9] AbstractQueuedSynchronizer$ConditionObject.await
  [10] LockedSingleValue.take
  [11] Channel.take
  [12] TickPerCell.waitTick
  [13] Cell.notifyLiveness
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 9426205 total (0.16%), 9425 samples
  [ 0] AbstractQueuedSynchronizer.casTail
  [ 1] AbstractQueuedSynchronizer.enqueue
  [ 2] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 3] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] TickPerCell.lambda$tick$0
  [ 7] TickPerCell$$Lambda$47.0x0000000801035678.accept
  [ 8] ChannelsGrid.lambda$forEachChannel$0
  [ 9] ChannelsGrid$$Lambda$48.0x0000000801035890.accept
  [10] Dimensions.forEachRowCol
  [11] ChannelsGrid.forEachChannel
  [12] TickPerCell.tick
  [13] GameOfLife.calculateFrame
  [14] GameOfLife.lambda$calculateFrameBlocking$4
  [15] GameOfLife$$Lambda$46.0x0000000801035468.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 9381074 total (0.16%), 9411 samples
  [ 0] AbstractOwnableSynchronizer.setExclusiveOwnerThread
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] TickPerCell.waitTick
  [ 7] Cell.notifyLiveness
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 9158696 total (0.16%), 9178 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 8939968 total (0.15%), 8952 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.canReacquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 8878428 total (0.15%), 8930 samples
  [ 0] Unsafe_Unpark
  [ 1] Unsafe.unpark
  [ 2] LockSupport.unpark
  [ 3] AbstractQueuedSynchronizer.signalNext
  [ 4] AbstractQueuedSynchronizer.release
  [ 5] ReentrantLock.unlock
  [ 6] LockedSingleValue.put
  [ 7] Channel.put
  [ 8] Cell.lambda$notifyLiveness$0
  [ 9] Cell$$Lambda$51.0x0000000801035cd0.accept
  [10] ArrayList.forEach
  [11] Cell.notifyLiveness
  [12] Cell.run
  [13] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 8765658 total (0.15%), 8805 samples
  [ 0] Unsafe.getAndBitwiseAndInt
  [ 1] AbstractQueuedSynchronizer$Node.getAndUnsetStatus
  [ 2] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 3] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 8761126 total (0.15%), 8736 samples
  [ 0] try_to_wake_up_[k]
  [ 1] wake_up_q_[k]
  [ 2] futex_wake_[k]
  [ 3] do_futex_[k]
  [ 4] __x64_sys_futex_[k]
  [ 5] do_syscall_64_[k]
  [ 6] entry_SYSCALL_64_after_hwframe_[k]
  [ 7] ___pthread_cond_signal
  [ 8] Unsafe.unpark
  [ 9] LockSupport.unpark
  [10] AbstractQueuedSynchronizer.signalNext
  [11] AbstractQueuedSynchronizer.release
  [12] ReentrantLock.unlock
  [13] LockedSingleValue.put
  [14] Channel.put
  [15] Cell.lambda$notifyLiveness$0
  [16] Cell$$Lambda$51.0x0000000801035cd0.accept
  [17] ArrayList.forEach
  [18] Cell.notifyLiveness
  [19] Cell.run
  [20] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [21] ThreadPoolExecutor.runWorker
  [22] ThreadPoolExecutor$Worker.run
  [23] Thread.run

--- 8420308 total (0.14%), 8408 samples
  [ 0] ReferencePipeline$4$1.accept
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 8324298 total (0.14%), 8350 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$47.0x0000000801035678.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$48.0x0000000801035890.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$46.0x0000000801035468.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 8247776 total (0.14%), 8283 samples
  [ 0] AbstractQueuedSynchronizer.signalNext
  [ 1] AbstractQueuedSynchronizer.release
  [ 2] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 3] AbstractQueuedSynchronizer$ConditionObject.await
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] Cell.run
  [17] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 8105765 total (0.14%), 8143 samples
  [ 0] psi_group_change_[k]
  [ 1] psi_task_switch_[k]
  [ 2] __schedule_[k]
  [ 3] schedule_[k]
  [ 4] futex_wait_queue_[k]
  [ 5] futex_wait_[k]
  [ 6] do_futex_[k]
  [ 7] __x64_sys_futex_[k]
  [ 8] do_syscall_64_[k]
  [ 9] entry_SYSCALL_64_after_hwframe_[k]
  [10] __futex_abstimed_wait_common
  [11] Unsafe.park
  [12] LockSupport.park
  [13] AbstractQueuedSynchronizer$ConditionNode.block
  [14] ForkJoinPool.unmanagedBlock
  [15] ForkJoinPool.managedBlock
  [16] AbstractQueuedSynchronizer$ConditionObject.await
  [17] LockedSingleValue.take
  [18] Channel.take
  [19] Cell$$Lambda$61.0x0000000801036dd0.apply
  [20] ReferencePipeline$3$1.accept
  [21] ArrayList$ArrayListSpliterator.forEachRemaining
  [22] AbstractPipeline.copyInto
  [23] AbstractPipeline.wrapAndCopyInto
  [24] ReduceOps$ReduceOp.evaluateSequential
  [25] AbstractPipeline.evaluate
  [26] IntPipeline.reduce
  [27] IntPipeline.sum
  [28] Cell.calculateNextState
  [29] Cell.run
  [30] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [31] ThreadPoolExecutor.runWorker
  [32] ThreadPoolExecutor$Worker.run
  [33] Thread.run

--- 8012912 total (0.14%), 8048 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] Cell.run
  [ 4] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 5] ThreadPoolExecutor.runWorker
  [ 6] ThreadPoolExecutor$Worker.run
  [ 7] Thread.run

--- 7779137 total (0.13%), 7797 samples
  [ 0] ReferencePipeline$4.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 7718867 total (0.13%), 7748 samples
  [ 0] AbstractQueuedSynchronizer.acquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 7704784 total (0.13%), 7692 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] GameOfLife$$Lambda$116.0x0000000801080658.test
  [ 6] ChannelsGrid.lambda$forEachChannel$1
  [ 7] ChannelsGrid$$Lambda$117.0x0000000801080890.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] GameOfLife.calculateFrame
  [11] GameOfLife.lambda$calculateFrameBlocking$4
  [12] GameOfLife$$Lambda$46.0x0000000801035468.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 7498387 total (0.13%), 7539 samples
  [ 0] psi_group_change_[k]
  [ 1] psi_task_change_[k]
  [ 2] enqueue_task_[k]
  [ 3] ttwu_do_activate_[k]
  [ 4] try_to_wake_up_[k]
  [ 5] wake_up_q_[k]
  [ 6] futex_wake_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] ___pthread_cond_signal
  [12] Unsafe.unpark
  [13] LockSupport.unpark
  [14] AbstractQueuedSynchronizer.signalNext
  [15] AbstractQueuedSynchronizer.release
  [16] ReentrantLock.unlock
  [17] LockedSingleValue.put
  [18] Channel.put
  [19] Cell.lambda$notifyLiveness$0
  [20] Cell$$Lambda$51.0x0000000801035cd0.accept
  [21] ArrayList.forEach
  [22] Cell.notifyLiveness
  [23] Cell.run
  [24] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [25] ThreadPoolExecutor.runWorker
  [26] ThreadPoolExecutor$Worker.run
  [27] Thread.run

--- 7358953 total (0.13%), 7343 samples
  [ 0] Objects.requireNonNull
  [ 1] StreamSupport.stream
  [ 2] Collection.stream
  [ 3] Cell.calculateNextState
  [ 4] Cell.run
  [ 5] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 7297666 total (0.12%), 7303 samples
  [ 0] ___pthread_cond_wait
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] TickPerCell.waitTick
  [10] Cell.notifyLiveness
  [11] Cell.run
  [12] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 7066766 total (0.12%), 7107 samples
  [ 0] ___pthread_cond_wait
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] Cell$$Lambda$61.0x0000000801036dd0.apply
  [11] ReferencePipeline$3$1.accept
  [12] ArrayList$ArrayListSpliterator.forEachRemaining
  [13] AbstractPipeline.copyInto
  [14] AbstractPipeline.wrapAndCopyInto
  [15] ReduceOps$ReduceOp.evaluateSequential
  [16] AbstractPipeline.evaluate
  [17] IntPipeline.reduce
  [18] IntPipeline.sum
  [19] Cell.calculateNextState
  [20] Cell.run
  [21] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 6885621 total (0.12%), 6928 samples
  [ 0] LockSupport.unpark
  [ 1] AbstractQueuedSynchronizer.signalNext
  [ 2] AbstractQueuedSynchronizer.release
  [ 3] ReentrantLock.unlock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 6859004 total (0.12%), 6869 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 1] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 6794386 total (0.12%), 6829 samples
  [ 0] __entry_text_start_[k]
  [ 1] ___pthread_cond_signal
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] Cell$$Lambda$61.0x0000000801036dd0.apply
  [11] ReferencePipeline$3$1.accept
  [12] ArrayList$ArrayListSpliterator.forEachRemaining
  [13] AbstractPipeline.copyInto
  [14] AbstractPipeline.wrapAndCopyInto
  [15] ReduceOps$ReduceOp.evaluateSequential
  [16] AbstractPipeline.evaluate
  [17] IntPipeline.reduce
  [18] IntPipeline.sum
  [19] Cell.calculateNextState
  [20] Cell.run
  [21] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 6655557 total (0.11%), 6676 samples
  [ 0] psi_task_change_[k]
  [ 1] enqueue_task_[k]
  [ 2] ttwu_do_activate_[k]
  [ 3] try_to_wake_up_[k]
  [ 4] wake_up_q_[k]
  [ 5] futex_wake_[k]
  [ 6] do_futex_[k]
  [ 7] __x64_sys_futex_[k]
  [ 8] do_syscall_64_[k]
  [ 9] entry_SYSCALL_64_after_hwframe_[k]
  [10] ___pthread_cond_signal
  [11] Unsafe.unpark
  [12] LockSupport.unpark
  [13] AbstractQueuedSynchronizer.signalNext
  [14] AbstractQueuedSynchronizer.release
  [15] ReentrantLock.unlock
  [16] LockedSingleValue.put
  [17] Channel.put
  [18] Cell.lambda$notifyLiveness$0
  [19] Cell$$Lambda$51.0x0000000801035cd0.accept
  [20] ArrayList.forEach
  [21] Cell.notifyLiveness
  [22] Cell.run
  [23] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [24] ThreadPoolExecutor.runWorker
  [25] ThreadPoolExecutor$Worker.run
  [26] Thread.run

--- 6523514 total (0.11%), 6551 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 6341452 total (0.11%), 6369 samples
  [ 0] AbstractQueuedSynchronizer.acquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 6283051 total (0.11%), 6287 samples
  [ 0] __rseq_handle_notify_resume_[k]
  [ 1] exit_to_user_mode_prepare_[k]
  [ 2] syscall_exit_to_user_mode_[k]
  [ 3] do_syscall_64_[k]
  [ 4] entry_SYSCALL_64_after_hwframe_[k]
  [ 5] __futex_abstimed_wait_common
  [ 6] Unsafe.park
  [ 7] LockSupport.park
  [ 8] AbstractQueuedSynchronizer$ConditionNode.block
  [ 9] ForkJoinPool.unmanagedBlock
  [10] ForkJoinPool.managedBlock
  [11] AbstractQueuedSynchronizer$ConditionObject.await
  [12] LockedSingleValue.take
  [13] Channel.take
  [14] Cell$$Lambda$61.0x0000000801036dd0.apply
  [15] ReferencePipeline$3$1.accept
  [16] ArrayList$ArrayListSpliterator.forEachRemaining
  [17] AbstractPipeline.copyInto
  [18] AbstractPipeline.wrapAndCopyInto
  [19] ReduceOps$ReduceOp.evaluateSequential
  [20] AbstractPipeline.evaluate
  [21] IntPipeline.reduce
  [22] IntPipeline.sum
  [23] Cell.calculateNextState
  [24] Cell.run
  [25] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [26] ThreadPoolExecutor.runWorker
  [27] ThreadPoolExecutor$Worker.run
  [28] Thread.run

--- 6246748 total (0.11%), 6272 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] Cell.run
  [12] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 6218688 total (0.11%), 6227 samples
  [ 0] __perf_event_task_sched_out_[k]
  [ 1] __schedule_[k]
  [ 2] schedule_[k]
  [ 3] futex_wait_queue_[k]
  [ 4] futex_wait_[k]
  [ 5] do_futex_[k]
  [ 6] __x64_sys_futex_[k]
  [ 7] do_syscall_64_[k]
  [ 8] entry_SYSCALL_64_after_hwframe_[k]
  [ 9] __futex_abstimed_wait_common
  [10] Unsafe.park
  [11] LockSupport.park
  [12] AbstractQueuedSynchronizer$ConditionNode.block
  [13] ForkJoinPool.unmanagedBlock
  [14] ForkJoinPool.managedBlock
  [15] AbstractQueuedSynchronizer$ConditionObject.await
  [16] LockedSingleValue.take
  [17] Channel.take
  [18] Cell$$Lambda$61.0x0000000801036dd0.apply
  [19] ReferencePipeline$3$1.accept
  [20] ArrayList$ArrayListSpliterator.forEachRemaining
  [21] AbstractPipeline.copyInto
  [22] AbstractPipeline.wrapAndCopyInto
  [23] ReduceOps$ReduceOp.evaluateSequential
  [24] AbstractPipeline.evaluate
  [25] IntPipeline.reduce
  [26] IntPipeline.sum
  [27] Cell.calculateNextState
  [28] Cell.run
  [29] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [30] ThreadPoolExecutor.runWorker
  [31] ThreadPoolExecutor$Worker.run
  [32] Thread.run

--- 6168186 total (0.11%), 6178 samples
  [ 0] Thread.interrupted
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 6064638 total (0.10%), 6089 samples
  [ 0] Cell.run
  [ 1] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 2] ThreadPoolExecutor.runWorker
  [ 3] ThreadPoolExecutor$Worker.run
  [ 4] Thread.run

--- 6024328 total (0.10%), 6024 samples
  [ 0] AbstractOwnableSynchronizer.setExclusiveOwnerThread
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] TickPerCell.waitTick
  [ 7] Cell.notifyLiveness
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 5926650 total (0.10%), 5952 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 2] AbstractQueuedSynchronizer$ConditionObject.await
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] Cell.run
  [16] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

--- 5904337 total (0.10%), 5907 samples
  [ 0] ReferencePipeline$3.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 5902850 total (0.10%), 5925 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.tryAcquire
  [ 2] AbstractQueuedSynchronizer.acquire
  [ 3] AbstractQueuedSynchronizer$ConditionObject.await
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] TickPerCell.waitTick
  [ 7] Cell.notifyLiveness
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 5834980 total (0.10%), 5829 samples
  [ 0] Unsafe.park
  [ 1] [unknown_Java]

--- 5642756 total (0.10%), 5629 samples
  [ 0] fpregs_restore_userregs_[k]
  [ 1] exit_to_user_mode_prepare_[k]
  [ 2] syscall_exit_to_user_mode_[k]
  [ 3] do_syscall_64_[k]
  [ 4] entry_SYSCALL_64_after_hwframe_[k]
  [ 5] __futex_abstimed_wait_common
  [ 6] Unsafe.park
  [ 7] LockSupport.park
  [ 8] AbstractQueuedSynchronizer$ConditionNode.block
  [ 9] ForkJoinPool.unmanagedBlock
  [10] ForkJoinPool.managedBlock
  [11] AbstractQueuedSynchronizer$ConditionObject.await
  [12] LockedSingleValue.take
  [13] Channel.take
  [14] TickPerCell.waitTick
  [15] Cell.notifyLiveness
  [16] Cell.run
  [17] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 5640205 total (0.10%), 5665 samples
  [ 0] AbstractQueuedSynchronizer.enqueue
  [ 1] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 2] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 3] LockedSingleValue.put
  [ 4] Channel.put
  [ 5] Cell.lambda$notifyLiveness$0
  [ 6] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 7] ArrayList.forEach
  [ 8] Cell.notifyLiveness
  [ 9] Cell.run
  [10] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 5624271 total (0.10%), 5638 samples
  [ 0] __schedule_[k]
  [ 1] schedule_[k]
  [ 2] futex_wait_queue_[k]
  [ 3] futex_wait_[k]
  [ 4] do_futex_[k]
  [ 5] __x64_sys_futex_[k]
  [ 6] do_syscall_64_[k]
  [ 7] entry_SYSCALL_64_after_hwframe_[k]
  [ 8] __futex_abstimed_wait_common
  [ 9] Unsafe.park
  [10] LockSupport.park
  [11] AbstractQueuedSynchronizer$ConditionNode.block
  [12] ForkJoinPool.unmanagedBlock
  [13] ForkJoinPool.managedBlock
  [14] AbstractQueuedSynchronizer$ConditionObject.await
  [15] LockedSingleValue.take
  [16] Channel.take
  [17] TickPerCell.waitTick
  [18] Cell.notifyLiveness
  [19] Cell.run
  [20] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [21] ThreadPoolExecutor.runWorker
  [22] ThreadPoolExecutor$Worker.run
  [23] Thread.run

--- 5555916 total (0.10%), 5514 samples
  [ 0] JavaThread::threadObj() const
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] TickPerCell.waitTick
  [11] Cell.notifyLiveness
  [12] Cell.run
  [13] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 5478510 total (0.09%), 5460 samples
  [ 0] check_preemption_disabled_[k]
  [ 1] fpregs_restore_userregs_[k]
  [ 2] exit_to_user_mode_prepare_[k]
  [ 3] syscall_exit_to_user_mode_[k]
  [ 4] do_syscall_64_[k]
  [ 5] entry_SYSCALL_64_after_hwframe_[k]
  [ 6] __futex_abstimed_wait_common
  [ 7] Unsafe.park
  [ 8] LockSupport.park
  [ 9] AbstractQueuedSynchronizer$ConditionNode.block
  [10] ForkJoinPool.unmanagedBlock
  [11] ForkJoinPool.managedBlock
  [12] AbstractQueuedSynchronizer$ConditionObject.await
  [13] LockedSingleValue.take
  [14] Channel.take
  [15] Cell$$Lambda$61.0x0000000801036dd0.apply
  [16] ReferencePipeline$3$1.accept
  [17] ArrayList$ArrayListSpliterator.forEachRemaining
  [18] AbstractPipeline.copyInto
  [19] AbstractPipeline.wrapAndCopyInto
  [20] ReduceOps$ReduceOp.evaluateSequential
  [21] AbstractPipeline.evaluate
  [22] IntPipeline.reduce
  [23] IntPipeline.sum
  [24] Cell.calculateNextState
  [25] Cell.run
  [26] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [27] ThreadPoolExecutor.runWorker
  [28] ThreadPoolExecutor$Worker.run
  [29] Thread.run

--- 5432997 total (0.09%), 5420 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] Cell.run
  [10] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 5358356 total (0.09%), 5360 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] Cell.run
  [10] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 5333739 total (0.09%), 5303 samples
  [ 0] JavaThread::threadObj() const
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] Cell$$Lambda$61.0x0000000801036dd0.apply
  [11] ReferencePipeline$3$1.accept
  [12] ArrayList$ArrayListSpliterator.forEachRemaining
  [13] AbstractPipeline.copyInto
  [14] AbstractPipeline.wrapAndCopyInto
  [15] ReduceOps$ReduceOp.evaluateSequential
  [16] AbstractPipeline.evaluate
  [17] IntPipeline.reduce
  [18] IntPipeline.sum
  [19] Cell.calculateNextState
  [20] Cell.run
  [21] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 5323541 total (0.09%), 5319 samples
  [ 0] ReferencePipeline$StatelessOp.<init>
  [ 1] ReferencePipeline$3.<init>
  [ 2] ReferencePipeline.map
  [ 3] Cell.calculateNextState
  [ 4] Cell.run
  [ 5] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 5317275 total (0.09%), 5314 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] TickPerCell.waitTick
  [ 3] Cell.notifyLiveness
  [ 4] Cell.run
  [ 5] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 5201084 total (0.09%), 5201 samples
  [ 0] __put_user_nocheck_8_[k]
  [ 1] __rseq_handle_notify_resume_[k]
  [ 2] exit_to_user_mode_prepare_[k]
  [ 3] syscall_exit_to_user_mode_[k]
  [ 4] do_syscall_64_[k]
  [ 5] entry_SYSCALL_64_after_hwframe_[k]
  [ 6] __futex_abstimed_wait_common
  [ 7] Unsafe.park
  [ 8] LockSupport.park
  [ 9] AbstractQueuedSynchronizer$ConditionNode.block
  [10] ForkJoinPool.unmanagedBlock
  [11] ForkJoinPool.managedBlock
  [12] AbstractQueuedSynchronizer$ConditionObject.await
  [13] LockedSingleValue.take
  [14] Channel.take
  [15] TickPerCell.waitTick
  [16] Cell.notifyLiveness
  [17] Cell.run
  [18] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [19] ThreadPoolExecutor.runWorker
  [20] ThreadPoolExecutor$Worker.run
  [21] Thread.run

--- 5150591 total (0.09%), 5156 samples
  [ 0] StreamSupport.stream
  [ 1] Collection.stream
  [ 2] Cell.calculateNextState
  [ 3] Cell.run
  [ 4] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 5] ThreadPoolExecutor.runWorker
  [ 6] ThreadPoolExecutor$Worker.run
  [ 7] Thread.run

--- 5013650 total (0.09%), 5020 samples
  [ 0] futex_wake_mark_[k]
  [ 1] futex_wake_[k]
  [ 2] do_futex_[k]
  [ 3] __x64_sys_futex_[k]
  [ 4] do_syscall_64_[k]
  [ 5] entry_SYSCALL_64_after_hwframe_[k]
  [ 6] ___pthread_cond_signal
  [ 7] Unsafe.unpark
  [ 8] LockSupport.unpark
  [ 9] AbstractQueuedSynchronizer.signalNext
  [10] AbstractQueuedSynchronizer.release
  [11] ReentrantLock.unlock
  [12] LockedSingleValue.put
  [13] Channel.put
  [14] Cell.lambda$notifyLiveness$0
  [15] Cell$$Lambda$51.0x0000000801035cd0.accept
  [16] ArrayList.forEach
  [17] Cell.notifyLiveness
  [18] Cell.run
  [19] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [20] ThreadPoolExecutor.runWorker
  [21] ThreadPoolExecutor$Worker.run
  [22] Thread.run

--- 4894508 total (0.08%), 4890 samples
  [ 0] ReentrantLock$Sync.isHeldExclusively
  [ 1] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 2] AbstractQueuedSynchronizer$ConditionObject.await
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] TickPerCell.waitTick
  [ 6] Cell.notifyLiveness
  [ 7] Cell.run
  [ 8] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 4891479 total (0.08%), 4894 samples
  [ 0] AbstractQueuedSynchronizer.acquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] Cell.run
  [ 7] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 4729553 total (0.08%), 4743 samples
  [ 0] __entry_text_start_[k]
  [ 1] __futex_abstimed_wait_common
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] TickPerCell.waitTick
  [11] Cell.notifyLiveness
  [12] Cell.run
  [13] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 4662563 total (0.08%), 4676 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] Cell.run
  [13] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 4651151 total (0.08%), 4634 samples
  [ 0] __GI___pthread_disable_asynccancel
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] Cell$$Lambda$61.0x0000000801036dd0.apply
  [10] ReferencePipeline$3$1.accept
  [11] ArrayList$ArrayListSpliterator.forEachRemaining
  [12] AbstractPipeline.copyInto
  [13] AbstractPipeline.wrapAndCopyInto
  [14] ReduceOps$ReduceOp.evaluateSequential
  [15] AbstractPipeline.evaluate
  [16] IntPipeline.reduce
  [17] IntPipeline.sum
  [18] Cell.calculateNextState
  [19] Cell.run
  [20] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [21] ThreadPoolExecutor.runWorker
  [22] ThreadPoolExecutor$Worker.run
  [23] Thread.run

--- 4623223 total (0.08%), 4648 samples
  [ 0] psi_group_change_[k]
  [ 1] psi_task_switch_[k]
  [ 2] __schedule_[k]
  [ 3] schedule_[k]
  [ 4] futex_wait_queue_[k]
  [ 5] futex_wait_[k]
  [ 6] do_futex_[k]
  [ 7] __x64_sys_futex_[k]
  [ 8] do_syscall_64_[k]
  [ 9] entry_SYSCALL_64_after_hwframe_[k]
  [10] __futex_abstimed_wait_common
  [11] Unsafe.park
  [12] LockSupport.park
  [13] AbstractQueuedSynchronizer$ConditionNode.block
  [14] ForkJoinPool.unmanagedBlock
  [15] ForkJoinPool.managedBlock
  [16] AbstractQueuedSynchronizer$ConditionObject.await
  [17] LockedSingleValue.take
  [18] Channel.take
  [19] TickPerCell.waitTick
  [20] Cell.notifyLiveness
  [21] Cell.run
  [22] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [23] ThreadPoolExecutor.runWorker
  [24] ThreadPoolExecutor$Worker.run
  [25] Thread.run

--- 4571936 total (0.08%), 4569 samples
  [ 0] AbstractQueuedSynchronizer$ConditionNode.isReleasable
  [ 1] AbstractQueuedSynchronizer$ConditionNode.block
  [ 2] ForkJoinPool.unmanagedBlock
  [ 3] ForkJoinPool.managedBlock
  [ 4] AbstractQueuedSynchronizer$ConditionObject.await
  [ 5] LockedSingleValue.take
  [ 6] Channel.take
  [ 7] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 8] ReferencePipeline$3$1.accept
  [ 9] ArrayList$ArrayListSpliterator.forEachRemaining
  [10] AbstractPipeline.copyInto
  [11] AbstractPipeline.wrapAndCopyInto
  [12] ReduceOps$ReduceOp.evaluateSequential
  [13] AbstractPipeline.evaluate
  [14] IntPipeline.reduce
  [15] IntPipeline.sum
  [16] Cell.calculateNextState
  [17] Cell.run
  [18] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [19] ThreadPoolExecutor.runWorker
  [20] ThreadPoolExecutor$Worker.run
  [21] Thread.run

--- 4502927 total (0.08%), 4484 samples
  [ 0] java_lang_Thread::set_thread_status(oopDesc*, JavaThreadStatus)
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] Cell$$Lambda$61.0x0000000801036dd0.apply
  [11] ReferencePipeline$3$1.accept
  [12] ArrayList$ArrayListSpliterator.forEachRemaining
  [13] AbstractPipeline.copyInto
  [14] AbstractPipeline.wrapAndCopyInto
  [15] ReduceOps$ReduceOp.evaluateSequential
  [16] AbstractPipeline.evaluate
  [17] IntPipeline.reduce
  [18] IntPipeline.sum
  [19] Cell.calculateNextState
  [20] Cell.run
  [21] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 4488661 total (0.08%), 4515 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] Cell.run
  [ 7] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 4487828 total (0.08%), 4510 samples
  [ 0] Unsafe.getAndBitwiseAndInt
  [ 1] AbstractQueuedSynchronizer$Node.getAndUnsetStatus
  [ 2] AbstractQueuedSynchronizer.signalNext
  [ 3] AbstractQueuedSynchronizer.release
  [ 4] ReentrantLock.unlock
  [ 5] LockedSingleValue.put
  [ 6] Channel.put
  [ 7] TickPerCell.lambda$tick$0
  [ 8] TickPerCell$$Lambda$47.0x0000000801035678.accept
  [ 9] ChannelsGrid.lambda$forEachChannel$0
  [10] ChannelsGrid$$Lambda$48.0x0000000801035890.accept
  [11] Dimensions.forEachRowCol
  [12] ChannelsGrid.forEachChannel
  [13] TickPerCell.tick
  [14] GameOfLife.calculateFrame
  [15] GameOfLife.lambda$calculateFrameBlocking$4
  [16] GameOfLife$$Lambda$46.0x0000000801035468.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

--- 4477764 total (0.08%), 4511 samples
  [ 0] vtable chunks
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 4460945 total (0.08%), 4472 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] Cell.run
  [13] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 4456159 total (0.08%), 4477 samples
  [ 0] vtable chunks
  [ 1] Sink$ChainedReference.end
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] Cell.run
  [10] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 4412558 total (0.08%), 4421 samples
  [ 0] psi_task_switch_[k]
  [ 1] __schedule_[k]
  [ 2] schedule_[k]
  [ 3] futex_wait_queue_[k]
  [ 4] futex_wait_[k]
  [ 5] do_futex_[k]
  [ 6] __x64_sys_futex_[k]
  [ 7] do_syscall_64_[k]
  [ 8] entry_SYSCALL_64_after_hwframe_[k]
  [ 9] __futex_abstimed_wait_common
  [10] Unsafe.park
  [11] LockSupport.park
  [12] AbstractQueuedSynchronizer$ConditionNode.block
  [13] ForkJoinPool.unmanagedBlock
  [14] ForkJoinPool.managedBlock
  [15] AbstractQueuedSynchronizer$ConditionObject.await
  [16] LockedSingleValue.take
  [17] Channel.take
  [18] Cell$$Lambda$61.0x0000000801036dd0.apply
  [19] ReferencePipeline$3$1.accept
  [20] ArrayList$ArrayListSpliterator.forEachRemaining
  [21] AbstractPipeline.copyInto
  [22] AbstractPipeline.wrapAndCopyInto
  [23] ReduceOps$ReduceOp.evaluateSequential
  [24] AbstractPipeline.evaluate
  [25] IntPipeline.reduce
  [26] IntPipeline.sum
  [27] Cell.calculateNextState
  [28] Cell.run
  [29] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [30] ThreadPoolExecutor.runWorker
  [31] ThreadPoolExecutor$Worker.run
  [32] Thread.run

--- 4397685 total (0.08%), 4412 samples
  [ 0] rcu_note_context_switch_[k]
  [ 1] __schedule_[k]
  [ 2] schedule_[k]
  [ 3] futex_wait_queue_[k]
  [ 4] futex_wait_[k]
  [ 5] do_futex_[k]
  [ 6] __x64_sys_futex_[k]
  [ 7] do_syscall_64_[k]
  [ 8] entry_SYSCALL_64_after_hwframe_[k]
  [ 9] __futex_abstimed_wait_common
  [10] Unsafe.park
  [11] LockSupport.park
  [12] AbstractQueuedSynchronizer$ConditionNode.block
  [13] ForkJoinPool.unmanagedBlock
  [14] ForkJoinPool.managedBlock
  [15] AbstractQueuedSynchronizer$ConditionObject.await
  [16] LockedSingleValue.take
  [17] Channel.take
  [18] Cell$$Lambda$61.0x0000000801036dd0.apply
  [19] ReferencePipeline$3$1.accept
  [20] ArrayList$ArrayListSpliterator.forEachRemaining
  [21] AbstractPipeline.copyInto
  [22] AbstractPipeline.wrapAndCopyInto
  [23] ReduceOps$ReduceOp.evaluateSequential
  [24] AbstractPipeline.evaluate
  [25] IntPipeline.reduce
  [26] IntPipeline.sum
  [27] Cell.calculateNextState
  [28] Cell.run
  [29] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [30] ThreadPoolExecutor.runWorker
  [31] ThreadPoolExecutor$Worker.run
  [32] Thread.run

--- 4311267 total (0.07%), 4328 samples
  [ 0] futex_q_lock_[k]
  [ 1] futex_wait_setup_[k]
  [ 2] futex_wait_[k]
  [ 3] do_futex_[k]
  [ 4] __x64_sys_futex_[k]
  [ 5] do_syscall_64_[k]
  [ 6] entry_SYSCALL_64_after_hwframe_[k]
  [ 7] __futex_abstimed_wait_common
  [ 8] Unsafe.park
  [ 9] LockSupport.park
  [10] AbstractQueuedSynchronizer$ConditionNode.block
  [11] ForkJoinPool.unmanagedBlock
  [12] ForkJoinPool.managedBlock
  [13] AbstractQueuedSynchronizer$ConditionObject.await
  [14] LockedSingleValue.take
  [15] Channel.take
  [16] Cell$$Lambda$61.0x0000000801036dd0.apply
  [17] ReferencePipeline$3$1.accept
  [18] ArrayList$ArrayListSpliterator.forEachRemaining
  [19] AbstractPipeline.copyInto
  [20] AbstractPipeline.wrapAndCopyInto
  [21] ReduceOps$ReduceOp.evaluateSequential
  [22] AbstractPipeline.evaluate
  [23] IntPipeline.reduce
  [24] IntPipeline.sum
  [25] Cell.calculateNextState
  [26] Cell.run
  [27] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [28] ThreadPoolExecutor.runWorker
  [29] ThreadPoolExecutor$Worker.run
  [30] Thread.run

--- 4300786 total (0.07%), 4313 samples
  [ 0] task_h_load_[k]
  [ 1] select_task_rq_fair_[k]
  [ 2] try_to_wake_up_[k]
  [ 3] wake_up_q_[k]
  [ 4] futex_wake_[k]
  [ 5] do_futex_[k]
  [ 6] __x64_sys_futex_[k]
  [ 7] do_syscall_64_[k]
  [ 8] entry_SYSCALL_64_after_hwframe_[k]
  [ 9] ___pthread_cond_signal
  [10] Unsafe.unpark
  [11] LockSupport.unpark
  [12] AbstractQueuedSynchronizer.signalNext
  [13] AbstractQueuedSynchronizer.release
  [14] ReentrantLock.unlock
  [15] LockedSingleValue.put
  [16] Channel.put
  [17] Cell.lambda$notifyLiveness$0
  [18] Cell$$Lambda$51.0x0000000801035cd0.accept
  [19] ArrayList.forEach
  [20] Cell.notifyLiveness
  [21] Cell.run
  [22] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [23] ThreadPoolExecutor.runWorker
  [24] ThreadPoolExecutor$Worker.run
  [25] Thread.run

--- 4254799 total (0.07%), 4260 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.canReacquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 4252473 total (0.07%), 4267 samples
  [ 0] _raw_spin_lock_[k]
  [ 1] raw_spin_rq_lock_nested_[k]
  [ 2] __schedule_[k]
  [ 3] schedule_[k]
  [ 4] futex_wait_queue_[k]
  [ 5] futex_wait_[k]
  [ 6] do_futex_[k]
  [ 7] __x64_sys_futex_[k]
  [ 8] do_syscall_64_[k]
  [ 9] entry_SYSCALL_64_after_hwframe_[k]
  [10] __futex_abstimed_wait_common
  [11] Unsafe.park
  [12] LockSupport.park
  [13] AbstractQueuedSynchronizer$ConditionNode.block
  [14] ForkJoinPool.unmanagedBlock
  [15] ForkJoinPool.managedBlock
  [16] AbstractQueuedSynchronizer$ConditionObject.await
  [17] LockedSingleValue.take
  [18] Channel.take
  [19] Cell$$Lambda$61.0x0000000801036dd0.apply
  [20] ReferencePipeline$3$1.accept
  [21] ArrayList$ArrayListSpliterator.forEachRemaining
  [22] AbstractPipeline.copyInto
  [23] AbstractPipeline.wrapAndCopyInto
  [24] ReduceOps$ReduceOp.evaluateSequential
  [25] AbstractPipeline.evaluate
  [26] IntPipeline.reduce
  [27] IntPipeline.sum
  [28] Cell.calculateNextState
  [29] Cell.run
  [30] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [31] ThreadPoolExecutor.runWorker
  [32] ThreadPoolExecutor$Worker.run
  [33] Thread.run

--- 4131621 total (0.07%), 4129 samples
  [ 0] Cell.calculateNextState
  [ 1] Cell.run
  [ 2] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 3] ThreadPoolExecutor.runWorker
  [ 4] ThreadPoolExecutor$Worker.run
  [ 5] Thread.run

--- 4087078 total (0.07%), 4077 samples
  [ 0] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] Cell.run
  [ 7] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 4085289 total (0.07%), 4102 samples
  [ 0] dequeue_task_fair_[k]
  [ 1] __schedule_[k]
  [ 2] schedule_[k]
  [ 3] futex_wait_queue_[k]
  [ 4] futex_wait_[k]
  [ 5] do_futex_[k]
  [ 6] __x64_sys_futex_[k]
  [ 7] do_syscall_64_[k]
  [ 8] entry_SYSCALL_64_after_hwframe_[k]
  [ 9] __futex_abstimed_wait_common
  [10] Unsafe.park
  [11] LockSupport.park
  [12] AbstractQueuedSynchronizer$ConditionNode.block
  [13] ForkJoinPool.unmanagedBlock
  [14] ForkJoinPool.managedBlock
  [15] AbstractQueuedSynchronizer$ConditionObject.await
  [16] LockedSingleValue.take
  [17] Channel.take
  [18] Cell$$Lambda$61.0x0000000801036dd0.apply
  [19] ReferencePipeline$3$1.accept
  [20] ArrayList$ArrayListSpliterator.forEachRemaining
  [21] AbstractPipeline.copyInto
  [22] AbstractPipeline.wrapAndCopyInto
  [23] ReduceOps$ReduceOp.evaluateSequential
  [24] AbstractPipeline.evaluate
  [25] IntPipeline.reduce
  [26] IntPipeline.sum
  [27] Cell.calculateNextState
  [28] Cell.run
  [29] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [30] ThreadPoolExecutor.runWorker
  [31] ThreadPoolExecutor$Worker.run
  [32] Thread.run

--- 4015501 total (0.07%), 4019 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] TickPerCell.waitTick
  [ 6] Cell.notifyLiveness
  [ 7] Cell.run
  [ 8] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 3981885 total (0.07%), 3994 samples
  [ 0] ForkJoinPool.managedBlock
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] Cell.run
  [ 7] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 3931675 total (0.07%), 3939 samples
  [ 0] __pthread_mutex_cond_lock
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] Cell$$Lambda$61.0x0000000801036dd0.apply
  [10] ReferencePipeline$3$1.accept
  [11] ArrayList$ArrayListSpliterator.forEachRemaining
  [12] AbstractPipeline.copyInto
  [13] AbstractPipeline.wrapAndCopyInto
  [14] ReduceOps$ReduceOp.evaluateSequential
  [15] AbstractPipeline.evaluate
  [16] IntPipeline.reduce
  [17] IntPipeline.sum
  [18] Cell.calculateNextState
  [19] Cell.run
  [20] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [21] ThreadPoolExecutor.runWorker
  [22] ThreadPoolExecutor$Worker.run
  [23] Thread.run

--- 3921397 total (0.07%), 3911 samples
  [ 0] ReferencePipeline.map
  [ 1] Cell.calculateNextState
  [ 2] Cell.run
  [ 3] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 4] ThreadPoolExecutor.runWorker
  [ 5] ThreadPoolExecutor$Worker.run
  [ 6] Thread.run

--- 3919356 total (0.07%), 3911 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] Cell.run
  [ 9] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 3918828 total (0.07%), 3955 samples
  [ 0] ___pthread_cond_signal
  [ 1] Unsafe.unpark
  [ 2] LockSupport.unpark
  [ 3] AbstractQueuedSynchronizer.signalNext
  [ 4] AbstractQueuedSynchronizer.release
  [ 5] ReentrantLock.unlock
  [ 6] LockedSingleValue.put
  [ 7] Channel.put
  [ 8] Cell.lambda$notifyLiveness$0
  [ 9] Cell$$Lambda$51.0x0000000801035cd0.accept
  [10] ArrayList.forEach
  [11] Cell.notifyLiveness
  [12] Cell.run
  [13] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 3789860 total (0.06%), 3802 samples
  [ 0] __list_add_valid_[k]
  [ 1] plist_add_[k]
  [ 2] __futex_queue_[k]
  [ 3] futex_wait_queue_[k]
  [ 4] futex_wait_[k]
  [ 5] do_futex_[k]
  [ 6] __x64_sys_futex_[k]
  [ 7] do_syscall_64_[k]
  [ 8] entry_SYSCALL_64_after_hwframe_[k]
  [ 9] __futex_abstimed_wait_common
  [10] Unsafe.park
  [11] LockSupport.park
  [12] AbstractQueuedSynchronizer$ConditionNode.block
  [13] ForkJoinPool.unmanagedBlock
  [14] ForkJoinPool.managedBlock
  [15] AbstractQueuedSynchronizer$ConditionObject.await
  [16] LockedSingleValue.take
  [17] Channel.take
  [18] Cell$$Lambda$61.0x0000000801036dd0.apply
  [19] ReferencePipeline$3$1.accept
  [20] ArrayList$ArrayListSpliterator.forEachRemaining
  [21] AbstractPipeline.copyInto
  [22] AbstractPipeline.wrapAndCopyInto
  [23] ReduceOps$ReduceOp.evaluateSequential
  [24] AbstractPipeline.evaluate
  [25] IntPipeline.reduce
  [26] IntPipeline.sum
  [27] Cell.calculateNextState
  [28] Cell.run
  [29] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [30] ThreadPoolExecutor.runWorker
  [31] ThreadPoolExecutor$Worker.run
  [32] Thread.run

--- 3749393 total (0.06%), 3766 samples
  [ 0] Unsafe.getAndBitwiseAndInt
  [ 1] AbstractQueuedSynchronizer$Node.getAndUnsetStatus
  [ 2] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 3] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 3742701 total (0.06%), 3751 samples
  [ 0] plist_add_[k]
  [ 1] __futex_queue_[k]
  [ 2] futex_wait_queue_[k]
  [ 3] futex_wait_[k]
  [ 4] do_futex_[k]
  [ 5] __x64_sys_futex_[k]
  [ 6] do_syscall_64_[k]
  [ 7] entry_SYSCALL_64_after_hwframe_[k]
  [ 8] __futex_abstimed_wait_common
  [ 9] Unsafe.park
  [10] LockSupport.park
  [11] AbstractQueuedSynchronizer$ConditionNode.block
  [12] ForkJoinPool.unmanagedBlock
  [13] ForkJoinPool.managedBlock
  [14] AbstractQueuedSynchronizer$ConditionObject.await
  [15] LockedSingleValue.take
  [16] Channel.take
  [17] TickPerCell.waitTick
  [18] Cell.notifyLiveness
  [19] Cell.run
  [20] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [21] ThreadPoolExecutor.runWorker
  [22] ThreadPoolExecutor$Worker.run
  [23] Thread.run

--- 3719336 total (0.06%), 3732 samples
  [ 0] ReentrantLock$Sync.lock
  [ 1] ReentrantLock.lock
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 3658849 total (0.06%), 3655 samples
  [ 0] blkcg_maybe_throttle_current_[k]
  [ 1] exit_to_user_mode_prepare_[k]
  [ 2] syscall_exit_to_user_mode_[k]
  [ 3] do_syscall_64_[k]
  [ 4] entry_SYSCALL_64_after_hwframe_[k]
  [ 5] __futex_abstimed_wait_common
  [ 6] Unsafe.park
  [ 7] LockSupport.park
  [ 8] AbstractQueuedSynchronizer$ConditionNode.block
  [ 9] ForkJoinPool.unmanagedBlock
  [10] ForkJoinPool.managedBlock
  [11] AbstractQueuedSynchronizer$ConditionObject.await
  [12] LockedSingleValue.take
  [13] Channel.take
  [14] TickPerCell.waitTick
  [15] Cell.notifyLiveness
  [16] Cell.run
  [17] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 3605982 total (0.06%), 3587 samples
  [ 0] __futex_abstimed_wait_common
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] TickPerCell.waitTick
  [10] Cell.notifyLiveness
  [11] Cell.run
  [12] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 3600528 total (0.06%), 3587 samples
  [ 0] check_preemption_disabled_[k]
  [ 1] fpregs_restore_userregs_[k]
  [ 2] exit_to_user_mode_prepare_[k]
  [ 3] syscall_exit_to_user_mode_[k]
  [ 4] do_syscall_64_[k]
  [ 5] entry_SYSCALL_64_after_hwframe_[k]
  [ 6] __futex_abstimed_wait_common
  [ 7] Unsafe.park
  [ 8] LockSupport.park
  [ 9] AbstractQueuedSynchronizer$ConditionNode.block
  [10] ForkJoinPool.unmanagedBlock
  [11] ForkJoinPool.managedBlock
  [12] AbstractQueuedSynchronizer$ConditionObject.await
  [13] LockedSingleValue.take
  [14] Channel.take
  [15] TickPerCell.waitTick
  [16] Cell.notifyLiveness
  [17] Cell.run
  [18] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [19] ThreadPoolExecutor.runWorker
  [20] ThreadPoolExecutor$Worker.run
  [21] Thread.run

--- 3554784 total (0.06%), 3562 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] Cell.run
  [13] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 3533738 total (0.06%), 3571 samples
  [ 0] native_write_msr_[k]
  [ 1] intel_pmu_disable_all_[k]
  [ 2] __perf_event_task_sched_out_[k]
  [ 3] __schedule_[k]
  [ 4] schedule_[k]
  [ 5] futex_wait_queue_[k]
  [ 6] futex_wait_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] __futex_abstimed_wait_common
  [12] Unsafe.park
  [13] LockSupport.park
  [14] AbstractQueuedSynchronizer$ConditionNode.block
  [15] ForkJoinPool.unmanagedBlock
  [16] ForkJoinPool.managedBlock
  [17] AbstractQueuedSynchronizer$ConditionObject.await
  [18] LockedSingleValue.take
  [19] Channel.take
  [20] Cell$$Lambda$61.0x0000000801036dd0.apply
  [21] ReferencePipeline$3$1.accept
  [22] ArrayList$ArrayListSpliterator.forEachRemaining
  [23] AbstractPipeline.copyInto
  [24] AbstractPipeline.wrapAndCopyInto
  [25] ReduceOps$ReduceOp.evaluateSequential
  [26] AbstractPipeline.evaluate
  [27] IntPipeline.reduce
  [28] IntPipeline.sum
  [29] Cell.calculateNextState
  [30] Cell.run
  [31] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [32] ThreadPoolExecutor.runWorker
  [33] ThreadPoolExecutor$Worker.run
  [34] Thread.run

--- 3471179 total (0.06%), 3453 samples
  [ 0] exit_to_user_mode_prepare_[k]
  [ 1] syscall_exit_to_user_mode_[k]
  [ 2] do_syscall_64_[k]
  [ 3] entry_SYSCALL_64_after_hwframe_[k]
  [ 4] __futex_abstimed_wait_common
  [ 5] Unsafe.park
  [ 6] LockSupport.park
  [ 7] AbstractQueuedSynchronizer$ConditionNode.block
  [ 8] ForkJoinPool.unmanagedBlock
  [ 9] ForkJoinPool.managedBlock
  [10] AbstractQueuedSynchronizer$ConditionObject.await
  [11] LockedSingleValue.take
  [12] Channel.take
  [13] TickPerCell.waitTick
  [14] Cell.notifyLiveness
  [15] Cell.run
  [16] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

--- 3399621 total (0.06%), 3413 samples
  [ 0] __pthread_mutex_unlock_usercnt
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] Cell$$Lambda$61.0x0000000801036dd0.apply
  [11] ReferencePipeline$3$1.accept
  [12] ArrayList$ArrayListSpliterator.forEachRemaining
  [13] AbstractPipeline.copyInto
  [14] AbstractPipeline.wrapAndCopyInto
  [15] ReduceOps$ReduceOp.evaluateSequential
  [16] AbstractPipeline.evaluate
  [17] IntPipeline.reduce
  [18] IntPipeline.sum
  [19] Cell.calculateNextState
  [20] Cell.run
  [21] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 3371715 total (0.06%), 3396 samples
  [ 0] LockedSingleValue.take
  [ 1] [unknown_Java]

--- 3361248 total (0.06%), 3366 samples
  [ 0] Objects.requireNonNull
  [ 1] StreamSupport.stream
  [ 2] Collection.stream
  [ 3] Cell.calculateNextState
  [ 4] Cell.run
  [ 5] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 3360842 total (0.06%), 3373 samples
  [ 0] enqueue_entity_[k]
  [ 1] enqueue_task_fair_[k]
  [ 2] enqueue_task_[k]
  [ 3] ttwu_do_activate_[k]
  [ 4] try_to_wake_up_[k]
  [ 5] wake_up_q_[k]
  [ 6] futex_wake_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] ___pthread_cond_signal
  [12] Unsafe.unpark
  [13] LockSupport.unpark
  [14] AbstractQueuedSynchronizer.signalNext
  [15] AbstractQueuedSynchronizer.release
  [16] ReentrantLock.unlock
  [17] LockedSingleValue.put
  [18] Channel.put
  [19] Cell.lambda$notifyLiveness$0
  [20] Cell$$Lambda$51.0x0000000801035cd0.accept
  [21] ArrayList.forEach
  [22] Cell.notifyLiveness
  [23] Cell.run
  [24] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [25] ThreadPoolExecutor.runWorker
  [26] ThreadPoolExecutor$Worker.run
  [27] Thread.run

--- 3337303 total (0.06%), 3355 samples
  [ 0] Sink$ChainedReference.end
  [ 1] Sink$ChainedReference.end
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] Cell.run
  [10] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 3330942 total (0.06%), 3344 samples
  [ 0] update_curr_[k]
  [ 1] dequeue_entity_[k]
  [ 2] dequeue_task_fair_[k]
  [ 3] __schedule_[k]
  [ 4] schedule_[k]
  [ 5] futex_wait_queue_[k]
  [ 6] futex_wait_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] __futex_abstimed_wait_common
  [12] Unsafe.park
  [13] LockSupport.park
  [14] AbstractQueuedSynchronizer$ConditionNode.block
  [15] ForkJoinPool.unmanagedBlock
  [16] ForkJoinPool.managedBlock
  [17] AbstractQueuedSynchronizer$ConditionObject.await
  [18] LockedSingleValue.take
  [19] Channel.take
  [20] Cell$$Lambda$61.0x0000000801036dd0.apply
  [21] ReferencePipeline$3$1.accept
  [22] ArrayList$ArrayListSpliterator.forEachRemaining
  [23] AbstractPipeline.copyInto
  [24] AbstractPipeline.wrapAndCopyInto
  [25] ReduceOps$ReduceOp.evaluateSequential
  [26] AbstractPipeline.evaluate
  [27] IntPipeline.reduce
  [28] IntPipeline.sum
  [29] Cell.calculateNextState
  [30] Cell.run
  [31] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [32] ThreadPoolExecutor.runWorker
  [33] ThreadPoolExecutor$Worker.run
  [34] Thread.run

--- 3313163 total (0.06%), 3328 samples
  [ 0] AbstractQueuedSynchronizer.acquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 3283615 total (0.06%), 3290 samples
  [ 0] __perf_event_task_sched_out_[k]
  [ 1] __schedule_[k]
  [ 2] schedule_[k]
  [ 3] futex_wait_queue_[k]
  [ 4] futex_wait_[k]
  [ 5] do_futex_[k]
  [ 6] __x64_sys_futex_[k]
  [ 7] do_syscall_64_[k]
  [ 8] entry_SYSCALL_64_after_hwframe_[k]
  [ 9] __futex_abstimed_wait_common
  [10] Unsafe.park
  [11] LockSupport.park
  [12] AbstractQueuedSynchronizer$ConditionNode.block
  [13] ForkJoinPool.unmanagedBlock
  [14] ForkJoinPool.managedBlock
  [15] AbstractQueuedSynchronizer$ConditionObject.await
  [16] LockedSingleValue.take
  [17] Channel.take
  [18] TickPerCell.waitTick
  [19] Cell.notifyLiveness
  [20] Cell.run
  [21] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 3271510 total (0.06%), 3263 samples
  [ 0] mem_cgroup_handle_over_high_[k]
  [ 1] exit_to_user_mode_prepare_[k]
  [ 2] syscall_exit_to_user_mode_[k]
  [ 3] do_syscall_64_[k]
  [ 4] entry_SYSCALL_64_after_hwframe_[k]
  [ 5] __futex_abstimed_wait_common
  [ 6] Unsafe.park
  [ 7] LockSupport.park
  [ 8] AbstractQueuedSynchronizer$ConditionNode.block
  [ 9] ForkJoinPool.unmanagedBlock
  [10] ForkJoinPool.managedBlock
  [11] AbstractQueuedSynchronizer$ConditionObject.await
  [12] LockedSingleValue.take
  [13] Channel.take
  [14] TickPerCell.waitTick
  [15] Cell.notifyLiveness
  [16] Cell.run
  [17] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 3269368 total (0.06%), 3302 samples
  [ 0] ThreadsListHandle::ThreadsListHandle(Thread*)
  [ 1] Unsafe_Unpark
  [ 2] Unsafe.unpark
  [ 3] LockSupport.unpark
  [ 4] AbstractQueuedSynchronizer.signalNext
  [ 5] AbstractQueuedSynchronizer.release
  [ 6] ReentrantLock.unlock
  [ 7] LockedSingleValue.put
  [ 8] Channel.put
  [ 9] Cell.lambda$notifyLiveness$0
  [10] Cell$$Lambda$51.0x0000000801035cd0.accept
  [11] ArrayList.forEach
  [12] Cell.notifyLiveness
  [13] Cell.run
  [14] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [15] ThreadPoolExecutor.runWorker
  [16] ThreadPoolExecutor$Worker.run
  [17] Thread.run

--- 3249907 total (0.06%), 3256 samples
  [ 0] __pthread_mutex_cond_lock
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] TickPerCell.waitTick
  [10] Cell.notifyLiveness
  [11] Cell.run
  [12] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 3199852 total (0.05%), 3211 samples
  [ 0] update_rq_clock_[k]
  [ 1] __schedule_[k]
  [ 2] schedule_[k]
  [ 3] futex_wait_queue_[k]
  [ 4] futex_wait_[k]
  [ 5] do_futex_[k]
  [ 6] __x64_sys_futex_[k]
  [ 7] do_syscall_64_[k]
  [ 8] entry_SYSCALL_64_after_hwframe_[k]
  [ 9] __futex_abstimed_wait_common
  [10] Unsafe.park
  [11] LockSupport.park
  [12] AbstractQueuedSynchronizer$ConditionNode.block
  [13] ForkJoinPool.unmanagedBlock
  [14] ForkJoinPool.managedBlock
  [15] AbstractQueuedSynchronizer$ConditionObject.await
  [16] LockedSingleValue.take
  [17] Channel.take
  [18] Cell$$Lambda$61.0x0000000801036dd0.apply
  [19] ReferencePipeline$3$1.accept
  [20] ArrayList$ArrayListSpliterator.forEachRemaining
  [21] AbstractPipeline.copyInto
  [22] AbstractPipeline.wrapAndCopyInto
  [23] ReduceOps$ReduceOp.evaluateSequential
  [24] AbstractPipeline.evaluate
  [25] IntPipeline.reduce
  [26] IntPipeline.sum
  [27] Cell.calculateNextState
  [28] Cell.run
  [29] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [30] ThreadPoolExecutor.runWorker
  [31] ThreadPoolExecutor$Worker.run
  [32] Thread.run

--- 3180585 total (0.05%), 3195 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] Cell.run
  [ 4] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 5] ThreadPoolExecutor.runWorker
  [ 6] ThreadPoolExecutor$Worker.run
  [ 7] Thread.run

--- 3139049 total (0.05%), 3153 samples
  [ 0] AbstractQueuedSynchronizer.casTail
  [ 1] AbstractQueuedSynchronizer.enqueue
  [ 2] AbstractQueuedSynchronizer$ConditionObject.doSignal
  [ 3] AbstractQueuedSynchronizer$ConditionObject.signal
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 3090178 total (0.05%), 3103 samples
  [ 0] AbstractQueuedSynchronizer.acquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] Cell.run
  [ 7] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 3058330 total (0.05%), 3068 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] Cell.run
  [10] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 3049635 total (0.05%), 3063 samples
  [ 0] AbstractQueuedSynchronizer.signalNext
  [ 1] AbstractQueuedSynchronizer.release
  [ 2] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 3] AbstractQueuedSynchronizer$ConditionObject.await
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] Cell.run
  [17] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 2995249 total (0.05%), 3014 samples
  [ 0] futex_wait_queue_[k]
  [ 1] futex_wait_[k]
  [ 2] do_futex_[k]
  [ 3] __x64_sys_futex_[k]
  [ 4] do_syscall_64_[k]
  [ 5] entry_SYSCALL_64_after_hwframe_[k]
  [ 6] __futex_abstimed_wait_common
  [ 7] Unsafe.park
  [ 8] LockSupport.park
  [ 9] AbstractQueuedSynchronizer$ConditionNode.block
  [10] ForkJoinPool.unmanagedBlock
  [11] ForkJoinPool.managedBlock
  [12] AbstractQueuedSynchronizer$ConditionObject.await
  [13] LockedSingleValue.take
  [14] Channel.take
  [15] Cell$$Lambda$61.0x0000000801036dd0.apply
  [16] ReferencePipeline$3$1.accept
  [17] ArrayList$ArrayListSpliterator.forEachRemaining
  [18] AbstractPipeline.copyInto
  [19] AbstractPipeline.wrapAndCopyInto
  [20] ReduceOps$ReduceOp.evaluateSequential
  [21] AbstractPipeline.evaluate
  [22] IntPipeline.reduce
  [23] IntPipeline.sum
  [24] Cell.calculateNextState
  [25] Cell.run
  [26] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [27] ThreadPoolExecutor.runWorker
  [28] ThreadPoolExecutor$Worker.run
  [29] Thread.run

--- 2930868 total (0.05%), 2943 samples
  [ 0] cpuacct_charge_[k]
  [ 1] update_curr_[k]
  [ 2] dequeue_entity_[k]
  [ 3] dequeue_task_fair_[k]
  [ 4] __schedule_[k]
  [ 5] schedule_[k]
  [ 6] futex_wait_queue_[k]
  [ 7] futex_wait_[k]
  [ 8] do_futex_[k]
  [ 9] __x64_sys_futex_[k]
  [10] do_syscall_64_[k]
  [11] entry_SYSCALL_64_after_hwframe_[k]
  [12] __futex_abstimed_wait_common
  [13] Unsafe.park
  [14] LockSupport.park
  [15] AbstractQueuedSynchronizer$ConditionNode.block
  [16] ForkJoinPool.unmanagedBlock
  [17] ForkJoinPool.managedBlock
  [18] AbstractQueuedSynchronizer$ConditionObject.await
  [19] LockedSingleValue.take
  [20] Channel.take
  [21] Cell$$Lambda$61.0x0000000801036dd0.apply
  [22] ReferencePipeline$3$1.accept
  [23] ArrayList$ArrayListSpliterator.forEachRemaining
  [24] AbstractPipeline.copyInto
  [25] AbstractPipeline.wrapAndCopyInto
  [26] ReduceOps$ReduceOp.evaluateSequential
  [27] AbstractPipeline.evaluate
  [28] IntPipeline.reduce
  [29] IntPipeline.sum
  [30] Cell.calculateNextState
  [31] Cell.run
  [32] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [33] ThreadPoolExecutor.runWorker
  [34] ThreadPoolExecutor$Worker.run
  [35] Thread.run

--- 2914844 total (0.05%), 2926 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] Cell.run
  [12] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 2909553 total (0.05%), 2931 samples
  [ 0] Unsafe.getAndBitwiseAndInt
  [ 1] AbstractQueuedSynchronizer$Node.getAndUnsetStatus
  [ 2] AbstractQueuedSynchronizer.signalNext
  [ 3] AbstractQueuedSynchronizer.release
  [ 4] ReentrantLock.unlock
  [ 5] LockedSingleValue.put
  [ 6] Channel.put
  [ 7] Cell.lambda$notifyLiveness$0
  [ 8] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 9] ArrayList.forEach
  [10] Cell.notifyLiveness
  [11] Cell.run
  [12] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 2903383 total (0.05%), 2915 samples
  [ 0] __tls_get_addr
  [ 1] Unsafe.unpark
  [ 2] LockSupport.unpark
  [ 3] AbstractQueuedSynchronizer.signalNext
  [ 4] AbstractQueuedSynchronizer.release
  [ 5] ReentrantLock.unlock
  [ 6] LockedSingleValue.put
  [ 7] Channel.put
  [ 8] Cell.lambda$notifyLiveness$0
  [ 9] Cell$$Lambda$51.0x0000000801035cd0.accept
  [10] ArrayList.forEach
  [11] Cell.notifyLiveness
  [12] Cell.run
  [13] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 2882602 total (0.05%), 2899 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$Head.<init>
  [ 3] StreamSupport.stream
  [ 4] Collection.stream
  [ 5] Cell.calculateNextState
  [ 6] Cell.run
  [ 7] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 2879492 total (0.05%), 2891 samples
  [ 0] AbstractQueuedSynchronizer.acquire
  [ 1] AbstractQueuedSynchronizer$ConditionObject.await
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$61.0x0000000801036dd0.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] Cell.run
  [15] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 2823931 total (0.05%), 2833 samples
  [ 0] native_sched_clock_[k]
  [ 1] sched_clock_cpu_[k]
  [ 2] update_rq_clock_[k]
  [ 3] __schedule_[k]
  [ 4] schedule_[k]
  [ 5] futex_wait_queue_[k]
  [ 6] futex_wait_[k]
  [ 7] do_futex_[k]
  [ 8] __x64_sys_futex_[k]
  [ 9] do_syscall_64_[k]
  [10] entry_SYSCALL_64_after_hwframe_[k]
  [11] __futex_abstimed_wait_common
  [12] Unsafe.park
  [13] LockSupport.park
  [14] AbstractQueuedSynchronizer$ConditionNode.block
  [15] ForkJoinPool.unmanagedBlock
  [16] ForkJoinPool.managedBlock
  [17] AbstractQueuedSynchronizer$ConditionObject.await
  [18] LockedSingleValue.take
  [19] Channel.take
  [20] Cell$$Lambda$61.0x0000000801036dd0.apply
  [21] ReferencePipeline$3$1.accept
  [22] ArrayList$ArrayListSpliterator.forEachRemaining
  [23] AbstractPipeline.copyInto
  [24] AbstractPipeline.wrapAndCopyInto
  [25] ReduceOps$ReduceOp.evaluateSequential
  [26] AbstractPipeline.evaluate
  [27] IntPipeline.reduce
  [28] IntPipeline.sum
  [29] Cell.calculateNextState
  [30] Cell.run
  [31] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [32] ThreadPoolExecutor.runWorker
  [33] ThreadPoolExecutor$Worker.run
  [34] Thread.run

--- 2802354 total (0.05%), 2821 samples
  [ 0] LockSupport.unpark
  [ 1] AbstractQueuedSynchronizer.signalNext
  [ 2] AbstractQueuedSynchronizer.release
  [ 3] ReentrantLock.unlock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$51.0x0000000801035cd0.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] Cell.run
  [11] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 2749315 total (0.05%), 2744 samples
  [ 0] Unsafe.park
  [ 1] [unknown_Java]

--- 2748514 total (0.05%), 2737 samples
  [ 0] exit_to_user_mode_prepare_[k]
  [ 1] syscall_exit_to_user_mode_[k]
  [ 2] do_syscall_64_[k]
  [ 3] entry_SYSCALL_64_after_hwframe_[k]
  [ 4] __futex_abstimed_wait_common
  [ 5] Unsafe.park
  [ 6] LockSupport.park
  [ 7] AbstractQueuedSynchronizer$ConditionNode.block
  [ 8] ForkJoinPool.unmanagedBlock
  [ 9] ForkJoinPool.managedBlock
  [10] AbstractQueuedSynchronizer$ConditionObject.await
  [11] LockedSingleValue.take
  [12] Channel.take
  [13] Cell$$Lambda$61.0x0000000801036dd0.apply
  [14] ReferencePipeline$3$1.accept
  [15] ArrayList$ArrayListSpliterator.forEachRemaining
  [16] AbstractPipeline.copyInto
  [17] AbstractPipeline.wrapAndCopyInto
  [18] ReduceOps$ReduceOp.evaluateSequential
  [19] AbstractPipeline.evaluate
  [20] IntPipeline.reduce
  [21] IntPipeline.sum
  [22] Cell.calculateNextState
  [23] Cell.run
  [24] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [25] ThreadPoolExecutor.runWorker
  [26] ThreadPoolExecutor$Worker.run
  [27] Thread.run

--- 2743016 total (0.05%), 2749 samples
  [ 0] __condvar_confirm_wakeup
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] Cell$$Lambda$61.0x0000000801036dd0.apply
  [10] ReferencePipeline$3$1.accept
  [11] ArrayList$ArrayListSpliterator.forEachRemaining
  [12] AbstractPipeline.copyInto
  [13] AbstractPipeline.wrapAndCopyInto
  [14] ReduceOps$ReduceOp.evaluateSequential
  [15] AbstractPipeline.evaluate
  [16] IntPipeline.reduce
  [17] IntPipeline.sum
  [18] Cell.calculateNextState
  [19] Cell.run
  [20] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [21] ThreadPoolExecutor.runWorker
  [22] ThreadPoolExecutor$Worker.run
  [23] Thread.run

--- 2711964 total (0.05%), 2727 samples
  [ 0] syscall_exit_to_user_mode_[k]
  [ 1] do_syscall_64_[k]
  [ 2] entry_SYSCALL_64_after_hwframe_[k]
  [ 3] ___pthread_cond_signal
  [ 4] Unsafe.unpark
  [ 5] LockSupport.unpark
  [ 6] AbstractQueuedSynchronizer.signalNext
  [ 7] AbstractQueuedSynchronizer.release
  [ 8] ReentrantLock.unlock
  [ 9] LockedSingleValue.put
  [10] Channel.put
  [11] Cell.lambda$notifyLiveness$0
  [12] Cell$$Lambda$51.0x0000000801035cd0.accept
  [13] ArrayList.forEach
  [14] Cell.notifyLiveness
  [15] Cell.run
  [16] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

--- 2699964 total (0.05%), 2696 samples
  [ 0] __GI___pthread_getspecific
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] TickPerCell.waitTick
  [11] Cell.notifyLiveness
  [12] Cell.run
  [13] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 2692585 total (0.05%), 2687 samples
  [ 0] ReentrantLock$Sync.isHeldExclusively
  [ 1] AbstractQueuedSynchronizer$ConditionObject.enableWait
  [ 2] AbstractQueuedSynchronizer$ConditionObject.await
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] TickPerCell.waitTick
  [ 6] Cell.notifyLiveness
  [ 7] Cell.run
  [ 8] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 2691948 total (0.05%), 2702 samples
  [ 0] __GI___pthread_getspecific
  [ 1] Unsafe_Park
  [ 2] Unsafe.park
  [ 3] LockSupport.park
  [ 4] AbstractQueuedSynchronizer$ConditionNode.block
  [ 5] ForkJoinPool.unmanagedBlock
  [ 6] ForkJoinPool.managedBlock
  [ 7] AbstractQueuedSynchronizer$ConditionObject.await
  [ 8] LockedSingleValue.take
  [ 9] Channel.take
  [10] Cell$$Lambda$61.0x0000000801036dd0.apply
  [11] ReferencePipeline$3$1.accept
  [12] ArrayList$ArrayListSpliterator.forEachRemaining
  [13] AbstractPipeline.copyInto
  [14] AbstractPipeline.wrapAndCopyInto
  [15] ReduceOps$ReduceOp.evaluateSequential
  [16] AbstractPipeline.evaluate
  [17] IntPipeline.reduce
  [18] IntPipeline.sum
  [19] Cell.calculateNextState
  [20] Cell.run
  [21] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 2615922 total (0.04%), 2629 samples
  [ 0] __pthread_mutex_unlock_usercnt
  [ 1] Unsafe.park
  [ 2] LockSupport.park
  [ 3] AbstractQueuedSynchronizer$ConditionNode.block
  [ 4] ForkJoinPool.unmanagedBlock
  [ 5] ForkJoinPool.managedBlock
  [ 6] AbstractQueuedSynchronizer$ConditionObject.await
  [ 7] LockedSingleValue.take
  [ 8] Channel.take
  [ 9] Cell$$Lambda$61.0x0000000801036dd0.apply
  [10] ReferencePipeline$3$1.accept
  [11] ArrayList$ArrayListSpliterator.forEachRemaining
  [12] AbstractPipeline.copyInto
  [13] AbstractPipeline.wrapAndCopyInto
  [14] ReduceOps$ReduceOp.evaluateSequential
  [15] AbstractPipeline.evaluate
  [16] IntPipeline.reduce
  [17] IntPipeline.sum
  [18] Cell.calculateNextState
  [19] Cell.run
  [20] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [21] ThreadPoolExecutor.runWorker
  [22] ThreadPoolExecutor$Worker.run
  [23] Thread.run

--- 2613109 total (0.04%), 2622 samples
  [ 0] PipelineHelper.<init>
  [ 1] AbstractPipeline.<init>
  [ 2] ReferencePipeline.<init>
  [ 3] ReferencePipeline$Head.<init>
  [ 4] StreamSupport.stream
  [ 5] Collection.stream
  [ 6] Cell.calculateNextState
  [ 7] Cell.run
  [ 8] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 2603595 total (0.04%), 2601 samples
  [ 0] __put_user_nocheck_8_[k]
  [ 1] __rseq_handle_notify_resume_[k]
  [ 2] exit_to_user_mode_prepare_[k]
  [ 3] syscall_exit_to_user_mode_[k]
  [ 4] do_syscall_64_[k]
  [ 5] entry_SYSCALL_64_after_hwframe_[k]
  [ 6] __futex_abstimed_wait_common
  [ 7] Unsafe.park
  [ 8] LockSupport.park
  [ 9] AbstractQueuedSynchronizer$ConditionNode.block
  [10] ForkJoinPool.unmanagedBlock
  [11] ForkJoinPool.managedBlock
  [12] AbstractQueuedSynchronizer$ConditionObject.await
  [13] LockedSingleValue.take
  [14] Channel.take
  [15] Cell$$Lambda$61.0x0000000801036dd0.apply
  [16] ReferencePipeline$3$1.accept
  [17] ArrayList$ArrayListSpliterator.forEachRemaining
  [18] AbstractPipeline.copyInto
  [19] AbstractPipeline.wrapAndCopyInto
  [20] ReduceOps$ReduceOp.evaluateSequential
  [21] AbstractPipeline.evaluate
  [22] IntPipeline.reduce
  [23] IntPipeline.sum
  [24] Cell.calculateNextState
  [25] Cell.run
  [26] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [27] ThreadPoolExecutor.runWorker
  [28] ThreadPoolExecutor$Worker.run
  [29] Thread.run

--- 2601300 total (0.04%), 2610 samples
  [ 0] Cell.run
  [ 1] ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
  [ 2] ThreadPoolExecutor.runWorker
  [ 3] ThreadPoolExecutor$Worker.run
  [ 4] Thread.run

       total  percent  samples  top
  ----------  -------  -------  ---
  2096662391   35.89%  2092763  Unsafe.park
   944988421   16.18%   946166  Unsafe.unpark
   248026766    4.25%   248711  Cell.lambda$notifyLiveness$0
   243542843    4.17%   244478  AbstractQueuedSynchronizer.compareAndSetState
   103761607    1.78%   103837  AbstractQueuedSynchronizer.acquire
   100130792    1.71%   100436  ReduceOps$5ReducingSink.get
    84504048    1.45%    83387  restore_fpregs_from_fpstate_[k]
    82498254    1.41%    82758  AbstractQueuedSynchronizer.release
    80421884    1.38%    80127  Unsafe_Park
    66778947    1.14%    66840  AbstractQueuedSynchronizer$ConditionObject.enableWait
    66638766    1.14%    66750  AbstractOwnableSynchronizer.setExclusiveOwnerThread
    63437198    1.09%    63574  LockedSingleValue.take
    62507852    1.07%    62688  AbstractQueuedSynchronizer.signalNext
    60660578    1.04%    60873  futex_wake_[k]
    59011061    1.01%    59006  AbstractQueuedSynchronizer$ConditionObject.doSignal
    58580486    1.00%    58471  Parker::park(bool, long)
    48731356    0.83%    48530  __condvar_dec_grefs
    46872920    0.80%    46974  AbstractQueuedSynchronizer.enqueue
    42859630    0.73%    42899  Channel.take
    39767246    0.68%    39867  Unsafe.getAndBitwiseAndInt
    36522436    0.63%    36620  Cell$$Lambda$61.0x0000000801036dd0.apply
    35367440    0.61%    35169  __get_user_8_[k]
    35228242    0.60%    35261  syscall_exit_to_user_mode_[k]
    34163860    0.58%    33879  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<286822ul, G1BarrierSet>, (AccessInternal::BarrierType)3, 286822ul>::oop_access_barrier(oopDesc*, long)
    33136702    0.57%    33157  ReentrantLock$NonfairSync.initialTryLock
    32189677    0.55%    32177  AbstractQueuedSynchronizer$ConditionObject.await
    31241152    0.53%    31227  ReferencePipeline$3$1.accept
    30422068    0.52%    30412  StreamSupport.stream
    28818522    0.49%    28792  ReferencePipeline$4$1.accept
    28639348    0.49%    28763  __entry_text_start_[k]
    27556625    0.47%    27650  ___pthread_cond_wait
    24861959    0.43%    24861  TickPerCell.lambda$tick$0
    24079507    0.41%    23852  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<548964ul, G1BarrierSet>, (AccessInternal::BarrierType)2, 548964ul>::oop_access_barrier(void*)
    21009802    0.36%    21115  psi_group_change_[k]
    18216189    0.31%    18174  fpregs_restore_userregs_[k]
    18127397    0.31%    18134  AbstractQueuedSynchronizer$ConditionNode.isReleasable
    17307675    0.30%    17351  __schedule_[k]
    16943850    0.29%    17008  _raw_spin_lock_[k]
    16766084    0.29%    16791  __rseq_handle_notify_resume_[k]
    16011203    0.27%    15938  __GI___pthread_disable_asynccancel
    15953175    0.27%    15951  check_preemption_disabled_[k]
    14807187    0.25%    14830  AbstractQueuedSynchronizer$ConditionObject.canReacquire
    14474732    0.25%    14531  Cell.run
    14424978    0.25%    14510  LockSupport.unpark
    14176462    0.24%    14206  plist_add_[k]
    14070166    0.24%    14089  AbstractQueuedSynchronizer.casTail
    12960508    0.22%    12900  JavaThread::threadObj() const
    12512479    0.21%    12548  AbstractPipeline.<init>
    12243267    0.21%    12235  Objects.requireNonNull
    11832468    0.20%    11837  ArrayList$ArrayListSpliterator.forEachRemaining
    11745582    0.20%    11795  select_task_rq_fair_[k]
    11369061    0.19%    11377  Thread.interrupted
    10650366    0.18%    10721  vtable chunks
     9919852    0.17%     9938  ReentrantLock$Sync.lock
     9543948    0.16%     9559  __perf_event_task_sched_out_[k]
     9380153    0.16%     9423  __pthread_mutex_unlock_usercnt
     9338984    0.16%     9367  ReferencePipeline$4.opWrapSink
     9237305    0.16%     9233  ReentrantLock$Sync.isHeldExclusively
     9234751    0.16%     9289  Unsafe_Unpark
     8882768    0.15%     8858  try_to_wake_up_[k]
     8520730    0.15%     8427  clear_page_erms_[k]
     8507521    0.15%     8536  native_sched_clock_[k]
     8343535    0.14%     8356  Cell.calculateNextState
     8220368    0.14%     8185  java_lang_Thread::set_thread_status(oopDesc*, JavaThreadStatus)
     7921898    0.14%     7957  Sink$ChainedReference.end
     7824524    0.13%     7822  __put_user_nocheck_8_[k]
     7645582    0.13%     7678  AbstractQueuedSynchronizer$ConditionObject.signal
     7210097    0.12%     7223  __pthread_mutex_cond_lock
     7180342    0.12%     7205  ArrayList.forEach
     7022057    0.12%     7035  psi_task_switch_[k]
     6918276    0.12%     6939  psi_task_change_[k]
     6853901    0.12%     6863  ReferencePipeline$3.opWrapSink
     6816517    0.12%     6838  AbstractQueuedSynchronizer$ConditionNode.block
     6692782    0.11%     6662  exit_to_user_mode_prepare_[k]
     6614353    0.11%     6639  update_curr_[k]
     6560456    0.11%     6579  ForkJoinPool.managedBlock
     6344727    0.11%     6341  ReferencePipeline$StatelessOp.<init>
     6229631    0.11%     6262  LockedSingleValue.put
     6219451    0.11%     6195  __futex_abstimed_wait_common
     6160495    0.11%     6184  dequeue_task_fair_[k]
     6135379    0.11%     6155  rcu_note_context_switch_[k]
     6061933    0.10%     6073  __GI___pthread_getspecific
     5881012    0.10%     5899  update_rq_clock_[k]
     5859677    0.10%     5882  __tls_get_addr
     5784813    0.10%     5809  futex_q_lock_[k]
     5624179    0.10%     5636  update_load_avg_[k]
     5616710    0.10%     5607  blkcg_maybe_throttle_current_[k]
     5406598    0.09%     5425  __list_add_valid_[k]
     5136368    0.09%     5191  native_write_msr_[k]
     5015653    0.09%     5022  futex_wake_mark_[k]
     4969218    0.09%     4989  cpuacct_charge_[k]
     4930906    0.08%     4973  ___pthread_cond_signal
     4921027    0.08%     4953  pthread_mutex_trylock@@GLIBC_2.34
     4913575    0.08%     4925  StreamOpFlag.fromCharacteristics
     4840280    0.08%     4823  mem_cgroup_handle_over_high_[k]
     4831862    0.08%     4853  AbstractOwnableSynchronizer.getExclusiveOwnerThread
     4319451    0.07%     4339  preempt_count_add_[k]
     4307888    0.07%     4320  task_h_load_[k]
     4233636    0.07%     4252  ReentrantLock$Sync.tryRelease
     4157028    0.07%     4167  __condvar_confirm_wakeup
     4101239    0.07%     4125  futex_wait_queue_[k]
     4027130    0.07%     4017  ReferencePipeline.map
     3869964    0.07%     3885  __update_load_avg_se_[k]
     3773337    0.06%     3776  psi_flags_change_[k]
     3761697    0.06%     3774  PipelineHelper.<init>
     3753318    0.06%     3760  iterate_groups_[k]
     3545767    0.06%     3582  ThreadsListHandle::ThreadsListHandle(Thread*)
     3538766    0.06%     3552  enqueue_entity_[k]
     3537490    0.06%     3535  Thread.getAndClearInterrupt
     3414194    0.06%     3398  _pthread_cleanup_pop@@GLIBC_2.34
     3385783    0.06%     3402  AbstractQueuedSynchronizer.setState
     3141672    0.05%     3146  __update_load_avg_cfs_rq_[k]
     3113453    0.05%     3125  update_min_vruntime_[k]
     2900590    0.05%     2900  __list_del_entry_valid_[k]
     2868179    0.05%     2869  Dimensions.forEachRowCol
     2722658    0.05%     2736  preempt_count_sub_[k]
     2651044    0.05%     2669  itable stub
     2614736    0.04%     2625  set_task_cpu_[k]
     2604530    0.04%     2602  AbstractQueuedSynchronizer$Node.clearStatus
     2524955    0.04%     2540  Cell.notifyLiveness
     2444039    0.04%     2470  ThreadsListHandle::cv_internal_thread_to_JavaThread(_jobject*, JavaThread**, oopDesc**)
     2426652    0.04%     2442  set_next_buddy_[k]
     2415824    0.04%     2431  _raw_spin_unlock_[k]
     2336332    0.04%     2344  __GI___pthread_mutex_lock
     2173830    0.04%     2189  __get_user_nocheck_4_[k]
     2140924    0.04%     2144  AbstractQueuedSynchronizer$Node.setPrevRelaxed
     2113073    0.04%     2129  JavaThread::is_interrupted(bool)
     2068833    0.04%     2085  Sink$ChainedReference.<init>
     2023540    0.03%     2038  AbstractQueuedSynchronizer$Node.getAndUnsetStatus
     2010287    0.03%     2025  AbstractPipeline.copyInto
     1980476    0.03%     1991  __cgroup_account_cputime_[k]
     1950057    0.03%     1951  JavaFrameAnchor::make_walkable()
     1926623    0.03%     1940  vtable stub
     1924983    0.03%     1942  StreamOpFlag.isKnown
     1917810    0.03%     1934  Sink$ChainedReference.begin
     1895333    0.03%     1904  get_futex_key_[k]
     1841614    0.03%     1850  dequeue_entity_[k]
     1838274    0.03%     1838  update_cfs_group_[k]
     1810156    0.03%     1801  update_blocked_averages_[k]
     1784262    0.03%     1791  __rcu_read_lock_[k]
     1705736    0.03%     1716  __futex_unqueue_[k]
     1701520    0.03%     1704  ReentrantLock.lock
     1672784    0.03%     1673  [deoptimization]
     1617444    0.03%     1618  _raw_spin_lock_irqsave_[k]
     1611679    0.03%     1621  futex_hash_[k]
     1603648    0.03%     1577  syscall_return_via_sysret_[k]
     1539372    0.03%     1548  wake_q_add_safe_[k]
     1536706    0.03%     1538  enqueue_task_fair_[k]
     1487158    0.03%     1493  available_idle_cpu_[k]
     1457241    0.02%     1456  __x64_sys_futex_[k]
     1455814    0.02%     1459  get_mem_cgroup_from_mm_[k]
     1449172    0.02%     1458  wake_up_q_[k]
     1432502    0.02%     1435  rb_erase_[k]
     1429294    0.02%     1434  ThreadLocalStorage::is_initialized()
     1414763    0.02%     1419  ReduceOps$5ReducingSink.accept
     1392870    0.02%     1395  I2C/C2I adapters
     1384628    0.02%     1392  cgroup_rstat_updated_[k]
     1361830    0.02%     1370  x86_pmu_disable_[k]
     1318053    0.02%     1326  LockSupport.setCurrentBlocker
     1302493    0.02%     1308  ChannelsGrid$$Lambda$117.0x0000000801080890.accept
     1298389    0.02%     1294  G1CardSet::occupied() const
     1291359    0.02%     1291  __this_cpu_preempt_check_[k]
     1281522    0.02%     1283  __calc_delta_[k]
     1278633    0.02%     1281  Channel.put
     1204184    0.02%     1210  Cell$$Lambda$51.0x0000000801035cd0.accept
     1185508    0.02%     1182  get_page_from_freelist_[k]
     1114389    0.02%     1118  Cell$$Lambda$68.0x0000000801033638.applyAsInt
     1095149    0.02%     1101  schedule_[k]
     1063589    0.02%     1065  __handle_mm_fault_[k]
     1057982    0.02%     1058  reweight_entity_[k]
     1054572    0.02%     1058  sched_clock_cpu_[k]
     1044677    0.02%     1049  ThreadPerCellGameOfLife$$Lambda$45.0x0000000801035068.run
     1007672    0.02%     1012  debug_smp_processor_id_[k]
      978354    0.02%      987  java_lang_Thread::get_thread_status(oopDesc*)
      974958    0.02%      979  ChannelsGrid.getChannel
      961961    0.02%      964  do_syscall_64_[k]
      961836    0.02%      964  AbstractQueuedSynchronizer.getState
      941005    0.02%      944  _raw_read_lock_irqsave_[k]
      939585    0.02%      945  entry_SYSCALL_64_safe_stack_[k]
      938422    0.02%      942  __update_load_avg_blocked_se_[k]
      935679    0.02%      930  GameOfLife.calculateFrame
      933250    0.02%      941  java_lang_Thread::interrupted(oopDesc*)
      921843    0.02%      926  native_queued_spin_lock_slowpath_[k]
      884919    0.02%      887  pick_next_task_fair_[k]
      846669    0.01%      852  AbstractQueuedSynchronizer$Node.setStatusRelaxed
      846236    0.01%      850  ThreadLocalStorage::thread()
      843430    0.01%      841  futex_wait_[k]
      812724    0.01%      807  ttwu_do_activate_[k]
      808372    0.01%      813  LockSupport.park
      808256    0.01%      810  __cgroup_throttle_swaprate_[k]
      807097    0.01%      807  __GI___pthread_mutex_unlock
      781546    0.01%      785  pthread_getspecific@plt
      737552    0.01%      741  __rcu_read_unlock_[k]
      728068    0.01%      730  asm_exc_page_fault_[k]
      719775    0.01%      724  __GI___pthread_enable_asynccancel
      667357    0.01%      665  rb_next_[k]
      623410    0.01%      626  pid_task_[k]
      613670    0.01%      614  check_preempt_wakeup_[k]
      608626    0.01%      612  migrate_task_rq_fair_[k]
      608373    0.01%      608  enqueue_task_[k]
