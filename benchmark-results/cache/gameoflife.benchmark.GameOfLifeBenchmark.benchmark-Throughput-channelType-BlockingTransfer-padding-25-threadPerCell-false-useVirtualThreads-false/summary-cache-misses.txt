--- Execution profile ---
Total samples       : 11464471
unknown_Java        : 68622 (0.60%)
not_walkable_Java   : 203 (0.00%)
deoptimization      : 21 (0.00%)
skipped             : 2 (0.00%)

--- 2786649016 total (24.31%), 2787231 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$53.0x0000000801036510.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 796480381 total (6.95%), 795715 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 573516114 total (5.00%), 575007 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue$Node.casItem
  [ 3] LinkedTransferQueue$Node.tryMatch
  [ 4] LinkedTransferQueue.xfer
  [ 5] LinkedTransferQueue.take
  [ 6] BlockingTransfer.take
  [ 7] Channel.take
  [ 8] Cell$$Lambda$55.0x0000000801036948.apply
  [ 9] ReferencePipeline$3$1.accept
  [10] ArrayList$ArrayListSpliterator.forEachRemaining
  [11] AbstractPipeline.copyInto
  [12] AbstractPipeline.wrapAndCopyInto
  [13] ReduceOps$ReduceOp.evaluateSequential
  [14] AbstractPipeline.evaluate
  [15] IntPipeline.reduce
  [16] IntPipeline.sum
  [17] Cell.calculateNextState
  [18] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [19] Iterable.forEach
  [20] CellsGroup.run
  [21] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 427453172 total (3.73%), 427934 samples
  [ 0] Cell$$Lambda$55.0x0000000801036948.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 384699198 total (3.36%), 382227 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 332481358 total (2.90%), 333428 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue.casHead
  [ 3] LinkedTransferQueue.skipDeadNodesNearHead
  [ 4] LinkedTransferQueue.xfer
  [ 5] LinkedTransferQueue.take
  [ 6] BlockingTransfer.take
  [ 7] Channel.take
  [ 8] Cell$$Lambda$55.0x0000000801036948.apply
  [ 9] ReferencePipeline$3$1.accept
  [10] ArrayList$ArrayListSpliterator.forEachRemaining
  [11] AbstractPipeline.copyInto
  [12] AbstractPipeline.wrapAndCopyInto
  [13] ReduceOps$ReduceOp.evaluateSequential
  [14] AbstractPipeline.evaluate
  [15] IntPipeline.reduce
  [16] IntPipeline.sum
  [17] Cell.calculateNextState
  [18] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [19] Iterable.forEach
  [20] CellsGroup.run
  [21] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [22] ThreadPoolExecutor.runWorker
  [23] ThreadPoolExecutor$Worker.run
  [24] Thread.run

--- 295414361 total (2.58%), 295534 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue$Node.casNext
  [ 3] LinkedTransferQueue.xfer
  [ 4] LinkedTransferQueue.put
  [ 5] BlockingTransfer.put
  [ 6] Channel.put
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 271963689 total (2.37%), 272143 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 251919088 total (2.20%), 252356 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$53.0x0000000801036510.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 246794684 total (2.15%), 247115 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue$Node.casItem
  [ 3] LinkedTransferQueue$Node.tryMatch
  [ 4] LinkedTransferQueue.xfer
  [ 5] LinkedTransferQueue.take
  [ 6] BlockingTransfer.take
  [ 7] Channel.take
  [ 8] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 9] ChannelsGrid.lambda$forEachChannel$1
  [10] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [11] Dimensions.forEachRowCol
  [12] ChannelsGrid.forEachChannel
  [13] GameOfLife.calculateFrame
  [14] GameOfLife.lambda$calculateFrameBlocking$4
  [15] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 221583775 total (1.93%), 221565 samples
  [ 0] LinkedTransferQueue.skipDeadNodesNearHead
  [ 1] LinkedTransferQueue.xfer
  [ 2] LinkedTransferQueue.take
  [ 3] BlockingTransfer.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$55.0x0000000801036948.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [19] ThreadPoolExecutor.runWorker
  [20] ThreadPoolExecutor$Worker.run
  [21] Thread.run

--- 144895373 total (1.26%), 145154 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 144057865 total (1.26%), 143704 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 137545597 total (1.20%), 137645 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue.casHead
  [ 3] LinkedTransferQueue.skipDeadNodesNearHead
  [ 4] LinkedTransferQueue.xfer
  [ 5] LinkedTransferQueue.take
  [ 6] BlockingTransfer.take
  [ 7] Channel.take
  [ 8] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 9] ChannelsGrid.lambda$forEachChannel$1
  [10] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [11] Dimensions.forEachRowCol
  [12] ChannelsGrid.forEachChannel
  [13] GameOfLife.calculateFrame
  [14] GameOfLife.lambda$calculateFrameBlocking$4
  [15] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 129545712 total (1.13%), 129345 samples
  [ 0] LinkedTransferQueue.skipDeadNodesNearHead
  [ 1] LinkedTransferQueue.xfer
  [ 2] LinkedTransferQueue.take
  [ 3] BlockingTransfer.take
  [ 4] Channel.take
  [ 5] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 6] ChannelsGrid.lambda$forEachChannel$1
  [ 7] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] GameOfLife.calculateFrame
  [11] GameOfLife.lambda$calculateFrameBlocking$4
  [12] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 129481594 total (1.13%), 129804 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$55.0x0000000801036948.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [15] ThreadPoolExecutor.runWorker
  [16] ThreadPoolExecutor$Worker.run
  [17] Thread.run

--- 129235114 total (1.13%), 129626 samples
  [ 0] Dimensions.forEachRowCol
  [ 1] ChannelsGrid.forEachChannel
  [ 2] GameOfLife.calculateFrame
  [ 3] GameOfLife.lambda$calculateFrameBlocking$4
  [ 4] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [ 5] ThreadPoolExecutor.runWorker
  [ 6] ThreadPoolExecutor$Worker.run
  [ 7] Thread.run

--- 125778960 total (1.10%), 125203 samples
  [ 0] LinkedTransferQueue.skipDeadNodesNearHead
  [ 1] LinkedTransferQueue.xfer
  [ 2] LinkedTransferQueue.put
  [ 3] BlockingTransfer.put
  [ 4] Channel.put
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 125386648 total (1.09%), 125505 samples
  [ 0] Dimensions.forEachRowCol
  [ 1] ChannelsGrid.forEachChannel
  [ 2] TickPerCell.tick
  [ 3] GameOfLife.calculateFrame
  [ 4] GameOfLife.lambda$calculateFrameBlocking$4
  [ 5] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 119641228 total (1.04%), 119729 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue$Node.casNext
  [ 3] LinkedTransferQueue.xfer
  [ 4] LinkedTransferQueue.put
  [ 5] BlockingTransfer.put
  [ 6] Channel.put
  [ 7] TickPerCell.lambda$tick$0
  [ 8] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 9] ChannelsGrid.lambda$forEachChannel$0
  [10] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [11] Dimensions.forEachRowCol
  [12] ChannelsGrid.forEachChannel
  [13] TickPerCell.tick
  [14] GameOfLife.calculateFrame
  [15] GameOfLife.lambda$calculateFrameBlocking$4
  [16] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

--- 111743313 total (0.97%), 112022 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 99511191 total (0.87%), 99570 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 97052688 total (0.85%), 96954 samples
  [ 0] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 4] ThreadPoolExecutor.runWorker
  [ 5] ThreadPoolExecutor$Worker.run
  [ 6] Thread.run

--- 95999678 total (0.84%), 96157 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 89877131 total (0.78%), 90008 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue$Node.casItem
  [ 3] LinkedTransferQueue$Node.tryMatch
  [ 4] LinkedTransferQueue.xfer
  [ 5] LinkedTransferQueue.take
  [ 6] BlockingTransfer.take
  [ 7] Channel.take
  [ 8] TickPerCell.waitTick
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 69728590 total (0.61%), 69797 samples
  [ 0] itable stub
  [ 1] Sink$ChainedReference.begin
  [ 2] Sink$ChainedReference.begin
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 69175471 total (0.60%), 69271 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 7] ThreadPoolExecutor.runWorker
  [ 8] ThreadPoolExecutor$Worker.run
  [ 9] Thread.run

--- 63294708 total (0.55%), 63271 samples
  [ 0] StreamSupport.stream
  [ 1] Collection.stream
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 7] ThreadPoolExecutor.runWorker
  [ 8] ThreadPoolExecutor$Worker.run
  [ 9] Thread.run

--- 60322637 total (0.53%), 60185 samples
  [ 0] vtable stub
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 60237577 total (0.53%), 60152 samples
  [ 0] Object.<init>
  [ 1] PipelineHelper.<init>
  [ 2] AbstractPipeline.<init>
  [ 3] ReferencePipeline.<init>
  [ 4] ReferencePipeline$Head.<init>
  [ 5] StreamSupport.stream
  [ 6] Collection.stream
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 50173403 total (0.44%), 50057 samples
  [ 0] StreamOpFlag.fromCharacteristics
  [ 1] StreamSupport.stream
  [ 2] Collection.stream
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 49319496 total (0.43%), 49305 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue.casHead
  [ 3] LinkedTransferQueue.skipDeadNodesNearHead
  [ 4] LinkedTransferQueue.xfer
  [ 5] LinkedTransferQueue.take
  [ 6] BlockingTransfer.take
  [ 7] Channel.take
  [ 8] TickPerCell.waitTick
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 49062741 total (0.43%), 49122 samples
  [ 0] itable stub
  [ 1] Sink$ChainedReference.end
  [ 2] Sink$ChainedReference.end
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 47020380 total (0.41%), 46893 samples
  [ 0] ReferencePipeline$4.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 44296627 total (0.39%), 44267 samples
  [ 0] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 4] ThreadPoolExecutor.runWorker
  [ 5] ThreadPoolExecutor$Worker.run
  [ 6] Thread.run

--- 39170177 total (0.34%), 39193 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$53.0x0000000801036510.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 39108481 total (0.34%), 39143 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 38936238 total (0.34%), 38887 samples
  [ 0] ReferencePipeline$3.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 32606737 total (0.28%), 32713 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 32151874 total (0.28%), 32247 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 30188567 total (0.26%), 30212 samples
  [ 0] ReduceOps$5ReducingSink.begin
  [ 1] Sink$ChainedReference.begin
  [ 2] Sink$ChainedReference.begin
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 29846758 total (0.26%), 29800 samples
  [ 0] Cell.notifyLiveness
  [ 1] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 5] ThreadPoolExecutor.runWorker
  [ 6] ThreadPoolExecutor$Worker.run
  [ 7] Thread.run

--- 29033147 total (0.25%), 29079 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 7] ThreadPoolExecutor.runWorker
  [ 8] ThreadPoolExecutor$Worker.run
  [ 9] Thread.run

--- 28810435 total (0.25%), 28899 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 28048109 total (0.24%), 28077 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 27628298 total (0.24%), 27645 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 27362325 total (0.24%), 27413 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] [unknown_Java]

--- 27233006 total (0.24%), 27132 samples
  [ 0] Object.<init>
  [ 1] PipelineHelper.<init>
  [ 2] AbstractPipeline.<init>
  [ 3] ReferencePipeline.<init>
  [ 4] ReferencePipeline$StatelessOp.<init>
  [ 5] ReferencePipeline$3.<init>
  [ 6] ReferencePipeline.map
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 26865266 total (0.23%), 26901 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue$Node.casItem
  [ 3] LinkedTransferQueue$Node.tryMatch
  [ 4] LinkedTransferQueue.xfer
  [ 5] LinkedTransferQueue.put
  [ 6] BlockingTransfer.put
  [ 7] Channel.put
  [ 8] Cell.lambda$notifyLiveness$0
  [ 9] Cell$$Lambda$53.0x0000000801036510.accept
  [10] ArrayList.forEach
  [11] Cell.notifyLiveness
  [12] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 26730919 total (0.23%), 26806 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 26196032 total (0.23%), 26294 samples
  [ 0] Cell$$Lambda$53.0x0000000801036510.accept
  [ 1] ArrayList.forEach
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 7] ThreadPoolExecutor.runWorker
  [ 8] ThreadPoolExecutor$Worker.run
  [ 9] Thread.run

--- 25705367 total (0.22%), 25616 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 23922588 total (0.21%), 24027 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$55.0x0000000801036948.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [15] ThreadPoolExecutor.runWorker
  [16] ThreadPoolExecutor$Worker.run
  [17] Thread.run

--- 23788154 total (0.21%), 23794 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue$Node.casItem
  [ 3] LinkedTransferQueue$Node.tryMatch
  [ 4] LinkedTransferQueue.xfer
  [ 5] LinkedTransferQueue.put
  [ 6] BlockingTransfer.put
  [ 7] Channel.put
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 23729194 total (0.21%), 23785 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 23393379 total (0.20%), 23451 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 23078936 total (0.20%), 23087 samples
  [ 0] LockSupport.unpark
  [ 1] LinkedTransferQueue$Node.tryMatch
  [ 2] LinkedTransferQueue.xfer
  [ 3] LinkedTransferQueue.take
  [ 4] BlockingTransfer.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$55.0x0000000801036948.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [20] ThreadPoolExecutor.runWorker
  [21] ThreadPoolExecutor$Worker.run
  [22] Thread.run

--- 22378393 total (0.20%), 22405 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue.casTail
  [ 3] LinkedTransferQueue.xfer
  [ 4] LinkedTransferQueue.put
  [ 5] BlockingTransfer.put
  [ 6] Channel.put
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 22246738 total (0.19%), 22303 samples
  [ 0] ChannelsGrid.getChannel
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 7] ThreadPoolExecutor.runWorker
  [ 8] ThreadPoolExecutor$Worker.run
  [ 9] Thread.run

--- 21803829 total (0.19%), 21858 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 21756342 total (0.19%), 21766 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 21530118 total (0.19%), 21602 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 21218872 total (0.19%), 21249 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$53.0x0000000801036510.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 20577812 total (0.18%), 20616 samples
  [ 0] ChannelsGrid.getChannel
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 7] ThreadPoolExecutor.runWorker
  [ 8] ThreadPoolExecutor$Worker.run
  [ 9] Thread.run

--- 20184925 total (0.18%), 20182 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 20027009 total (0.17%), 20037 samples
  [ 0] Sink$ChainedReference.begin
  [ 1] Sink$ChainedReference.begin
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 19240198 total (0.17%), 19289 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 19037466 total (0.17%), 19048 samples
  [ 0] LinkedTransferQueue.skipDeadNodesNearHead
  [ 1] LinkedTransferQueue.xfer
  [ 2] LinkedTransferQueue.take
  [ 3] BlockingTransfer.take
  [ 4] Channel.take
  [ 5] TickPerCell.waitTick
  [ 6] Cell.notifyLiveness
  [ 7] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 18554666 total (0.16%), 18494 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 18284914 total (0.16%), 18327 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 18098662 total (0.16%), 18090 samples
  [ 0] ArrayList.spliterator
  [ 1] Collection.stream
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 7] ThreadPoolExecutor.runWorker
  [ 8] ThreadPoolExecutor$Worker.run
  [ 9] Thread.run

--- 17373840 total (0.15%), 17339 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 16977747 total (0.15%), 16964 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$3$1.<init>
  [ 2] ReferencePipeline$3.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 16961039 total (0.15%), 17015 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 16724357 total (0.15%), 16765 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 16071975 total (0.14%), 16117 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 16017523 total (0.14%), 16026 samples
  [ 0] Sink.end
  [ 1] Sink$ChainedReference.end
  [ 2] Sink$ChainedReference.end
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 15936578 total (0.14%), 15943 samples
  [ 0] ArrayList.forEach
  [ 1] Cell.notifyLiveness
  [ 2] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 3] Iterable.forEach
  [ 4] CellsGroup.run
  [ 5] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 15883292 total (0.14%), 15898 samples
  [ 0] StreamSupport.stream
  [ 1] Collection.stream
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 7] ThreadPoolExecutor.runWorker
  [ 8] ThreadPoolExecutor$Worker.run
  [ 9] Thread.run

--- 15876105 total (0.14%), 15917 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 15465414 total (0.13%), 15437 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$4$1.<init>
  [ 2] ReferencePipeline$4.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 15342410 total (0.13%), 15380 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 15298412 total (0.13%), 15362 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue$Node.casNext
  [ 3] LinkedTransferQueue.xfer
  [ 4] LinkedTransferQueue.take
  [ 5] BlockingTransfer.take
  [ 6] Channel.take
  [ 7] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 8] ChannelsGrid.lambda$forEachChannel$1
  [ 9] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [10] Dimensions.forEachRowCol
  [11] ChannelsGrid.forEachChannel
  [12] GameOfLife.calculateFrame
  [13] GameOfLife.lambda$calculateFrameBlocking$4
  [14] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [15] ThreadPoolExecutor.runWorker
  [16] ThreadPoolExecutor$Worker.run
  [17] Thread.run

--- 15204078 total (0.13%), 15226 samples
  [ 0] Sink$ChainedReference.end
  [ 1] Sink$ChainedReference.end
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 15032703 total (0.13%), 15079 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 14916173 total (0.13%), 14954 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 14666046 total (0.13%), 14671 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 14454132 total (0.13%), 14480 samples
  [ 0] AbstractPipeline.<init>
  [ 1] IntPipeline.<init>
  [ 2] IntPipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$4.<init>
  [ 4] ReferencePipeline.mapToInt
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 14316291 total (0.12%), 14299 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$Head.<init>
  [ 3] StreamSupport.stream
  [ 4] Collection.stream
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 14145519 total (0.12%), 14153 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 13839694 total (0.12%), 13849 samples
  [ 0] ArrayList.forEach
  [ 1] Cell.notifyLiveness
  [ 2] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 3] Iterable.forEach
  [ 4] CellsGroup.run
  [ 5] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 13769815 total (0.12%), 13802 samples
  [ 0] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 1] AbstractPipeline.copyInto
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 13588657 total (0.12%), 13630 samples
  [ 0] LinkedTransferQueue.take
  [ 1] BlockingTransfer.take
  [ 2] Channel.take
  [ 3] Cell$$Lambda$55.0x0000000801036948.apply
  [ 4] ReferencePipeline$3$1.accept
  [ 5] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 6] AbstractPipeline.copyInto
  [ 7] AbstractPipeline.wrapAndCopyInto
  [ 8] ReduceOps$ReduceOp.evaluateSequential
  [ 9] AbstractPipeline.evaluate
  [10] IntPipeline.reduce
  [11] IntPipeline.sum
  [12] Cell.calculateNextState
  [13] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [14] Iterable.forEach
  [15] CellsGroup.run
  [16] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

--- 13532002 total (0.12%), 13515 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 13404319 total (0.12%), 13423 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 12781776 total (0.11%), 12794 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$53.0x0000000801036510.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 12764874 total (0.11%), 12780 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 12750428 total (0.11%), 12793 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 12723838 total (0.11%), 12760 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$55.0x0000000801036948.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 12523609 total (0.11%), 12532 samples
  [ 0] LinkedTransferQueue.put
  [ 1] BlockingTransfer.put
  [ 2] Channel.put
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 12445520 total (0.11%), 12479 samples
  [ 0] LinkedTransferQueue$Node.tryMatch
  [ 1] LinkedTransferQueue.xfer
  [ 2] LinkedTransferQueue.take
  [ 3] BlockingTransfer.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$55.0x0000000801036948.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [19] ThreadPoolExecutor.runWorker
  [20] ThreadPoolExecutor$Worker.run
  [21] Thread.run

--- 11964470 total (0.10%), 12008 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 11797815 total (0.10%), 11815 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue$Node.casItem
  [ 3] LinkedTransferQueue$Node.tryMatch
  [ 4] LinkedTransferQueue.xfer
  [ 5] LinkedTransferQueue.put
  [ 6] BlockingTransfer.put
  [ 7] Channel.put
  [ 8] TickPerCell.lambda$tick$0
  [ 9] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [10] ChannelsGrid.lambda$forEachChannel$0
  [11] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [12] Dimensions.forEachRowCol
  [13] ChannelsGrid.forEachChannel
  [14] TickPerCell.tick
  [15] GameOfLife.calculateFrame
  [16] GameOfLife.lambda$calculateFrameBlocking$4
  [17] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [18] ThreadPoolExecutor.runWorker
  [19] ThreadPoolExecutor$Worker.run
  [20] Thread.run

--- 11578402 total (0.10%), 11600 samples
  [ 0] Channel.put
  [ 1] Cell.lambda$notifyLiveness$0
  [ 2] Cell$$Lambda$53.0x0000000801036510.accept
  [ 3] ArrayList.forEach
  [ 4] Cell.notifyLiveness
  [ 5] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 11155206 total (0.10%), 11195 samples
  [ 0] BlockingTransfer.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$55.0x0000000801036948.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 11123133 total (0.10%), 11125 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 11100881 total (0.10%), 11115 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 10992535 total (0.10%), 11023 samples
  [ 0] BlockingTransfer.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$55.0x0000000801036948.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [16] ThreadPoolExecutor.runWorker
  [17] ThreadPoolExecutor$Worker.run
  [18] Thread.run

--- 10986918 total (0.10%), 10990 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$Head.<init>
  [ 3] StreamSupport.stream
  [ 4] Collection.stream
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 10805951 total (0.09%), 10670 samples
  [ 0] __entry_text_start_[k]
  [ 1] sched_yield
  [ 2] Thread.yield0
  [ 3] Thread.yield
  [ 4] LinkedTransferQueue.awaitMatch
  [ 5] LinkedTransferQueue.xfer
  [ 6] LinkedTransferQueue.take
  [ 7] BlockingTransfer.take
  [ 8] Channel.take
  [ 9] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [10] ChannelsGrid.lambda$forEachChannel$1
  [11] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [12] Dimensions.forEachRowCol
  [13] ChannelsGrid.forEachChannel
  [14] GameOfLife.calculateFrame
  [15] GameOfLife.lambda$calculateFrameBlocking$4
  [16] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

--- 10630507 total (0.09%), 10640 samples
  [ 0] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 4] ThreadPoolExecutor.runWorker
  [ 5] ThreadPoolExecutor$Worker.run
  [ 6] Thread.run

--- 10557410 total (0.09%), 10566 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue.casTail
  [ 3] LinkedTransferQueue.xfer
  [ 4] LinkedTransferQueue.put
  [ 5] BlockingTransfer.put
  [ 6] Channel.put
  [ 7] TickPerCell.lambda$tick$0
  [ 8] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 9] ChannelsGrid.lambda$forEachChannel$0
  [10] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [11] Dimensions.forEachRowCol
  [12] ChannelsGrid.forEachChannel
  [13] TickPerCell.tick
  [14] GameOfLife.calculateFrame
  [15] GameOfLife.lambda$calculateFrameBlocking$4
  [16] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

--- 10556674 total (0.09%), 10583 samples
  [ 0] ReferencePipeline$4$1.accept
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 10491908 total (0.09%), 10516 samples
  [ 0] ChannelsGrid.getChannel
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 7] ThreadPoolExecutor.runWorker
  [ 8] ThreadPoolExecutor$Worker.run
  [ 9] Thread.run

--- 10423260 total (0.09%), 10402 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 10363415 total (0.09%), 10366 samples
  [ 0] Cell.notifyLiveness
  [ 1] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 5] ThreadPoolExecutor.runWorker
  [ 6] ThreadPoolExecutor$Worker.run
  [ 7] Thread.run

--- 10315945 total (0.09%), 10344 samples
  [ 0] ReferencePipeline$4$1.accept
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 10138361 total (0.09%), 10168 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 10054718 total (0.09%), 10082 samples
  [ 0] Cell$$Lambda$56.0x0000000801036b70.applyAsInt
  [ 1] ReferencePipeline$4$1.accept
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [15] ThreadPoolExecutor.runWorker
  [16] ThreadPoolExecutor$Worker.run
  [17] Thread.run

--- 10001908 total (0.09%), 10000 samples
  [ 0] ArrayList$SubList$1.next
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 4] ThreadPoolExecutor.runWorker
  [ 5] ThreadPoolExecutor$Worker.run
  [ 6] Thread.run

--- 9810292 total (0.09%), 9834 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] [unknown_Java]

--- 9628034 total (0.08%), 9650 samples
  [ 0] ChannelsGrid.getChannel
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 7] ThreadPoolExecutor.runWorker
  [ 8] ThreadPoolExecutor$Worker.run
  [ 9] Thread.run

--- 9582011 total (0.08%), 9588 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 9450700 total (0.08%), 9436 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 9414604 total (0.08%), 9411 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 9068894 total (0.08%), 9085 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$Head.<init>
  [ 3] StreamSupport.stream
  [ 4] Collection.stream
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 9048897 total (0.08%), 9058 samples
  [ 0] LinkedTransferQueue.put
  [ 1] BlockingTransfer.put
  [ 2] Channel.put
  [ 3] TickPerCell.lambda$tick$0
  [ 4] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 5] ChannelsGrid.lambda$forEachChannel$0
  [ 6] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] TickPerCell.tick
  [10] GameOfLife.calculateFrame
  [11] GameOfLife.lambda$calculateFrameBlocking$4
  [12] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 8538664 total (0.07%), 8534 samples
  [ 0] LinkedTransferQueue.skipDeadNodesNearHead
  [ 1] LinkedTransferQueue.xfer
  [ 2] LinkedTransferQueue.put
  [ 3] BlockingTransfer.put
  [ 4] Channel.put
  [ 5] TickPerCell.lambda$tick$0
  [ 6] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 7] ChannelsGrid.lambda$forEachChannel$0
  [ 8] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 9] Dimensions.forEachRowCol
  [10] ChannelsGrid.forEachChannel
  [11] TickPerCell.tick
  [12] GameOfLife.calculateFrame
  [13] GameOfLife.lambda$calculateFrameBlocking$4
  [14] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [15] ThreadPoolExecutor.runWorker
  [16] ThreadPoolExecutor$Worker.run
  [17] Thread.run

--- 8463506 total (0.07%), 8472 samples
  [ 0] Channel.put
  [ 1] Cell.lambda$notifyLiveness$0
  [ 2] Cell$$Lambda$53.0x0000000801036510.accept
  [ 3] ArrayList.forEach
  [ 4] Cell.notifyLiveness
  [ 5] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 8431541 total (0.07%), 8435 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 8402923 total (0.07%), 8405 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 8255370 total (0.07%), 8241 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$Head.<init>
  [ 3] StreamSupport.stream
  [ 4] Collection.stream
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 8223392 total (0.07%), 8065 samples
  [ 0] psi_group_change_[k]
  [ 1] psi_task_switch_[k]
  [ 2] __schedule_[k]
  [ 3] schedule_[k]
  [ 4] futex_wait_queue_[k]
  [ 5] futex_wait_[k]
  [ 6] do_futex_[k]
  [ 7] __x64_sys_futex_[k]
  [ 8] do_syscall_64_[k]
  [ 9] entry_SYSCALL_64_after_hwframe_[k]
  [10] __futex_abstimed_wait_common
  [11] Unsafe.park
  [12] LockSupport.park
  [13] LinkedTransferQueue$Node.block
  [14] ForkJoinPool.unmanagedBlock
  [15] ForkJoinPool.managedBlock
  [16] LinkedTransferQueue.awaitMatch
  [17] LinkedTransferQueue.xfer
  [18] LinkedTransferQueue.take
  [19] BlockingTransfer.take
  [20] Channel.take
  [21] TickPerCell.waitTick
  [22] Cell.notifyLiveness
  [23] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [24] Iterable.forEach
  [25] CellsGroup.run
  [26] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [27] ThreadPoolExecutor.runWorker
  [28] ThreadPoolExecutor$Worker.run
  [29] Thread.run

--- 8052217 total (0.07%), 8043 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$3$1.<init>
  [ 2] ReferencePipeline$3.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 7939873 total (0.07%), 7930 samples
  [ 0] AbstractPipeline.<init>
  [ 1] ReferencePipeline.<init>
  [ 2] ReferencePipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$3.<init>
  [ 4] ReferencePipeline.map
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 7855904 total (0.07%), 7871 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$53.0x0000000801036510.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 7774348 total (0.07%), 7790 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 7723468 total (0.07%), 7731 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 7714131 total (0.07%), 7707 samples
  [ 0] ReferencePipeline$3.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 7701577 total (0.07%), 7681 samples
  [ 0] ReferencePipeline$4.opWrapSink
  [ 1] AbstractPipeline.wrapSink
  [ 2] AbstractPipeline.wrapAndCopyInto
  [ 3] ReduceOps$ReduceOp.evaluateSequential
  [ 4] AbstractPipeline.evaluate
  [ 5] IntPipeline.reduce
  [ 6] IntPipeline.sum
  [ 7] Cell.calculateNextState
  [ 8] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 7659354 total (0.07%), 7670 samples
  [ 0] BlockingTransfer.put
  [ 1] Channel.put
  [ 2] Cell.lambda$notifyLiveness$0
  [ 3] Cell$$Lambda$53.0x0000000801036510.accept
  [ 4] ArrayList.forEach
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 7656826 total (0.07%), 7668 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 7646910 total (0.07%), 7658 samples
  [ 0] Cell.notifyLiveness
  [ 1] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 5] ThreadPoolExecutor.runWorker
  [ 6] ThreadPoolExecutor$Worker.run
  [ 7] Thread.run

--- 7418253 total (0.06%), 7424 samples
  [ 0] LinkedTransferQueue.take
  [ 1] BlockingTransfer.take
  [ 2] Channel.take
  [ 3] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 4] ChannelsGrid.lambda$forEachChannel$1
  [ 5] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 6] Dimensions.forEachRowCol
  [ 7] ChannelsGrid.forEachChannel
  [ 8] GameOfLife.calculateFrame
  [ 9] GameOfLife.lambda$calculateFrameBlocking$4
  [10] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 7293877 total (0.06%), 7309 samples
  [ 0] ReduceOps$5ReducingSink.accept
  [ 1] ReferencePipeline$4$1.accept
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [15] ThreadPoolExecutor.runWorker
  [16] ThreadPoolExecutor$Worker.run
  [17] Thread.run

--- 7286079 total (0.06%), 7273 samples
  [ 0] ArrayList.forEach
  [ 1] Cell.notifyLiveness
  [ 2] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 3] Iterable.forEach
  [ 4] CellsGroup.run
  [ 5] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 7212290 total (0.06%), 7207 samples
  [ 0] Cell.notifyLiveness
  [ 1] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 5] ThreadPoolExecutor.runWorker
  [ 6] ThreadPoolExecutor$Worker.run
  [ 7] Thread.run

--- 7115045 total (0.06%), 7135 samples
  [ 0] LinkedTransferQueue.skipDeadNodesNearHead
  [ 1] LinkedTransferQueue.xfer
  [ 2] LinkedTransferQueue.take
  [ 3] BlockingTransfer.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$55.0x0000000801036948.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [19] ThreadPoolExecutor.runWorker
  [20] ThreadPoolExecutor$Worker.run
  [21] Thread.run

--- 6845017 total (0.06%), 6859 samples
  [ 0] ReferencePipeline$4$1.accept
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 6824411 total (0.06%), 6822 samples
  [ 0] Iterable.forEach
  [ 1] CellsGroup.run
  [ 2] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 3] ThreadPoolExecutor.runWorker
  [ 4] ThreadPoolExecutor$Worker.run
  [ 5] Thread.run

--- 6755336 total (0.06%), 6763 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 6643906 total (0.06%), 6658 samples
  [ 0] ReduceOps$5ReducingSink.accept
  [ 1] ReferencePipeline$4$1.accept
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [15] ThreadPoolExecutor.runWorker
  [16] ThreadPoolExecutor$Worker.run
  [17] Thread.run

--- 6559583 total (0.06%), 6555 samples
  [ 0] Collection.stream
  [ 1] Cell.calculateNextState
  [ 2] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 3] Iterable.forEach
  [ 4] CellsGroup.run
  [ 5] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 6446720 total (0.06%), 6430 samples
  [ 0] Sink$ChainedReference.<init>
  [ 1] ReferencePipeline$4$1.<init>
  [ 2] ReferencePipeline$4.opWrapSink
  [ 3] AbstractPipeline.wrapSink
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 6229781 total (0.05%), 6245 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 6216292 total (0.05%), 6204 samples
  [ 0] LockSupport.unpark
  [ 1] LinkedTransferQueue$Node.tryMatch
  [ 2] LinkedTransferQueue.xfer
  [ 3] LinkedTransferQueue.take
  [ 4] BlockingTransfer.take
  [ 5] Channel.take
  [ 6] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 7] ChannelsGrid.lambda$forEachChannel$1
  [ 8] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 9] Dimensions.forEachRowCol
  [10] ChannelsGrid.forEachChannel
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 6182795 total (0.05%), 6200 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 6177571 total (0.05%), 6176 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 5999671 total (0.05%), 6008 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 5921542 total (0.05%), 5928 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$53.0x0000000801036510.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 9] Iterable.forEach
  [10] CellsGroup.run
  [11] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 5886129 total (0.05%), 5882 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 5724874 total (0.05%), 5724 samples
  [ 0] LinkedTransferQueue.put
  [ 1] [unknown_Java]

--- 5720534 total (0.05%), 5703 samples
  [ 0] Iterable.forEach
  [ 1] CellsGroup.run
  [ 2] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 3] ThreadPoolExecutor.runWorker
  [ 4] ThreadPoolExecutor$Worker.run
  [ 5] Thread.run

--- 5634564 total (0.05%), 5633 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 5619477 total (0.05%), 5625 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 5505219 total (0.05%), 5518 samples
  [ 0] LinkedTransferQueue$Node.tryMatch
  [ 1] LinkedTransferQueue.xfer
  [ 2] LinkedTransferQueue.take
  [ 3] BlockingTransfer.take
  [ 4] Channel.take
  [ 5] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 6] ChannelsGrid.lambda$forEachChannel$1
  [ 7] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] GameOfLife.calculateFrame
  [11] GameOfLife.lambda$calculateFrameBlocking$4
  [12] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 5501233 total (0.05%), 5510 samples
  [ 0] LinkedTransferQueue$Node.<init>
  [ 1] LinkedTransferQueue.xfer
  [ 2] LinkedTransferQueue.put
  [ 3] BlockingTransfer.put
  [ 4] Channel.put
  [ 5] TickPerCell.lambda$tick$0
  [ 6] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 7] ChannelsGrid.lambda$forEachChannel$0
  [ 8] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 9] Dimensions.forEachRowCol
  [10] ChannelsGrid.forEachChannel
  [11] TickPerCell.tick
  [12] GameOfLife.calculateFrame
  [13] GameOfLife.lambda$calculateFrameBlocking$4
  [14] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [15] ThreadPoolExecutor.runWorker
  [16] ThreadPoolExecutor$Worker.run
  [17] Thread.run

--- 5473630 total (0.05%), 5375 samples
  [ 0] ThreadPoolExecutor.runWorker
  [ 1] ThreadPoolExecutor$Worker.run
  [ 2] Thread.run

--- 5387928 total (0.05%), 5401 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 5372226 total (0.05%), 5373 samples
  [ 0] VarHandleReferences$FieldInstanceReadWrite.compareAndSet
  [ 1] VarHandleGuards.guard_LLL_Z
  [ 2] LinkedTransferQueue.casTail
  [ 3] LinkedTransferQueue.xfer
  [ 4] LinkedTransferQueue.put
  [ 5] BlockingTransfer.put
  [ 6] Channel.put
  [ 7] Cell.lambda$notifyLiveness$0
  [ 8] Cell$$Lambda$53.0x0000000801036510.accept
  [ 9] ArrayList.forEach
  [10] Cell.notifyLiveness
  [11] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [15] ThreadPoolExecutor.runWorker
  [16] ThreadPoolExecutor$Worker.run
  [17] Thread.run

--- 5282870 total (0.05%), 5287 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 5259347 total (0.05%), 5273 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 5164125 total (0.05%), 5158 samples
  [ 0] LinkedTransferQueue$Node.<init>
  [ 1] LinkedTransferQueue.xfer
  [ 2] LinkedTransferQueue.put
  [ 3] BlockingTransfer.put
  [ 4] Channel.put
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 5159046 total (0.05%), 5161 samples
  [ 0] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 1] [unknown_Java]

--- 5068736 total (0.04%), 5066 samples
  [ 0] ArrayList.forEach
  [ 1] Cell.notifyLiveness
  [ 2] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 3] Iterable.forEach
  [ 4] CellsGroup.run
  [ 5] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 5038074 total (0.04%), 5040 samples
  [ 0] Cell.notifyLiveness
  [ 1] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 5] ThreadPoolExecutor.runWorker
  [ 6] ThreadPoolExecutor$Worker.run
  [ 7] Thread.run

--- 5014617 total (0.04%), 5014 samples
  [ 0] ArrayList$SubList$1.next
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 4] ThreadPoolExecutor.runWorker
  [ 5] ThreadPoolExecutor$Worker.run
  [ 6] Thread.run

--- 4911146 total (0.04%), 4923 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 4899615 total (0.04%), 4904 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 4887414 total (0.04%), 4881 samples
  [ 0] LinkedTransferQueue.put
  [ 1] BlockingTransfer.put
  [ 2] Channel.put
  [ 3] Cell.calculateNextState
  [ 4] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 5] Iterable.forEach
  [ 6] CellsGroup.run
  [ 7] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 8] ThreadPoolExecutor.runWorker
  [ 9] ThreadPoolExecutor$Worker.run
  [10] Thread.run

--- 4886762 total (0.04%), 4891 samples
  [ 0] ArrayList$SubList$1.next
  [ 1] Iterable.forEach
  [ 2] CellsGroup.run
  [ 3] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 4] ThreadPoolExecutor.runWorker
  [ 5] ThreadPoolExecutor$Worker.run
  [ 6] Thread.run

--- 4796444 total (0.04%), 4803 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 4749704 total (0.04%), 4751 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 4749176 total (0.04%), 4756 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 4610780 total (0.04%), 4600 samples
  [ 0] AbstractPipeline.wrapSink
  [ 1] AbstractPipeline.wrapAndCopyInto
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 4525673 total (0.04%), 4527 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] GameOfLife$$Lambda$57.0x0000000801036d78.test
  [ 5] ChannelsGrid.lambda$forEachChannel$1
  [ 6] ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] GameOfLife.calculateFrame
  [10] GameOfLife.lambda$calculateFrameBlocking$4
  [11] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [12] ThreadPoolExecutor.runWorker
  [13] ThreadPoolExecutor$Worker.run
  [14] Thread.run

--- 4509337 total (0.04%), 4520 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 4452737 total (0.04%), 4450 samples
  [ 0] ReferencePipeline$3.<init>
  [ 1] ReferencePipeline.map
  [ 2] Cell.calculateNextState
  [ 3] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 4] Iterable.forEach
  [ 5] CellsGroup.run
  [ 6] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 7] ThreadPoolExecutor.runWorker
  [ 8] ThreadPoolExecutor$Worker.run
  [ 9] Thread.run

--- 4381992 total (0.04%), 4381 samples
  [ 0] Integer.valueOf
  [ 1] Dimensions.forEachRowCol
  [ 2] ChannelsGrid.forEachChannel
  [ 3] GameOfLife.calculateFrame
  [ 4] GameOfLife.lambda$calculateFrameBlocking$4
  [ 5] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [ 6] ThreadPoolExecutor.runWorker
  [ 7] ThreadPoolExecutor$Worker.run
  [ 8] Thread.run

--- 4252585 total (0.04%), 4255 samples
  [ 0] LinkedTransferQueue.put
  [ 1] BlockingTransfer.put
  [ 2] Channel.put
  [ 3] TickPerCell.lambda$tick$0
  [ 4] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 5] ChannelsGrid.lambda$forEachChannel$0
  [ 6] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 7] Dimensions.forEachRowCol
  [ 8] ChannelsGrid.forEachChannel
  [ 9] TickPerCell.tick
  [10] GameOfLife.calculateFrame
  [11] GameOfLife.lambda$calculateFrameBlocking$4
  [12] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 4210538 total (0.04%), 4204 samples
  [ 0] AbstractPipeline.<init>
  [ 1] IntPipeline.<init>
  [ 2] IntPipeline$StatelessOp.<init>
  [ 3] ReferencePipeline$4.<init>
  [ 4] ReferencePipeline.mapToInt
  [ 5] Cell.calculateNextState
  [ 6] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 4159410 total (0.04%), 4167 samples
  [ 0] ReferencePipeline$3$1.accept
  [ 1] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 2] AbstractPipeline.copyInto
  [ 3] AbstractPipeline.wrapAndCopyInto
  [ 4] ReduceOps$ReduceOp.evaluateSequential
  [ 5] AbstractPipeline.evaluate
  [ 6] IntPipeline.reduce
  [ 7] IntPipeline.sum
  [ 8] Cell.calculateNextState
  [ 9] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [10] Iterable.forEach
  [11] CellsGroup.run
  [12] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [13] ThreadPoolExecutor.runWorker
  [14] ThreadPoolExecutor$Worker.run
  [15] Thread.run

--- 4017930 total (0.04%), 4022 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] TickPerCell.lambda$tick$0
  [ 5] TickPerCell$$Lambda$51.0x00000008010360d8.accept
  [ 6] ChannelsGrid.lambda$forEachChannel$0
  [ 7] ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
  [ 8] Dimensions.forEachRowCol
  [ 9] ChannelsGrid.forEachChannel
  [10] TickPerCell.tick
  [11] GameOfLife.calculateFrame
  [12] GameOfLife.lambda$calculateFrameBlocking$4
  [13] GameOfLife$$Lambda$50.0x0000000801035ec8.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 3865113 total (0.03%), 3854 samples
  [ 0] StreamOpFlag.combineOpFlags
  [ 1] AbstractPipeline.<init>
  [ 2] ReferencePipeline.<init>
  [ 3] ReferencePipeline$StatelessOp.<init>
  [ 4] ReferencePipeline$3.<init>
  [ 5] ReferencePipeline.map
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [11] ThreadPoolExecutor.runWorker
  [12] ThreadPoolExecutor$Worker.run
  [13] Thread.run

--- 3858208 total (0.03%), 3869 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.take
  [ 2] BlockingTransfer.take
  [ 3] Channel.take
  [ 4] TickPerCell.waitTick
  [ 5] Cell.notifyLiveness
  [ 6] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 7] Iterable.forEach
  [ 8] CellsGroup.run
  [ 9] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [10] ThreadPoolExecutor.runWorker
  [11] ThreadPoolExecutor$Worker.run
  [12] Thread.run

--- 3841861 total (0.03%), 3838 samples
  [ 0] ReferencePipeline$3.opWrapSink
  [ 1] [unknown_Java]

--- 3771222 total (0.03%), 3777 samples
  [ 0] ReduceOps$5ReducingSink.begin
  [ 1] Sink$ChainedReference.begin
  [ 2] Sink$ChainedReference.begin
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [14] ThreadPoolExecutor.runWorker
  [15] ThreadPoolExecutor$Worker.run
  [16] Thread.run

--- 3728604 total (0.03%), 3718 samples
  [ 0] LinkedTransferQueue.xfer
  [ 1] LinkedTransferQueue.put
  [ 2] BlockingTransfer.put
  [ 3] Channel.put
  [ 4] Cell.calculateNextState
  [ 5] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 3616339 total (0.03%), 3625 samples
  [ 0] LinkedTransferQueue.take
  [ 1] BlockingTransfer.take
  [ 2] Channel.take
  [ 3] TickPerCell.waitTick
  [ 4] Cell.notifyLiveness
  [ 5] CellsGroup$$Lambda$47.0x0000000801035478.accept
  [ 6] Iterable.forEach
  [ 7] CellsGroup.run
  [ 8] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [ 9] ThreadPoolExecutor.runWorker
  [10] ThreadPoolExecutor$Worker.run
  [11] Thread.run

--- 3572472 total (0.03%), 3583 samples
  [ 0] LinkedTransferQueue.take
  [ 1] BlockingTransfer.take
  [ 2] Channel.take
  [ 3] Cell$$Lambda$55.0x0000000801036948.apply
  [ 4] ReferencePipeline$3$1.accept
  [ 5] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 6] AbstractPipeline.copyInto
  [ 7] AbstractPipeline.wrapAndCopyInto
  [ 8] ReduceOps$ReduceOp.evaluateSequential
  [ 9] AbstractPipeline.evaluate
  [10] IntPipeline.reduce
  [11] IntPipeline.sum
  [12] Cell.calculateNextState
  [13] CellsGroup$$Lambda$54.0x0000000801036730.accept
  [14] Iterable.forEach
  [15] CellsGroup.run
  [16] ThreadPerCoreGameOfLife$$Lambda$45.0x0000000801035268.run
  [17] ThreadPoolExecutor.runWorker
  [18] ThreadPoolExecutor$Worker.run
  [19] Thread.run

       total  percent  samples  top
  ----------  -------  -------  ---
  2786649016   24.31%  2787231  Cell.lambda$notifyLiveness$0
  2466117399   21.51%  2465939  LinkedTransferQueue.xfer
  1965306427   17.14%  1968650  VarHandleReferences$FieldInstanceReadWrite.compareAndSet
   797661688    6.96%   796898  ReduceOps$5ReducingSink.get
   515622466    4.50%   514857  LinkedTransferQueue.skipDeadNodesNearHead
   427453172    3.73%   427934  Cell$$Lambda$55.0x0000000801036948.apply
   257845525    2.25%   258360  Dimensions.forEachRowCol
   254657364    2.22%   255232  Channel.take
   141349315    1.23%   141221  CellsGroup$$Lambda$47.0x0000000801035478.accept
   118791331    1.04%   118919  itable stub
   100442187    0.88%   100387  AbstractPipeline.<init>
    95532546    0.83%    95766  ReferencePipeline$3$1.accept
    87785951    0.77%    87599  Object.<init>
    80253944    0.70%    80244  StreamSupport.stream
    71363233    0.62%    71509  ChannelsGrid.getChannel
    67563454    0.59%    67533  Cell.notifyLiveness
    60324603    0.53%    60187  vtable stub
    59493321    0.52%    59335  ReferencePipeline$4.opWrapSink
    52498464    0.46%    52438  ReferencePipeline$3.opWrapSink
    50173403    0.44%    50057  StreamOpFlag.fromCharacteristics
    46942098    0.41%    46874  Sink$ChainedReference.<init>
    45652746    0.40%    45653  ArrayList.forEach
    43044235    0.38%    43058  ArrayList$SubList$1.next
    37247433    0.32%    37238  Iterable.forEach
    36624023    0.32%    36655  ReduceOps$5ReducingSink.begin
    36437379    0.32%    36450  LinkedTransferQueue.put
    32902914    0.29%    32893  LockSupport.unpark
    31846708    0.28%    31920  LinkedTransferQueue.take
    30324187    0.26%    30337  Sink$ChainedReference.begin
    28551343    0.25%    28622  ReferencePipeline$4$1.accept
    27858359    0.24%    27957  Cell$$Lambda$53.0x0000000801036510.accept
    26346530    0.23%    26427  BlockingTransfer.take
    23487087    0.20%    23543  LinkedTransferQueue$Node.tryMatch
    22833573    0.20%    22864  Sink$ChainedReference.end
    20045895    0.17%    20076  Channel.put
    18098662    0.16%    18090  ArrayList.spliterator
    17936102    0.16%    17944  Sink.end
    17096250    0.15%    16844  __entry_text_start_[k]
    16752746    0.15%    16790  ReduceOps$5ReducingSink.accept
    16073146    0.14%    15919  ThreadPoolExecutor.runWorker
    15800542    0.14%    15812  CellsGroup$$Lambda$54.0x0000000801036730.accept
    15459263    0.13%    15240  psi_group_change_[k]
    13769815    0.12%    13802  ArrayList$ArrayListSpliterator.forEachRemaining
    12376269    0.11%    12388  BlockingTransfer.put
    11341327    0.10%    11350  ArrayList$SubList$1.checkForComodification
    11046745    0.10%    11051  LinkedTransferQueue$Node.<init>
    10054718    0.09%    10082  Cell$$Lambda$56.0x0000000801036b70.applyAsInt
     8574383    0.07%     8402  __update_load_avg_cfs_rq_[k]
     8554339    0.07%     8388  update_load_avg_[k]
     8043010    0.07%     8030  AbstractPipeline.wrapSink
     6646490    0.06%     6642  Collection.stream
     6512786    0.06%     6382  __update_load_avg_se_[k]
     5838032    0.05%     5712  update_curr_[k]
     5219741    0.05%     5135  update_cfs_group_[k]
     5159790    0.05%     5125  __memset_avx2_unaligned_erms
     5134190    0.04%     5138  ArrayList$SubList$1.hasNext
     4845786    0.04%     4764  syscall_exit_to_user_mode_[k]
     4840579    0.04%     4862  LinkedTransferQueue.awaitMatch
     4698781    0.04%     4699  ChannelsGrid$$Lambda$58.0x0000000801036fb0.accept
     4667352    0.04%     4667  Integer.valueOf
     4452737    0.04%     4450  ReferencePipeline$3.<init>
     4273665    0.04%     4265  ReferencePipeline.mapToInt
     4028790    0.04%     4016  PipelineHelper.<init>
     4024637    0.04%     3931  update_blocked_averages_[k]
     4004264    0.03%     4008  G1ParScanThreadState::trim_queue_to_threshold(unsigned int)
     3865113    0.03%     3854  StreamOpFlag.combineOpFlags
     3679976    0.03%     3602  __calc_delta_[k]
     3674854    0.03%     3603  pick_next_task_fair_[k]
     3656929    0.03%     3648  Unsafe_Park
     3338787    0.03%     3330  IntPipeline.<init>
     3297736    0.03%     3253  reweight_entity_[k]
     2959581    0.03%     2961  ChannelsGrid.lambda$forEachChannel$1
     2958444    0.03%     2955  GameOfLifeBenchmark_benchmark_jmhTest.benchmark_thrpt_jmhStub
     2950795    0.03%     2925  enqueue_entity_[k]
     2880332    0.03%     2838  __schedule_[k]
     2550301    0.02%     2549  Invokers$Holder.linkToTargetMethod
     2449246    0.02%     2450  ChannelsGrid$$Lambda$52.0x00000008010362f0.accept
     2445363    0.02%     2439  Parker::park(bool, long)
     2424678    0.02%     2379  check_preemption_disabled_[k]
     2372113    0.02%     2366  I2C/C2I adapters
     2331786    0.02%     2290  _raw_spin_lock_[k]
     2289613    0.02%     2290  Objects.requireNonNull
     2238594    0.02%     2219  enqueue_task_fair_[k]
     2130746    0.02%     2122  Unsafe.park
     2088508    0.02%     2089  Boolean.booleanValue
     2077612    0.02%     2021  __get_user_8_[k]
     2017014    0.02%     2028  JVM_Yield
     2014552    0.02%     2014  ReferencePipeline.<init>
     1939429    0.02%     1895  update_min_vruntime_[k]
     1935090    0.02%     1925  G1CardSet::occupied() const
     1902803    0.02%     1901  Cell.calculateNextState
     1871071    0.02%     1858  CellsGroup.run
     1821967    0.02%     1828  ___pthread_cond_wait
     1805102    0.02%     1803  DirectMethodHandle.allocateInstance
     1724098    0.02%     1700  select_task_rq_fair_[k]
     1675883    0.01%     1652  futex_q_lock_[k]
     1647027    0.01%     1615  update_rq_clock_[k]
     1592521    0.01%     1571  iterate_groups_[k]
     1570035    0.01%     1571  ArrayList.elementAt
     1530693    0.01%     1507  preempt_count_add_[k]
     1517253    0.01%     1470  rcu_sched_clock_irq_[k]
     1510479    0.01%     1479  update_irq_load_avg_[k]
     1508213    0.01%     1507  __futex_abstimed_wait_common
     1506684    0.01%     1508  Thread.yield0
     1489912    0.01%     1452  asm_sysvec_apic_timer_interrupt_[k]
     1487472    0.01%     1490  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<1335398ul, G1BarrierSet>, (AccessInternal::BarrierType)1, 1335398ul>::oop_access_barrier(oopDesc*, long, oopDesc*)
     1480481    0.01%     1442  task_tick_fair_[k]
     1441238    0.01%     1441  __GI___pthread_mutex_lock
     1435986    0.01%     1403  preempt_count_sub_[k]
     1428598    0.01%     1380  rb_next_[k]
     1399014    0.01%     1387  psi_task_change_[k]
     1336186    0.01%     1311  G1Allocator::unsafe_max_tlab_alloc()
     1324876    0.01%     1278  syscall_return_via_sysret_[k]
     1318713    0.01%     1276  fpregs_restore_userregs_[k]
     1285122    0.01%     1269  native_sched_clock_[k]
     1283063    0.01%     1277  ObjArrayKlass::multi_allocate(int, int*, JavaThread*)
     1279084    0.01%     1258  cpuacct_charge_[k]
     1265634    0.01%     1273  pthread_mutex_trylock@@GLIBC_2.34
     1242872    0.01%     1242  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<548964ul, G1BarrierSet>, (AccessInternal::BarrierType)2, 548964ul>::oop_access_barrier(void*)
     1240510    0.01%     1215  futex_wake_[k]
     1231016    0.01%     1223  __condvar_dec_grefs
     1224416    0.01%     1186  __hrtimer_run_queues_[k]
     1221606    0.01%     1222  MemAllocator::allocate() const
     1181361    0.01%     1164  psi_task_switch_[k]
     1168955    0.01%     1152  futex_wake_mark_[k]
     1160486    0.01%     1165  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<286822ul, G1BarrierSet>, (AccessInternal::BarrierType)3, 286822ul>::oop_access_barrier(oopDesc*, long)
     1118498    0.01%     1083  restore_fpregs_from_fpstate_[k]
     1116034    0.01%     1102  G1Policy::preventive_collection_required(unsigned int)
     1086490    0.01%     1040  exit_to_user_mode_prepare_[k]
     1072630    0.01%     1071  TypeArrayKlass::multi_allocate(int, int*, JavaThread*)
     1048630    0.01%     1052  void OopOopIterateBackwardsDispatch<G1ScanEvacuatedObjClosure>::Table::oop_oop_iterate_backwards<InstanceKlass, narrowOop>(G1ScanEvacuatedObjClosure*, oopDesc*, Klass*)
     1028693    0.01%     1030  Unsafe_Unpark
     1022089    0.01%     1029  sched_yield
     1009412    0.01%      992  try_to_wake_up_[k]
     1005981    0.01%     1009  LinkedTransferQueue$Node.isReleasable
     1001252    0.01%      992  G1Analytics::predict_scan_card_num(unsigned long, bool) const
      987681    0.01%      991  __tls_get_addr
      977212    0.01%      983  ___pthread_cond_signal
      947612    0.01%      943  ThreadsListHandle::cv_internal_thread_to_JavaThread(_jobject*, JavaThread**, oopDesc**)
      924404    0.01%      919  ObjArrayKlass::allocate(int, JavaThread*)
      897220    0.01%      878  timerqueue_add_[k]
      890173    0.01%      886  dequeue_entity_[k]
      889433    0.01%      879  newidle_balance_[k]
      887687    0.01%      893  native_write_msr_[k]
      884072    0.01%      871  update_sd_lb_stats.constprop.0_[k]
      878414    0.01%      874  HeapRegionManager::allocate_free_region(HeapRegionType, unsigned int)
      873844    0.01%      866  G1CollectedHeap::allocate_new_tlab(unsigned long, unsigned long, unsigned long*)
      851912    0.01%      849  LambdaForm$MH.0x0000000801002800.invoke
      827693    0.01%      823  OptoRuntime::new_instance_C(Klass*, JavaThread*)
      827673    0.01%      825  __clock_gettime
      815140    0.01%      805  ThreadPoolExecutor.getTask
      813876    0.01%      806  MemAllocator::allocate_inside_tlab_slow(MemAllocator::Allocation&) const
      790633    0.01%      778  futex_wait_[k]
      788662    0.01%      778  entry_SYSCALL_64_safe_stack_[k]
      779405    0.01%      759  native_read_msr_[k]
      778275    0.01%      781  __pthread_mutex_unlock_usercnt
      776635    0.01%      767  G1CollectedHeap::fill_with_dummy_object(HeapWordImpl**, HeapWordImpl**, bool)
      757615    0.01%      748  __cgroup_account_cputime_[k]
      756453    0.01%      732  __cgroup_account_cputime_field_[k]
      750877    0.01%      753  G1FromCardCache::clear(unsigned int)
      743799    0.01%      735  __perf_event_task_sched_out_[k]
      739818    0.01%      719  update_process_times_[k]
      721324    0.01%      721  java_lang_Thread::set_thread_status(oopDesc*, JavaThreadStatus)
      705552    0.01%      694  __get_user_nocheck_4_[k]
      699650    0.01%      698  JavaThread::threadObj() const
      698560    0.01%      696  dequeue_task_fair_[k]
      697642    0.01%      690  GameOfLife.calculateFrameBlocking
      683119    0.01%      671  pick_next_entity_[k]
      680240    0.01%      681  Klass::check_array_allocation_length(int, int, JavaThread*)
      677294    0.01%      672  JavaFrameAnchor::make_walkable()
      672188    0.01%      652  scheduler_tick_[k]
      670322    0.01%      655  _raw_spin_lock_irqsave_[k]
      665338    0.01%      661  ClassLoaderData::holder() const
      651870    0.01%      652  ObjArrayAllocator::initialize(HeapWordImpl**) const
      643675    0.01%      633  AbsSeq::davg() const
      635712    0.01%      639  AbstractQueuedSynchronizer.acquire
      634311    0.01%      633  OptoRuntime::multianewarray2_C(Klass*, int, int, JavaThread*)
      620408    0.01%      621  SharedRuntime::on_slowpath_allocation_exit(JavaThread*)
      619992    0.01%      618  Thread.interrupted
      618266    0.01%      614  HSpaceCounters::update_used(unsigned long)
      614683    0.01%      612  G1YoungRemSetSamplingClosure::do_heap_region(HeapRegion*)
      609617    0.01%      591  hrtimer_interrupt_[k]
      603885    0.01%      599  __vdso_clock_gettime
      598005    0.01%      600  AbsSeq::dsd() const
      591758    0.01%      591  void OopOopIterateDispatch<G1ScanCardClosure>::Table::oop_oop_iterate<InstanceKlass, narrowOop>(G1ScanCardClosure*, oopDesc*, Klass*)
      589434    0.01%      582  G1CollectedHeap::attempt_allocation_slow(unsigned long)
      581471    0.01%      582  FreeListAllocator::reset()
      576582    0.01%      561  pvclock_gtod_notify?[kvm]_[k]
      567109    0.00%      554  timekeeping_advance_[k]
      561674    0.00%      546  hrtimer_active_[k]
      548293    0.00%      548  ThreadsListHandle::ThreadsListHandle(Thread*)
      538578    0.00%      529  __GI___pthread_disable_asynccancel
      536145    0.00%      523  read_tsc_[k]
      533142    0.00%      524  yield_task_fair_[k]
      532168    0.00%      522  schedule_[k]
      531798    0.00%      519  ReentrantLock$NonfairSync.initialTryLock
      529462    0.00%      531  java_lang_Thread::get_thread_status(oopDesc*)
      526051    0.00%      525  AbstractQueuedSynchronizer.compareAndSetState
      517005    0.00%      517  CardTableBarrierSet::on_slowpath_allocation_exit(JavaThread*, oopDesc*)
      513766    0.00%      509  G1CollectedHeap::unsafe_max_tlab_alloc(Thread*) const
