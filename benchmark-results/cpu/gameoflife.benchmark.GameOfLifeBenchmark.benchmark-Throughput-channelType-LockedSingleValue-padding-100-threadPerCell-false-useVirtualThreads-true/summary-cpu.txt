--- Execution profile ---
Total samples       : 62801
unknown_Java        : 188 (0.30%)
not_walkable_Java   : 78 (0.12%)

--- 24650865447 ns (3.92%), 2465 samples
  [ 0] void OopOopIterateDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate<InstanceKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*)
  [ 1] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#0 tid=200494]

--- 17812980485 ns (2.84%), 1780 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 5] Iterable.forEach
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run
  [16] [ForkJoinPool-1-worker-1 tid=200524]

--- 17472113454 ns (2.78%), 1746 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 5] Iterable.forEach
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run
  [16] [ForkJoinPool-1-worker-2 tid=200525]

--- 17382154158 ns (2.77%), 1737 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 5] Iterable.forEach
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run
  [16] [ForkJoinPool-1-worker-3 tid=200526]

--- 17241977897 ns (2.74%), 1723 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 5] Iterable.forEach
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run
  [16] [ForkJoinPool-1-worker-4 tid=200527]

--- 17171734949 ns (2.73%), 1716 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 5] Iterable.forEach
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run
  [16] [ForkJoinPool-1-worker-5 tid=200528]

--- 16953000050 ns (2.70%), 1694 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 5] Iterable.forEach
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run
  [16] [ForkJoinPool-1-worker-6 tid=200529]

--- 16901639505 ns (2.69%), 1689 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 5] Iterable.forEach
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run
  [16] [ForkJoinPool-1-worker-8 tid=200532]

--- 16882648821 ns (2.69%), 1687 samples
  [ 0] Cell.lambda$notifyLiveness$0
  [ 1] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 2] ArrayList.forEach
  [ 3] Cell.notifyLiveness
  [ 4] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 5] Iterable.forEach
  [ 6] Continuation.enterSpecial
  [ 7] Continuation.run
  [ 8] VirtualThread.runContinuation
  [ 9] VirtualThread$$Lambda$51.0x000000080103df08.run
  [10] ForkJoinTask$RunnableExecuteAction.exec
  [11] ForkJoinTask.doExec
  [12] ForkJoinPool$WorkQueue.topLevelExec
  [13] ForkJoinPool.scan
  [14] ForkJoinPool.runWorker
  [15] ForkJoinWorkerThread.run
  [16] [ForkJoinPool-1-worker-7 tid=200531]

--- 12681404452 ns (2.02%), 1268 samples
  [ 0] oopDesc::size()
  [ 1] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 2] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 3] G1ConcurrentRefineThread::run_service()
  [ 4] ConcurrentGCThread::run()
  [ 5] Thread::call_run()
  [ 6] thread_native_entry(Thread*)
  [ 7] start_thread
  [ 8] [G1 Refine#0 tid=200494]

--- 10700579579 ns (1.70%), 1070 samples
  [ 0] void OopOopIterateDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate<InstanceKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*)
  [ 1] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#1 tid=200540]

--- 9911025817 ns (1.58%), 991 samples
  [ 0] oopDesc::size()
  [ 1] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#0 tid=200494]

--- 8470352851 ns (1.35%), 847 samples
  [ 0] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 1] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 2] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 3] G1ConcurrentRefineThread::run_service()
  [ 4] ConcurrentGCThread::run()
  [ 5] Thread::call_run()
  [ 6] thread_native_entry(Thread*)
  [ 7] start_thread
  [ 8] [G1 Refine#0 tid=200494]

--- 8410360308 ns (1.34%), 841 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run
  [23] [ForkJoinPool-1-worker-1 tid=200524]

--- 8260432143 ns (1.31%), 826 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run
  [23] [ForkJoinPool-1-worker-5 tid=200528]

--- 8250657608 ns (1.31%), 825 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run
  [23] [ForkJoinPool-1-worker-3 tid=200526]

--- 8250404327 ns (1.31%), 825 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run
  [23] [ForkJoinPool-1-worker-8 tid=200532]

--- 8240294304 ns (1.31%), 824 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run
  [23] [ForkJoinPool-1-worker-4 tid=200527]

--- 8230327592 ns (1.31%), 823 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run
  [23] [ForkJoinPool-1-worker-6 tid=200529]

--- 8150538803 ns (1.30%), 815 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run
  [23] [ForkJoinPool-1-worker-2 tid=200525]

--- 8140636902 ns (1.30%), 814 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] CellsGroup.run
  [13] Continuation.enterSpecial
  [14] Continuation.run
  [15] VirtualThread.runContinuation
  [16] VirtualThread$$Lambda$51.0x000000080103df08.run
  [17] ForkJoinTask$RunnableExecuteAction.exec
  [18] ForkJoinTask.doExec
  [19] ForkJoinPool$WorkQueue.topLevelExec
  [20] ForkJoinPool.scan
  [21] ForkJoinPool.runWorker
  [22] ForkJoinWorkerThread.run
  [23] [ForkJoinPool-1-worker-7 tid=200531]

--- 5700232564 ns (0.91%), 570 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-2 tid=200525]

--- 5380392904 ns (0.86%), 538 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-5 tid=200528]

--- 5340392266 ns (0.85%), 534 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-6 tid=200529]

--- 5310502195 ns (0.85%), 531 samples
  [ 0] oopDesc::size()
  [ 1] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 2] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 3] G1ConcurrentRefineThread::run_service()
  [ 4] ConcurrentGCThread::run()
  [ 5] Thread::call_run()
  [ 6] thread_native_entry(Thread*)
  [ 7] start_thread
  [ 8] [G1 Refine#1 tid=200540]

--- 5070195766 ns (0.81%), 507 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-8 tid=200532]

--- 5010461745 ns (0.80%), 501 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-3 tid=200526]

--- 5000213432 ns (0.80%), 500 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-1 tid=200524]

--- 4980580718 ns (0.79%), 498 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-7 tid=200531]

--- 4960505885 ns (0.79%), 496 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] CellsGroup.run
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-4 tid=200527]

--- 3970136088 ns (0.63%), 397 samples
  [ 0] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 1] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 2] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 3] G1ConcurrentRefineThread::run_service()
  [ 4] ConcurrentGCThread::run()
  [ 5] Thread::call_run()
  [ 6] thread_native_entry(Thread*)
  [ 7] start_thread
  [ 8] [G1 Refine#1 tid=200540]

--- 3779852960 ns (0.60%), 378 samples
  [ 0] void QuickSort::inner_sort<false, unsigned char*, int (*)(unsigned char const*, unsigned char const*)>(unsigned char**, unsigned long, int (*)(unsigned char const*, unsigned char const*)) [clone .constprop.0]
  [ 1] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 2] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 3] G1ConcurrentRefineThread::run_service()
  [ 4] ConcurrentGCThread::run()
  [ 5] Thread::call_run()
  [ 6] thread_native_entry(Thread*)
  [ 7] start_thread
  [ 8] [G1 Refine#0 tid=200494]

--- 3730453299 ns (0.59%), 373 samples
  [ 0] oopDesc::size()
  [ 1] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#1 tid=200540]

--- 3131970634 ns (0.50%), 313 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-3 tid=200526]

--- 3102457478 ns (0.49%), 310 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-7 tid=200531]

--- 3062420130 ns (0.49%), 306 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-2 tid=200525]

--- 2950259456 ns (0.47%), 295 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run
  [29] [ForkJoinPool-1-worker-4 tid=200527]

--- 2931735994 ns (0.47%), 293 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-8 tid=200532]

--- 2929922963 ns (0.47%), 293 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run
  [29] [ForkJoinPool-1-worker-7 tid=200531]

--- 2842167346 ns (0.45%), 284 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-1 tid=200524]

--- 2821986891 ns (0.45%), 282 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-6 tid=200529]

--- 2791365172 ns (0.44%), 279 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-4 tid=200527]

--- 2790160202 ns (0.44%), 279 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run
  [29] [ForkJoinPool-1-worker-8 tid=200532]

--- 2781365930 ns (0.44%), 278 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.put
  [ 5] Channel.put
  [ 6] Cell.lambda$notifyLiveness$0
  [ 7] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 8] ArrayList.forEach
  [ 9] Cell.notifyLiveness
  [10] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-5 tid=200528]

--- 2690133486 ns (0.43%), 269 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run
  [29] [ForkJoinPool-1-worker-2 tid=200525]

--- 2620106746 ns (0.42%), 262 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run
  [29] [ForkJoinPool-1-worker-5 tid=200528]

--- 2569891245 ns (0.41%), 257 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run
  [29] [ForkJoinPool-1-worker-1 tid=200524]

--- 2510206515 ns (0.40%), 251 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run
  [29] [ForkJoinPool-1-worker-6 tid=200529]

--- 2490113045 ns (0.40%), 249 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] CellsGroup.run
  [19] Continuation.enterSpecial
  [20] Continuation.run
  [21] VirtualThread.runContinuation
  [22] VirtualThread$$Lambda$51.0x000000080103df08.run
  [23] ForkJoinTask$RunnableExecuteAction.exec
  [24] ForkJoinTask.doExec
  [25] ForkJoinPool$WorkQueue.topLevelExec
  [26] ForkJoinPool.scan
  [27] ForkJoinPool.runWorker
  [28] ForkJoinWorkerThread.run
  [29] [ForkJoinPool-1-worker-3 tid=200526]

--- 2151810969 ns (0.34%), 215 samples
  [ 0] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 1] Iterable.forEach
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run
  [12] [ForkJoinPool-1-worker-1 tid=200524]

--- 2091854085 ns (0.33%), 209 samples
  [ 0] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 1] Iterable.forEach
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run
  [12] [ForkJoinPool-1-worker-5 tid=200528]

--- 2060094724 ns (0.33%), 206 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-5 tid=200528]

--- 2060042705 ns (0.33%), 206 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-6 tid=200529]

--- 2040175547 ns (0.32%), 204 samples
  [ 0] void OopOopIterateDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate<InstanceKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*)
  [ 1] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#2 tid=200541]

--- 2039991347 ns (0.32%), 204 samples
  [ 0] void OopOopIterateDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate<ObjArrayKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*)
  [ 1] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#0 tid=200494]

--- 2020163612 ns (0.32%), 202 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-4 tid=200527]

--- 2020139817 ns (0.32%), 202 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-8 tid=200532]

--- 2011584279 ns (0.32%), 201 samples
  [ 0] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 1] Iterable.forEach
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run
  [12] [ForkJoinPool-1-worker-6 tid=200529]

--- 1991701780 ns (0.32%), 199 samples
  [ 0] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 1] Iterable.forEach
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run
  [12] [ForkJoinPool-1-worker-4 tid=200527]

--- 1990144795 ns (0.32%), 199 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-2 tid=200525]

--- 1989965465 ns (0.32%), 199 samples
  [ 0] G1HotCardCache::insert(unsigned char*)
  [ 1] G1RemSet::clean_card_before_refine(unsigned char**)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#0 tid=200494]

--- 1920117940 ns (0.31%), 192 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-3 tid=200526]

--- 1920007612 ns (0.31%), 192 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-1 tid=200524]

--- 1901254981 ns (0.30%), 190 samples
  [ 0] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 1] Iterable.forEach
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run
  [12] [ForkJoinPool-1-worker-8 tid=200532]

--- 1900242844 ns (0.30%), 190 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-7 tid=200531]

--- 1841026966 ns (0.29%), 184 samples
  [ 0] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 1] Iterable.forEach
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run
  [12] [ForkJoinPool-1-worker-7 tid=200531]

--- 1820983889 ns (0.29%), 182 samples
  [ 0] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 1] Iterable.forEach
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run
  [12] [ForkJoinPool-1-worker-2 tid=200525]

--- 1820043172 ns (0.29%), 182 samples
  [ 0] void QuickSort::inner_sort<false, unsigned char*, int (*)(unsigned char const*, unsigned char const*)>(unsigned char**, unsigned long, int (*)(unsigned char const*, unsigned char const*)) [clone .constprop.0]
  [ 1] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 2] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 3] G1ConcurrentRefineThread::run_service()
  [ 4] ConcurrentGCThread::run()
  [ 5] Thread::call_run()
  [ 6] thread_native_entry(Thread*)
  [ 7] start_thread
  [ 8] [G1 Refine#1 tid=200540]

--- 1789985777 ns (0.28%), 179 samples
  [ 0] void OopOopIterateDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate<InstanceKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*)
  [ 1] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 2] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 3] G1ConcurrentRefineThread::run_service()
  [ 4] ConcurrentGCThread::run()
  [ 5] Thread::call_run()
  [ 6] thread_native_entry(Thread*)
  [ 7] start_thread
  [ 8] [G1 Refine#0 tid=200494]

--- 1641242321 ns (0.26%), 164 samples
  [ 0] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 1] Iterable.forEach
  [ 2] Continuation.enterSpecial
  [ 3] Continuation.run
  [ 4] VirtualThread.runContinuation
  [ 5] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 6] ForkJoinTask$RunnableExecuteAction.exec
  [ 7] ForkJoinTask.doExec
  [ 8] ForkJoinPool$WorkQueue.topLevelExec
  [ 9] ForkJoinPool.scan
  [10] ForkJoinPool.runWorker
  [11] ForkJoinWorkerThread.run
  [12] [ForkJoinPool-1-worker-3 tid=200526]

--- 1560091511 ns (0.25%), 156 samples
  [ 0] G1RemSet::clean_card_before_refine(unsigned char**)
  [ 1] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 2] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 3] G1ConcurrentRefineThread::run_service()
  [ 4] ConcurrentGCThread::run()
  [ 5] Thread::call_run()
  [ 6] thread_native_entry(Thread*)
  [ 7] start_thread
  [ 8] [G1 Refine#0 tid=200494]

--- 1550106839 ns (0.25%), 155 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$63.0x0000000801036978.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-8 tid=200532]

--- 1520158415 ns (0.24%), 152 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$63.0x0000000801036978.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-7 tid=200531]

--- 1490071194 ns (0.24%), 149 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$63.0x0000000801036978.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-4 tid=200527]

--- 1470129432 ns (0.23%), 147 samples
  [ 0] G1BlockOffsetTablePart::block_start(void const*)
  [ 1] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#0 tid=200494]

--- 1440058664 ns (0.23%), 144 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$63.0x0000000801036978.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-6 tid=200529]

--- 1440030494 ns (0.23%), 144 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$63.0x0000000801036978.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-1 tid=200524]

--- 1431048676 ns (0.23%), 143 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 9] Iterable.forEach
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-5 tid=200528]

--- 1410126445 ns (0.22%), 141 samples
  [ 0] G1CardSet::add_card(unsigned int, unsigned int, bool)
  [ 1] void OopOopIterateDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate<InstanceKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*)
  [ 2] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 3] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 4] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 5] G1ConcurrentRefineThread::run_service()
  [ 6] ConcurrentGCThread::run()
  [ 7] Thread::call_run()
  [ 8] thread_native_entry(Thread*)
  [ 9] start_thread
  [10] [G1 Refine#0 tid=200494]

--- 1401015196 ns (0.22%), 140 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 9] Iterable.forEach
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-7 tid=200531]

--- 1399963689 ns (0.22%), 140 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$63.0x0000000801036978.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-3 tid=200526]

--- 1390019569 ns (0.22%), 139 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$63.0x0000000801036978.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-5 tid=200528]

--- 1370063362 ns (0.22%), 137 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$63.0x0000000801036978.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-3 tid=200526]

--- 1330950515 ns (0.21%), 133 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 9] Iterable.forEach
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-8 tid=200532]

--- 1330036503 ns (0.21%), 133 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$63.0x0000000801036978.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-5 tid=200528]

--- 1320100427 ns (0.21%), 132 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$63.0x0000000801036978.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-1 tid=200524]

--- 1310018730 ns (0.21%), 131 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$63.0x0000000801036978.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-8 tid=200532]

--- 1299892894 ns (0.21%), 130 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$63.0x0000000801036978.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-4 tid=200527]

--- 1289958190 ns (0.21%), 129 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$63.0x0000000801036978.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run
  [27] [ForkJoinPool-1-worker-5 tid=200528]

--- 1280245491 ns (0.20%), 128 samples
  [ 0] Channel.take
  [ 1] Cell$$Lambda$63.0x0000000801036978.apply
  [ 2] ReferencePipeline$3$1.accept
  [ 3] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 4] AbstractPipeline.copyInto
  [ 5] AbstractPipeline.wrapAndCopyInto
  [ 6] ReduceOps$ReduceOp.evaluateSequential
  [ 7] AbstractPipeline.evaluate
  [ 8] IntPipeline.reduce
  [ 9] IntPipeline.sum
  [10] Cell.calculateNextState
  [11] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [12] Iterable.forEach
  [13] CellsGroup.run
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-2 tid=200525]

--- 1270867753 ns (0.20%), 127 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 9] Iterable.forEach
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-6 tid=200529]

--- 1251364340 ns (0.20%), 125 samples
  [ 0] TickPerCell.lambda$tick$0
  [ 1] TickPerCell$$Lambda$57.0x0000000801035cb0.accept
  [ 2] ChannelsGrid.lambda$forEachChannel$0
  [ 3] ChannelsGrid$$Lambda$58.0x0000000801035ec8.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] TickPerCell.tick
  [ 7] GameOfLife.calculateFrame
  [ 8] GameOfLife.lambda$calculateFrameBlocking$4
  [ 9] GameOfLife$$Lambda$53.0x0000000801035268.run
  [10] VirtualThread.run
  [11] VirtualThread$VThreadContinuation.lambda$new$0
  [12] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [13] Continuation.enter0
  [14] Continuation.enter
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-7 tid=200531]

--- 1241442598 ns (0.20%), 124 samples
  [ 0] TickPerCell.lambda$tick$0
  [ 1] TickPerCell$$Lambda$57.0x0000000801035cb0.accept
  [ 2] ChannelsGrid.lambda$forEachChannel$0
  [ 3] ChannelsGrid$$Lambda$58.0x0000000801035ec8.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] TickPerCell.tick
  [ 7] GameOfLife.calculateFrame
  [ 8] GameOfLife.lambda$calculateFrameBlocking$4
  [ 9] GameOfLife$$Lambda$53.0x0000000801035268.run
  [10] VirtualThread.run
  [11] VirtualThread$VThreadContinuation.lambda$new$0
  [12] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [13] Continuation.enter0
  [14] Continuation.enter
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-5 tid=200528]

--- 1239965162 ns (0.20%), 124 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$63.0x0000000801036978.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-2 tid=200525]

--- 1230837409 ns (0.20%), 123 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 9] Iterable.forEach
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-2 tid=200525]

--- 1221181675 ns (0.19%), 122 samples
  [ 0] TickPerCell.lambda$tick$0
  [ 1] TickPerCell$$Lambda$57.0x0000000801035cb0.accept
  [ 2] ChannelsGrid.lambda$forEachChannel$0
  [ 3] ChannelsGrid$$Lambda$58.0x0000000801035ec8.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] TickPerCell.tick
  [ 7] GameOfLife.calculateFrame
  [ 8] GameOfLife.lambda$calculateFrameBlocking$4
  [ 9] GameOfLife$$Lambda$53.0x0000000801035268.run
  [10] VirtualThread.run
  [11] VirtualThread$VThreadContinuation.lambda$new$0
  [12] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [13] Continuation.enter0
  [14] Continuation.enter
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-3 tid=200526]

--- 1201649233 ns (0.19%), 120 samples
  [ 0] TickPerCell.lambda$tick$0
  [ 1] TickPerCell$$Lambda$57.0x0000000801035cb0.accept
  [ 2] ChannelsGrid.lambda$forEachChannel$0
  [ 3] ChannelsGrid$$Lambda$58.0x0000000801035ec8.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] TickPerCell.tick
  [ 7] GameOfLife.calculateFrame
  [ 8] GameOfLife.lambda$calculateFrameBlocking$4
  [ 9] GameOfLife$$Lambda$53.0x0000000801035268.run
  [10] VirtualThread.run
  [11] VirtualThread$VThreadContinuation.lambda$new$0
  [12] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [13] Continuation.enter0
  [14] Continuation.enter
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-4 tid=200527]

--- 1200046486 ns (0.19%), 120 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$63.0x0000000801036978.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-7 tid=200531]

--- 1190081138 ns (0.19%), 119 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$63.0x0000000801036978.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run
  [27] [ForkJoinPool-1-worker-3 tid=200526]

--- 1180914388 ns (0.19%), 118 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 9] Iterable.forEach
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-3 tid=200526]

--- 1161321094 ns (0.18%), 116 samples
  [ 0] TickPerCell.lambda$tick$0
  [ 1] TickPerCell$$Lambda$57.0x0000000801035cb0.accept
  [ 2] ChannelsGrid.lambda$forEachChannel$0
  [ 3] ChannelsGrid$$Lambda$58.0x0000000801035ec8.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] TickPerCell.tick
  [ 7] GameOfLife.calculateFrame
  [ 8] GameOfLife.lambda$calculateFrameBlocking$4
  [ 9] GameOfLife$$Lambda$53.0x0000000801035268.run
  [10] VirtualThread.run
  [11] VirtualThread$VThreadContinuation.lambda$new$0
  [12] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [13] Continuation.enter0
  [14] Continuation.enter
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-8 tid=200532]

--- 1160305503 ns (0.18%), 116 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] Cell$$Lambda$63.0x0000000801036978.apply
  [ 6] ReferencePipeline$3$1.accept
  [ 7] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 8] AbstractPipeline.copyInto
  [ 9] AbstractPipeline.wrapAndCopyInto
  [10] ReduceOps$ReduceOp.evaluateSequential
  [11] AbstractPipeline.evaluate
  [12] IntPipeline.reduce
  [13] IntPipeline.sum
  [14] Cell.calculateNextState
  [15] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [16] Iterable.forEach
  [17] CellsGroup.run
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-6 tid=200529]

--- 1151437555 ns (0.18%), 115 samples
  [ 0] TickPerCell.lambda$tick$0
  [ 1] TickPerCell$$Lambda$57.0x0000000801035cb0.accept
  [ 2] ChannelsGrid.lambda$forEachChannel$0
  [ 3] ChannelsGrid$$Lambda$58.0x0000000801035ec8.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] TickPerCell.tick
  [ 7] GameOfLife.calculateFrame
  [ 8] GameOfLife.lambda$calculateFrameBlocking$4
  [ 9] GameOfLife$$Lambda$53.0x0000000801035268.run
  [10] VirtualThread.run
  [11] VirtualThread$VThreadContinuation.lambda$new$0
  [12] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [13] Continuation.enter0
  [14] Continuation.enter
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-2 tid=200525]

--- 1150101784 ns (0.18%), 115 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$63.0x0000000801036978.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run
  [27] [ForkJoinPool-1-worker-4 tid=200527]

--- 1140992743 ns (0.18%), 114 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 9] Iterable.forEach
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-1 tid=200524]

--- 1140681164 ns (0.18%), 114 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-6 tid=200529]

--- 1121017203 ns (0.18%), 112 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-1 tid=200524]

--- 1120904768 ns (0.18%), 112 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-4 tid=200527]

--- 1110920123 ns (0.18%), 111 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-5 tid=200528]

--- 1100346025 ns (0.18%), 110 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.put
  [ 3] Channel.put
  [ 4] Cell.lambda$notifyLiveness$0
  [ 5] Cell$$Lambda$59.0x00000008010360e8.accept
  [ 6] ArrayList.forEach
  [ 7] Cell.notifyLiveness
  [ 8] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 9] Iterable.forEach
  [10] Continuation.enterSpecial
  [11] Continuation.run
  [12] VirtualThread.runContinuation
  [13] VirtualThread$$Lambda$51.0x000000080103df08.run
  [14] ForkJoinTask$RunnableExecuteAction.exec
  [15] ForkJoinTask.doExec
  [16] ForkJoinPool$WorkQueue.topLevelExec
  [17] ForkJoinPool.scan
  [18] ForkJoinPool.runWorker
  [19] ForkJoinWorkerThread.run
  [20] [ForkJoinPool-1-worker-4 tid=200527]

--- 1090976845 ns (0.17%), 109 samples
  [ 0] TickPerCell.lambda$tick$0
  [ 1] TickPerCell$$Lambda$57.0x0000000801035cb0.accept
  [ 2] ChannelsGrid.lambda$forEachChannel$0
  [ 3] ChannelsGrid$$Lambda$58.0x0000000801035ec8.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] TickPerCell.tick
  [ 7] GameOfLife.calculateFrame
  [ 8] GameOfLife.lambda$calculateFrameBlocking$4
  [ 9] GameOfLife$$Lambda$53.0x0000000801035268.run
  [10] VirtualThread.run
  [11] VirtualThread$VThreadContinuation.lambda$new$0
  [12] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [13] Continuation.enter0
  [14] Continuation.enter
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-6 tid=200529]

--- 1090792058 ns (0.17%), 109 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-7 tid=200531]

--- 1081105533 ns (0.17%), 108 samples
  [ 0] TickPerCell.lambda$tick$0
  [ 1] TickPerCell$$Lambda$57.0x0000000801035cb0.accept
  [ 2] ChannelsGrid.lambda$forEachChannel$0
  [ 3] ChannelsGrid$$Lambda$58.0x0000000801035ec8.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] TickPerCell.tick
  [ 7] GameOfLife.calculateFrame
  [ 8] GameOfLife.lambda$calculateFrameBlocking$4
  [ 9] GameOfLife$$Lambda$53.0x0000000801035268.run
  [10] VirtualThread.run
  [11] VirtualThread$VThreadContinuation.lambda$new$0
  [12] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [13] Continuation.enter0
  [14] Continuation.enter
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-1 tid=200524]

--- 1080118625 ns (0.17%), 108 samples
  [ 0] G1HotCardCache::insert(unsigned char*)
  [ 1] G1RemSet::clean_card_before_refine(unsigned char**)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#1 tid=200540]

--- 1060134911 ns (0.17%), 106 samples
  [ 0] oopDesc::size()
  [ 1] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 2] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 3] G1ConcurrentRefineThread::run_service()
  [ 4] ConcurrentGCThread::run()
  [ 5] Thread::call_run()
  [ 6] thread_native_entry(Thread*)
  [ 7] start_thread
  [ 8] [G1 Refine#2 tid=200541]

--- 1050020617 ns (0.17%), 105 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$63.0x0000000801036978.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run
  [27] [ForkJoinPool-1-worker-1 tid=200524]

--- 1020124897 ns (0.16%), 102 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$63.0x0000000801036978.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run
  [27] [ForkJoinPool-1-worker-8 tid=200532]

--- 1019984027 ns (0.16%), 102 samples
  [ 0] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 1] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 2] G1ConcurrentRefineThread::run_service()
  [ 3] ConcurrentGCThread::run()
  [ 4] Thread::call_run()
  [ 5] thread_native_entry(Thread*)
  [ 6] start_thread
  [ 7] [G1 Refine#0 tid=200494]

--- 1010073104 ns (0.16%), 101 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$63.0x0000000801036978.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run
  [27] [ForkJoinPool-1-worker-7 tid=200531]

--- 1010035319 ns (0.16%), 101 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$63.0x0000000801036978.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run
  [27] [ForkJoinPool-1-worker-2 tid=200525]

--- 970067370 ns (0.15%), 97 samples
  [ 0] AbstractQueuedSynchronizer.release
  [ 1] ReentrantLock.unlock
  [ 2] LockedSingleValue.take
  [ 3] Channel.take
  [ 4] Cell$$Lambda$63.0x0000000801036978.apply
  [ 5] ReferencePipeline$3$1.accept
  [ 6] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 7] AbstractPipeline.copyInto
  [ 8] AbstractPipeline.wrapAndCopyInto
  [ 9] ReduceOps$ReduceOp.evaluateSequential
  [10] AbstractPipeline.evaluate
  [11] IntPipeline.reduce
  [12] IntPipeline.sum
  [13] Cell.calculateNextState
  [14] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [15] Iterable.forEach
  [16] CellsGroup.run
  [17] Continuation.enterSpecial
  [18] Continuation.run
  [19] VirtualThread.runContinuation
  [20] VirtualThread$$Lambda$51.0x000000080103df08.run
  [21] ForkJoinTask$RunnableExecuteAction.exec
  [22] ForkJoinTask.doExec
  [23] ForkJoinPool$WorkQueue.topLevelExec
  [24] ForkJoinPool.scan
  [25] ForkJoinPool.runWorker
  [26] ForkJoinWorkerThread.run
  [27] [ForkJoinPool-1-worker-6 tid=200529]

--- 950829290 ns (0.15%), 95 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-2 tid=200525]

--- 900208241 ns (0.14%), 90 samples
  [ 0] void OopOopIterateDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate<ObjArrayKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*)
  [ 1] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#1 tid=200540]

--- 850887119 ns (0.14%), 85 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-8 tid=200532]

--- 820572086 ns (0.13%), 82 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$RunnableExecuteAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-3 tid=200526]

--- 800613891 ns (0.13%), 80 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-5 tid=200528]

--- 800563207 ns (0.13%), 80 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-4 tid=200527]

--- 790816613 ns (0.13%), 79 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-6 tid=200529]

--- 760713372 ns (0.12%), 76 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-3 tid=200526]

--- 760103862 ns (0.12%), 76 samples
  [ 0] G1CardSet::add_card(unsigned int, unsigned int, bool)
  [ 1] void OopOopIterateDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate<InstanceKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*)
  [ 2] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 3] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 4] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 5] G1ConcurrentRefineThread::run_service()
  [ 6] ConcurrentGCThread::run()
  [ 7] Thread::call_run()
  [ 8] thread_native_entry(Thread*)
  [ 9] start_thread
  [10] [G1 Refine#1 tid=200540]

--- 750620606 ns (0.12%), 75 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-2 tid=200525]

--- 740483394 ns (0.12%), 74 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-7 tid=200531]

--- 740367245 ns (0.12%), 74 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 4] Iterable.forEach
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run
  [15] [ForkJoinPool-1-worker-4 tid=200527]

--- 730099355 ns (0.12%), 73 samples
  [ 0] oopDesc::size()
  [ 1] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#2 tid=200541]

--- 719970999 ns (0.11%), 72 samples
  [ 0] void OopOopIterateDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate<InstanceKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*)
  [ 1] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 2] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 3] G1ConcurrentRefineThread::run_service()
  [ 4] ConcurrentGCThread::run()
  [ 5] Thread::call_run()
  [ 6] thread_native_entry(Thread*)
  [ 7] start_thread
  [ 8] [G1 Refine#1 tid=200540]

--- 690344690 ns (0.11%), 69 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-1 tid=200524]

--- 680096756 ns (0.11%), 68 samples
  [ 0] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 1] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 2] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 3] G1ConcurrentRefineThread::run_service()
  [ 4] ConcurrentGCThread::run()
  [ 5] Thread::call_run()
  [ 6] thread_native_entry(Thread*)
  [ 7] start_thread
  [ 8] [G1 Refine#2 tid=200541]

--- 670032004 ns (0.11%), 67 samples
  [ 0] G1BlockOffsetTablePart::block_start(void const*)
  [ 1] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#1 tid=200540]

--- 620363299 ns (0.10%), 62 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-8 tid=200532]

--- 610004445 ns (0.10%), 61 samples
  [ 0] G1RemSet::clean_card_before_refine(unsigned char**)
  [ 1] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 2] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 3] G1ConcurrentRefineThread::run_service()
  [ 4] ConcurrentGCThread::run()
  [ 5] Thread::call_run()
  [ 6] thread_native_entry(Thread*)
  [ 7] start_thread
  [ 8] [G1 Refine#1 tid=200540]

--- 590554797 ns (0.09%), 59 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 4] Iterable.forEach
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run
  [15] [ForkJoinPool-1-worker-6 tid=200529]

--- 580033929 ns (0.09%), 58 samples
  [ 0] G1CardSet::add_to_howl(void*, unsigned int, unsigned int, bool)
  [ 1] G1CardSet::add_card(unsigned int, unsigned int, bool)
  [ 2] void OopOopIterateDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate<InstanceKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*)
  [ 3] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 4] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 5] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 6] G1ConcurrentRefineThread::run_service()
  [ 7] ConcurrentGCThread::run()
  [ 8] Thread::call_run()
  [ 9] thread_native_entry(Thread*)
  [10] start_thread
  [11] [G1 Refine#0 tid=200494]

--- 570259097 ns (0.09%), 57 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 4] Iterable.forEach
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run
  [15] [ForkJoinPool-1-worker-7 tid=200531]

--- 570043077 ns (0.09%), 57 samples
  [ 0] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 1] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 2] G1ConcurrentRefineThread::run_service()
  [ 3] ConcurrentGCThread::run()
  [ 4] Thread::call_run()
  [ 5] thread_native_entry(Thread*)
  [ 6] start_thread
  [ 7] [G1 Refine#1 tid=200540]

--- 570030543 ns (0.09%), 57 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-3 tid=200526]

--- 560491073 ns (0.09%), 56 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 4] Iterable.forEach
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run
  [15] [ForkJoinPool-1-worker-3 tid=200526]

--- 560331863 ns (0.09%), 56 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 4] Iterable.forEach
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run
  [15] [ForkJoinPool-1-worker-1 tid=200524]

--- 560175007 ns (0.09%), 56 samples
  [ 0] Channel.take
  [ 1] GameOfLife$$Lambda$60.0x0000000801036308.test
  [ 2] ChannelsGrid.lambda$forEachChannel$1
  [ 3] ChannelsGrid$$Lambda$61.0x0000000801036540.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] GameOfLife.calculateFrame
  [ 7] GameOfLife.lambda$calculateFrameBlocking$4
  [ 8] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 9] VirtualThread.run
  [10] VirtualThread$VThreadContinuation.lambda$new$0
  [11] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [12] Continuation.enter0
  [13] Continuation.enter
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-3 tid=200526]

--- 540341714 ns (0.09%), 54 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 4] Iterable.forEach
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run
  [15] [ForkJoinPool-1-worker-5 tid=200528]

--- 520102219 ns (0.08%), 52 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$AdaptedRunnableAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-3 tid=200526]

--- 510327592 ns (0.08%), 51 samples
  [ 0] Channel.take
  [ 1] GameOfLife$$Lambda$60.0x0000000801036308.test
  [ 2] ChannelsGrid.lambda$forEachChannel$1
  [ 3] ChannelsGrid$$Lambda$61.0x0000000801036540.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] GameOfLife.calculateFrame
  [ 7] GameOfLife.lambda$calculateFrameBlocking$4
  [ 8] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 9] VirtualThread.run
  [10] VirtualThread$VThreadContinuation.lambda$new$0
  [11] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [12] Continuation.enter0
  [13] Continuation.enter
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-4 tid=200527]

--- 510157962 ns (0.08%), 51 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-6 tid=200529]

--- 510128434 ns (0.08%), 51 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-2 tid=200525]

--- 510009279 ns (0.08%), 51 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-1 tid=200524]

--- 489991370 ns (0.08%), 49 samples
  [ 0] void OopOopIterateBoundedDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate_bounded<ObjArrayKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*, MemRegion)
  [ 1] G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#0 tid=200494]

--- 470423782 ns (0.07%), 47 samples
  [ 0] Channel.take
  [ 1] GameOfLife$$Lambda$60.0x0000000801036308.test
  [ 2] ChannelsGrid.lambda$forEachChannel$1
  [ 3] ChannelsGrid$$Lambda$61.0x0000000801036540.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] GameOfLife.calculateFrame
  [ 7] GameOfLife.lambda$calculateFrameBlocking$4
  [ 8] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 9] VirtualThread.run
  [10] VirtualThread$VThreadContinuation.lambda$new$0
  [11] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [12] Continuation.enter0
  [13] Continuation.enter
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-2 tid=200525]

--- 470245371 ns (0.07%), 47 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 4] Iterable.forEach
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run
  [15] [ForkJoinPool-1-worker-8 tid=200532]

--- 470243534 ns (0.07%), 47 samples
  [ 0] Channel.take
  [ 1] GameOfLife$$Lambda$60.0x0000000801036308.test
  [ 2] ChannelsGrid.lambda$forEachChannel$1
  [ 3] ChannelsGrid$$Lambda$61.0x0000000801036540.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] GameOfLife.calculateFrame
  [ 7] GameOfLife.lambda$calculateFrameBlocking$4
  [ 8] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 9] VirtualThread.run
  [10] VirtualThread$VThreadContinuation.lambda$new$0
  [11] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [12] Continuation.enter0
  [13] Continuation.enter
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-5 tid=200528]

--- 460432262 ns (0.07%), 46 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-1 tid=200524]

--- 459962395 ns (0.07%), 46 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-8 tid=200532]

--- 451019344 ns (0.07%), 45 samples
  [ 0] ForkJoinPool.awaitWork
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run
  [ 3] [ForkJoinPool-1-worker-7 tid=200531]

--- 450281292 ns (0.07%), 45 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$AdaptedRunnableAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-2 tid=200525]

--- 450279475 ns (0.07%), 45 samples
  [ 0] Channel.take
  [ 1] TickPerCell.waitTick
  [ 2] Cell.notifyLiveness
  [ 3] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 4] Iterable.forEach
  [ 5] Continuation.enterSpecial
  [ 6] Continuation.run
  [ 7] VirtualThread.runContinuation
  [ 8] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 9] ForkJoinTask$RunnableExecuteAction.exec
  [10] ForkJoinTask.doExec
  [11] ForkJoinPool$WorkQueue.topLevelExec
  [12] ForkJoinPool.scan
  [13] ForkJoinPool.runWorker
  [14] ForkJoinWorkerThread.run
  [15] [ForkJoinPool-1-worker-2 tid=200525]

--- 449958539 ns (0.07%), 45 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-5 tid=200528]

--- 431290543 ns (0.07%), 43 samples
  [ 0] ForkJoinPool.awaitWork
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run
  [ 3] [ForkJoinPool-1-worker-6 tid=200529]

--- 431063837 ns (0.07%), 43 samples
  [ 0] ForkJoinPool.awaitWork
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run
  [ 3] [ForkJoinPool-1-worker-4 tid=200527]

--- 430101432 ns (0.07%), 43 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-4 tid=200527]

--- 430040611 ns (0.07%), 43 samples
  [ 0] G1CardCounts::add_card_count(unsigned char*)
  [ 1] G1RemSet::clean_card_before_refine(unsigned char**)
  [ 2] G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  [ 3] G1DirtyCardQueueSet::refine_completed_buffer_concurrently(unsigned int, unsigned long, G1ConcurrentRefineStats*)
  [ 4] G1ConcurrentRefineThread::run_service()
  [ 5] ConcurrentGCThread::run()
  [ 6] Thread::call_run()
  [ 7] thread_native_entry(Thread*)
  [ 8] start_thread
  [ 9] [G1 Refine#0 tid=200494]

--- 421457818 ns (0.07%), 42 samples
  [ 0] ForkJoinPool.awaitWork
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run
  [ 3] [ForkJoinPool-1-worker-1 tid=200524]

--- 421393041 ns (0.07%), 42 samples
  [ 0] ForkJoinPool.awaitWork
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run
  [ 3] [ForkJoinPool-1-worker-3 tid=200526]

--- 420768914 ns (0.07%), 42 samples
  [ 0] ForkJoinPool.awaitWork
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run
  [ 3] [ForkJoinPool-1-worker-2 tid=200525]

--- 420214470 ns (0.07%), 42 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$AdaptedRunnableAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-3 tid=200526]

--- 420016191 ns (0.07%), 42 samples
  [ 0] Cell.calculateNextState
  [ 1] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run
  [14] [ForkJoinPool-1-worker-6 tid=200529]

--- 400080740 ns (0.06%), 40 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] CellsGroup.run
  [15] Continuation.enterSpecial
  [16] Continuation.run
  [17] VirtualThread.runContinuation
  [18] VirtualThread$$Lambda$51.0x000000080103df08.run
  [19] ForkJoinTask$RunnableExecuteAction.exec
  [20] ForkJoinTask.doExec
  [21] ForkJoinPool$WorkQueue.topLevelExec
  [22] ForkJoinPool.scan
  [23] ForkJoinPool.runWorker
  [24] ForkJoinWorkerThread.run
  [25] [ForkJoinPool-1-worker-7 tid=200531]

--- 400080563 ns (0.06%), 40 samples
  [ 0] Channel.take
  [ 1] GameOfLife$$Lambda$60.0x0000000801036308.test
  [ 2] ChannelsGrid.lambda$forEachChannel$1
  [ 3] ChannelsGrid$$Lambda$61.0x0000000801036540.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] GameOfLife.calculateFrame
  [ 7] GameOfLife.lambda$calculateFrameBlocking$4
  [ 8] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 9] VirtualThread.run
  [10] VirtualThread$VThreadContinuation.lambda$new$0
  [11] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [12] Continuation.enter0
  [13] Continuation.enter
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-7 tid=200531]

--- 390153855 ns (0.06%), 39 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$AdaptedRunnableAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-5 tid=200528]

--- 390129081 ns (0.06%), 39 samples
  [ 0] Channel.take
  [ 1] GameOfLife$$Lambda$60.0x0000000801036308.test
  [ 2] ChannelsGrid.lambda$forEachChannel$1
  [ 3] ChannelsGrid$$Lambda$61.0x0000000801036540.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] GameOfLife.calculateFrame
  [ 7] GameOfLife.lambda$calculateFrameBlocking$4
  [ 8] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 9] VirtualThread.run
  [10] VirtualThread$VThreadContinuation.lambda$new$0
  [11] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [12] Continuation.enter0
  [13] Continuation.enter
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-1 tid=200524]

--- 390099009 ns (0.06%), 39 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$AdaptedRunnableAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-6 tid=200529]

--- 380926801 ns (0.06%), 38 samples
  [ 0] ForkJoinPool.awaitWork
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run
  [ 3] [ForkJoinPool-1-worker-8 tid=200532]

--- 380283035 ns (0.06%), 38 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-7 tid=200531]

--- 380215270 ns (0.06%), 38 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$AdaptedRunnableAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-4 tid=200527]

--- 380158140 ns (0.06%), 38 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-5 tid=200528]

--- 370199255 ns (0.06%), 37 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-8 tid=200532]

--- 370022397 ns (0.06%), 37 samples
  [ 0] Cell.calculateNextState
  [ 1] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run
  [14] [ForkJoinPool-1-worker-2 tid=200525]

--- 361453644 ns (0.06%), 36 samples
  [ 0] ForkJoinPool.awaitWork
  [ 1] ForkJoinPool.runWorker
  [ 2] ForkJoinWorkerThread.run
  [ 3] [ForkJoinPool-1-worker-5 tid=200528]

--- 360144415 ns (0.06%), 36 samples
  [ 0] Channel.take
  [ 1] GameOfLife$$Lambda$60.0x0000000801036308.test
  [ 2] ChannelsGrid.lambda$forEachChannel$1
  [ 3] ChannelsGrid$$Lambda$61.0x0000000801036540.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] GameOfLife.calculateFrame
  [ 7] GameOfLife.lambda$calculateFrameBlocking$4
  [ 8] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 9] VirtualThread.run
  [10] VirtualThread$VThreadContinuation.lambda$new$0
  [11] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [12] Continuation.enter0
  [13] Continuation.enter
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-8 tid=200532]

--- 350455292 ns (0.06%), 35 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$AdaptedRunnableAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-5 tid=200528]

--- 350352880 ns (0.06%), 35 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$AdaptedRunnableAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-2 tid=200525]

--- 350303041 ns (0.06%), 35 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-8 tid=200532]

--- 350268898 ns (0.06%), 35 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$AdaptedRunnableAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-8 tid=200532]

--- 350002181 ns (0.06%), 35 samples
  [ 0] Cell.calculateNextState
  [ 1] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run
  [14] [ForkJoinPool-1-worker-8 tid=200532]

--- 340426054 ns (0.05%), 34 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] TickPerCell.waitTick
  [ 6] Cell.notifyLiveness
  [ 7] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-8 tid=200532]

--- 340262999 ns (0.05%), 34 samples
  [ 0] LockedSingleValue.take
  [ 1] Channel.take
  [ 2] Cell$$Lambda$63.0x0000000801036978.apply
  [ 3] ReferencePipeline$3$1.accept
  [ 4] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 5] AbstractPipeline.copyInto
  [ 6] AbstractPipeline.wrapAndCopyInto
  [ 7] ReduceOps$ReduceOp.evaluateSequential
  [ 8] AbstractPipeline.evaluate
  [ 9] IntPipeline.reduce
  [10] IntPipeline.sum
  [11] Cell.calculateNextState
  [12] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [13] Iterable.forEach
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-4 tid=200527]

--- 340119913 ns (0.05%), 34 samples
  [ 0] Cell$$Lambda$63.0x0000000801036978.apply
  [ 1] ReferencePipeline$3$1.accept
  [ 2] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 3] AbstractPipeline.copyInto
  [ 4] AbstractPipeline.wrapAndCopyInto
  [ 5] ReduceOps$ReduceOp.evaluateSequential
  [ 6] AbstractPipeline.evaluate
  [ 7] IntPipeline.reduce
  [ 8] IntPipeline.sum
  [ 9] Cell.calculateNextState
  [10] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [11] Iterable.forEach
  [12] Continuation.enterSpecial
  [13] Continuation.run
  [14] VirtualThread.runContinuation
  [15] VirtualThread$$Lambda$51.0x000000080103df08.run
  [16] ForkJoinTask$AdaptedRunnableAction.exec
  [17] ForkJoinTask.doExec
  [18] ForkJoinPool$WorkQueue.topLevelExec
  [19] ForkJoinPool.scan
  [20] ForkJoinPool.runWorker
  [21] ForkJoinWorkerThread.run
  [22] [ForkJoinPool-1-worker-7 tid=200531]

--- 340104679 ns (0.05%), 34 samples
  [ 0] Channel.take
  [ 1] GameOfLife$$Lambda$60.0x0000000801036308.test
  [ 2] ChannelsGrid.lambda$forEachChannel$1
  [ 3] ChannelsGrid$$Lambda$61.0x0000000801036540.accept
  [ 4] Dimensions.forEachRowCol
  [ 5] ChannelsGrid.forEachChannel
  [ 6] GameOfLife.calculateFrame
  [ 7] GameOfLife.lambda$calculateFrameBlocking$4
  [ 8] GameOfLife$$Lambda$53.0x0000000801035268.run
  [ 9] VirtualThread.run
  [10] VirtualThread$VThreadContinuation.lambda$new$0
  [11] VirtualThread$VThreadContinuation$$Lambda$50.0x000000080103dcf8.run
  [12] Continuation.enter0
  [13] Continuation.enter
  [14] Continuation.enterSpecial
  [15] Continuation.run
  [16] VirtualThread.runContinuation
  [17] VirtualThread$$Lambda$51.0x000000080103df08.run
  [18] ForkJoinTask$RunnableExecuteAction.exec
  [19] ForkJoinTask.doExec
  [20] ForkJoinPool$WorkQueue.topLevelExec
  [21] ForkJoinPool.scan
  [22] ForkJoinPool.runWorker
  [23] ForkJoinWorkerThread.run
  [24] [ForkJoinPool-1-worker-6 tid=200529]

--- 340060741 ns (0.05%), 34 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-2 tid=200525]

--- 330322700 ns (0.05%), 33 samples
  [ 0] ReduceOps$5ReducingSink.get
  [ 1] ReduceOps$5ReducingSink.get
  [ 2] ReduceOps$ReduceOp.evaluateSequential
  [ 3] AbstractPipeline.evaluate
  [ 4] IntPipeline.reduce
  [ 5] IntPipeline.sum
  [ 6] Cell.calculateNextState
  [ 7] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$AdaptedRunnableAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-7 tid=200531]

--- 330256003 ns (0.05%), 33 samples
  [ 0] AbstractQueuedSynchronizer.compareAndSetState
  [ 1] ReentrantLock$NonfairSync.initialTryLock
  [ 2] ReentrantLock$Sync.lock
  [ 3] ReentrantLock.lock
  [ 4] LockedSingleValue.take
  [ 5] Channel.take
  [ 6] Cell$$Lambda$63.0x0000000801036978.apply
  [ 7] ReferencePipeline$3$1.accept
  [ 8] ArrayList$ArrayListSpliterator.forEachRemaining
  [ 9] AbstractPipeline.copyInto
  [10] AbstractPipeline.wrapAndCopyInto
  [11] ReduceOps$ReduceOp.evaluateSequential
  [12] AbstractPipeline.evaluate
  [13] IntPipeline.reduce
  [14] IntPipeline.sum
  [15] Cell.calculateNextState
  [16] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [17] Iterable.forEach
  [18] Continuation.enterSpecial
  [19] Continuation.run
  [20] VirtualThread.runContinuation
  [21] VirtualThread$$Lambda$51.0x000000080103df08.run
  [22] ForkJoinTask$RunnableExecuteAction.exec
  [23] ForkJoinTask.doExec
  [24] ForkJoinPool$WorkQueue.topLevelExec
  [25] ForkJoinPool.scan
  [26] ForkJoinPool.runWorker
  [27] ForkJoinWorkerThread.run
  [28] [ForkJoinPool-1-worker-4 tid=200527]

--- 330248513 ns (0.05%), 33 samples
  [ 0] ReentrantLock$NonfairSync.initialTryLock
  [ 1] ReentrantLock$Sync.lock
  [ 2] ReentrantLock.lock
  [ 3] LockedSingleValue.take
  [ 4] Channel.take
  [ 5] TickPerCell.waitTick
  [ 6] Cell.notifyLiveness
  [ 7] CellsGroup$$Lambda$55.0x0000000801035880.accept
  [ 8] Iterable.forEach
  [ 9] Continuation.enterSpecial
  [10] Continuation.run
  [11] VirtualThread.runContinuation
  [12] VirtualThread$$Lambda$51.0x000000080103df08.run
  [13] ForkJoinTask$RunnableExecuteAction.exec
  [14] ForkJoinTask.doExec
  [15] ForkJoinPool$WorkQueue.topLevelExec
  [16] ForkJoinPool.scan
  [17] ForkJoinPool.runWorker
  [18] ForkJoinWorkerThread.run
  [19] [ForkJoinPool-1-worker-5 tid=200528]

--- 330038172 ns (0.05%), 33 samples
  [ 0] Cell.calculateNextState
  [ 1] CellsGroup$$Lambda$62.0x0000000801036760.accept
  [ 2] Iterable.forEach
  [ 3] CellsGroup.run
  [ 4] Continuation.enterSpecial
  [ 5] Continuation.run
  [ 6] VirtualThread.runContinuation
  [ 7] VirtualThread$$Lambda$51.0x000000080103df08.run
  [ 8] ForkJoinTask$RunnableExecuteAction.exec
  [ 9] ForkJoinTask.doExec
  [10] ForkJoinPool$WorkQueue.topLevelExec
  [11] ForkJoinPool.scan
  [12] ForkJoinPool.runWorker
  [13] ForkJoinWorkerThread.run
  [14] [ForkJoinPool-1-worker-4 tid=200527]

          ns  percent  samples  top
  ----------  -------  -------  ---
137838257988   21.94%    13774  Cell.lambda$notifyLiveness$0
 77191414959   12.29%     7718  Cell$$Lambda$63.0x0000000801036978.apply
 54492734806    8.67%     5447  AbstractQueuedSynchronizer.compareAndSetState
 50109730389    7.98%     5010  ReduceOps$5ReducingSink.get
 40091604027    6.38%     4009  void OopOopIterateDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate<InstanceKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*)
 33423620029    5.32%     3342  oopDesc::size()
 26425471291    4.21%     2642  LockedSingleValue.take
 24512249669    3.90%     2450  AbstractQueuedSynchronizer.release
 22480606597    3.58%     2247  Channel.take
 15904084925    2.53%     1590  ReentrantLock$NonfairSync.initialTryLock
 15671544910    2.49%     1566  CellsGroup$$Lambda$55.0x0000000801035880.accept
 13190607889    2.10%     1319  G1RemSet::refine_card_concurrently(unsigned char*, unsigned int)
  9400478873    1.50%      939  TickPerCell.lambda$tick$0
  6009929868    0.96%      601  void QuickSort::inner_sort<false, unsigned char*, int (*)(unsigned char const*, unsigned char const*)>(unsigned char**, unsigned long, int (*)(unsigned char const*, unsigned char const*)) [clone .constprop.0]
  5415784781    0.86%      540  ForkJoinPool.awaitWork
  3650368917    0.58%      365  ReferencePipeline$3$1.accept
  3290455895    0.52%      329  Cell.calculateNextState
  3290127286    0.52%      329  G1HotCardCache::insert(unsigned char*)
  3190229100    0.51%      319  void OopOopIterateDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate<ObjArrayKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*)
  3001019016    0.48%      300  AbstractQueuedSynchronizer$ConditionObject.signal
  2742231895    0.44%      274  LockedSingleValue.put
  2721160647    0.43%      272  ReentrantLock$Sync.lock
  2632193118    0.42%      263  Cell.notifyLiveness
  2520488376    0.40%      252  AbstractPipeline.<init>
  2440386715    0.39%      244  ArrayList.spliterator
  2401401003    0.38%      240  ArrayList$SubList$1.next
  2380230588    0.38%      238  G1BlockOffsetTablePart::block_start(void const*)
  2340198763    0.37%      234  G1CardSet::add_card(unsigned int, unsigned int, bool)
  2330097298    0.37%      233  G1RemSet::clean_card_before_refine(unsigned char**)
  2202903266    0.35%      220  AbstractQueuedSynchronizer.signalNext
  1962425794    0.31%      196  AbstractOwnableSynchronizer.setExclusiveOwnerThread
  1880812668    0.30%      188  AbstractQueuedSynchronizer.setState
  1859091523    0.30%      185  _raw_spin_unlock_irqrestore_[k]
  1731581894    0.28%      173  ChannelsGrid.getChannel
  1721070375    0.27%      172  ArrayList.forEach
  1630011209    0.26%      163  G1DirtyCardQueueSet::refine_buffer(BufferNode*, unsigned int, G1ConcurrentRefineStats*)
  1519009614    0.24%      151  __futex_abstimed_wait_common
  1440171483    0.23%      144  ReferencePipeline$4$1.accept
  1300203715    0.21%      130  Sink$ChainedReference.<init>
  1192376905    0.19%      119  ForkJoinPool.scan
  1150287030    0.18%      115  ReferencePipeline$3.opWrapSink
  1030339537    0.16%      103  ReferencePipeline$4.opWrapSink
  1020039440    0.16%      102  G1CardSet::add_to_howl(void*, unsigned int, unsigned int, bool)
  1000760112    0.16%      100  Dimensions.forEachRowCol
   940090190    0.15%       94  ReferencePipeline.<init>
   871938945    0.14%       87  ForkJoinPool$WorkQueue.topLevelExec
   860043943    0.14%       86  PipelineHelper.<init>
   854471946    0.14%       85  ___pthread_cond_signal
   820853259    0.13%       82  itable stub
   820366168    0.13%       82  AbstractOwnableSynchronizer.getExclusiveOwnerThread
   801185076    0.13%       80  AbstractQueuedSynchronizer$ConditionObject.enableWait
   710207684    0.11%       71  Sink$ChainedReference.begin
   689970389    0.11%       69  void OopOopIterateBoundedDispatch<G1ConcurrentRefineOopClosure>::Table::oop_oop_iterate_bounded<ObjArrayKlass, narrowOop>(G1ConcurrentRefineOopClosure*, oopDesc*, Klass*, MemRegion)
   680296989    0.11%       68  Iterable.forEach
   640594433    0.10%       64  Cell$$Lambda$59.0x00000008010360e8.accept
   630580136    0.10%       63  AbstractQueuedSynchronizer.acquire
   610203315    0.10%       61  void OopOopIterateDispatch<G1ScanCardClosure>::Table::oop_oop_iterate<InstanceKlass, narrowOop>(G1ScanCardClosure*, oopDesc*, Klass*)
   600132039    0.10%       60  Object.<init>
   600058914    0.10%       60  G1CardCounts::add_card_count(unsigned char*)
   590166814    0.09%       59  vtable stub
   580646182    0.09%       58  ReentrantLock.lock
   549985768    0.09%       55  StreamOpFlag.fromCharacteristics
   530029843    0.08%       53  ReferencePipeline$3.<init>
   530014730    0.08%       53  Sink$ChainedReference.end
   520919794    0.08%       52  ChannelsGrid$$Lambda$61.0x0000000801036540.accept
   500342319    0.08%       50  ForkJoinPool$WorkQueue.push
   500278279    0.08%       50  ReentrantLock$Sync.tryRelease
   490047632    0.08%       49  ReentrantLock$Sync.isHeldExclusively
   490027092    0.08%       49  ReduceOps$5ReducingSink.accept
   442232584    0.07%       44  syscall_enter_from_user_mode_[k]
   441060142    0.07%       44  __memmove_sse2_unaligned_erms
   430898119    0.07%       43  VirtualThread.runContinuation
   421581201    0.07%       42  __lll_lock_wake
   420244017    0.07%       42  ArrayList$SubList$1.checkForComodification
   410011877    0.07%       41  Boolean.booleanValue
   390486516    0.06%       39  ForkJoinPool.compareAndExchangeCtl
   380156289    0.06%       38  Unsafe.getAndBitwiseAndInt
   380102387    0.06%       38  StreamSupport.stream
   370260828    0.06%       37  ForkJoinPool.signalWork
   360484788    0.06%       36  VirtualThread.unmount
   340451162    0.05%       34  ChannelsGrid$$Lambda$58.0x0000000801035ec8.accept
   340186750    0.05%       34  Channel.put
   340071937    0.05%       34  ArrayList.elementAt
   270239149    0.04%       27  AbstractQueuedSynchronizer.enqueue
   260423283    0.04%       26  ForkJoinTask.doExec
   260148365    0.04%       26  VirtualThread.unpark
   250134480    0.04%       25  __tls_get_addr
   240194913    0.04%       24  AbstractQueuedSynchronizer$ConditionObject.canReacquire
   230300896    0.04%       23  System$2.setExtentLocalCache
   230019547    0.04%       23  G1CardSet::add_to_container(void* volatile*, void*, unsigned int, unsigned int, bool)
   230000970    0.04%       23  Objects.requireNonNull
   220075282    0.04%       22  G1ScanHRForRegionClosure::scan_heap_roots(HeapRegion*)
   220015257    0.04%       22  _dl_update_slotinfo
   180859622    0.03%       18  Parker::park(bool, long)
   170589401    0.03%       17  ThreadPoolExecutor$Worker.tryRelease
   170458661    0.03%       17  FreezeBase::freeze_fast_copy(stackChunkOopDesc*, int)
   170213843    0.03%       17  VirtualThread.setParkPermit
   170186518    0.03%       17  VirtualThread.compareAndSetState
   169999696    0.03%       17  G1CardCounts::is_hot(unsigned int)
   160246414    0.03%       16  ForkJoinPool$WorkQueue.casSlotToNull
   160189618    0.03%       16  AbstractQueuedSynchronizer.getState
   150343142    0.02%       15  update_blocked_averages_[k]
   150038200    0.02%       15  Integer.intValue
   150016206    0.02%       15  G1DirtyCardQueueSet::dequeue_completed_buffer()
   140358182    0.02%       14  AbstractQueuedSynchronizer$ConditionObject.doSignal
   140278103    0.02%       14  AbstractQueuedSynchronizer.casTail
   140249348    0.02%       14  Continuation.yield0
   140039834    0.02%       14  ArrayList$SubList$1.hasNext
   140025185    0.02%       14  GlobalCounter::write_synchronize()
   140005772    0.02%       14  CellsGroup$$Lambda$62.0x0000000801036760.accept
   140000141    0.02%       14  AbstractPipeline.wrapSink
   130998811    0.02%       13  __schedule_[k]
   130186355    0.02%       13  int freeze<Config<(oop_kind)0, G1BarrierSet> >(JavaThread*, long*)
   130038767    0.02%       13  FreeListAllocator::allocate()
   120543469    0.02%       12  finish_task_switch.isra.0_[k]
   120359873    0.02%       12  Continuation::prepare_thaw(JavaThread*, bool)
   120167654    0.02%       12  ___pthread_cond_wait
   119986015    0.02%       12  update_get_addr
   111145169    0.02%       11  _raw_spin_lock_[k]
   110150613    0.02%       11  SafepointMechanism::update_poll_values(JavaThread*)
   110114051    0.02%       11  Integer.valueOf
   110025722    0.02%       11  void G1ScanCardClosure::do_oop_work<narrowOop>(narrowOop*)
   100288575    0.02%       10  Unsafe.park
    90426211    0.01%        9  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<286822ul, G1BarrierSet>, (AccessInternal::BarrierType)1, 286822ul>::oop_access_barrier(oopDesc*, long, oopDesc*)
    90389685    0.01%        9  futex_hash_[k]
    90282318    0.01%        9  exit_to_user_mode_prepare_[k]
    90241671    0.01%        9  pthread_mutex_trylock@@GLIBC_2.34
    90147481    0.01%        9  __condvar_dec_grefs
    90005968    0.01%        9  ReferencePipeline.map
    81155362    0.01%        8  futex_q_lock_[k]
    80364942    0.01%        8  __x64_sys_futex_[k]
    80321757    0.01%        8  VirtualThread.mount
    80236805    0.01%        8  G1CollectedHeap::requires_barriers(stackChunkOopDesc*) const
    80190499    0.01%        8  futex_wake_[k]
    80184290    0.01%        8  Thaw<Config<(oop_kind)0, G1BarrierSet> >::thaw_fast(stackChunkOopDesc*)
    80131101    0.01%        8  Unsafe.compareAndSetBoolean
    80069962    0.01%        8  __GI___pthread_mutex_lock
    80048507    0.01%        8  DirectMethodHandle.allocateInstance
    80041451    0.01%        8  VirtualThread.setCarrierThread
    80030852    0.01%        8  CellsGroup.run
    80003632    0.01%        8  ChannelsGrid.lambda$forEachChannel$1
    70907626    0.01%        7  futex_wait_[k]
    70293807    0.01%        7  VirtualThread.submitRunContinuation
    70111751    0.01%        7  VirtualThread$$Lambda$51.0x000000080103df08.run
    70015249    0.01%        7  G1ParScanThreadState::trim_queue_to_threshold(unsigned int)
    70005652    0.01%        7  StreamOpFlag.combineOpFlags
    60316827    0.01%        6  __pthread_mutex_unlock_usercnt
    60187073    0.01%        6  __pthread_mutex_cond_lock
    60179629    0.01%        6  ForkJoinPool.runWorker
    60103001    0.01%        6  GameOfLife$$Lambda$60.0x0000000801036308.test
    60075483    0.01%        6  _raw_spin_unlock_irq_[k]
    60059128    0.01%        6  long* thaw<Config<(oop_kind)0, G1BarrierSet> >(JavaThread*, int)
    59995848    0.01%        6  FreezeBase::recurse_freeze_compiled_frame(frame&, frame&, int, bool)
    50507216    0.01%        5  __get_user_nocheck_4_[k]
    50298892    0.01%        5  MemAllocator::allocate() const
    50209317    0.01%        5  schedule_[k]
    50184041    0.01%        5  Unsafe_Park
    50085874    0.01%        5  __get_user_8_[k]
    50055723    0.01%        5  AbstractQueuedSynchronizer$ConditionObject.await
    50046232    0.01%        5  __memset_avx2_unaligned_erms
    50002298    0.01%        5  MethodHandle.invokeBasic
    50001908    0.01%        5  G1CardSet::add_card(unsigned long)
    49969431    0.01%        5  ThawBase::recurse_thaw_compiled_frame(frame const&, frame&, int, bool)
    40493447    0.01%        4  do_syscall_64_[k]
    40363340    0.01%        4  ThreadsListHandle::ThreadsListHandle(Thread*)
    40327333    0.01%        4  SafeThreadsListPtr::release_stable_list()
    40152521    0.01%        4  __memcpy_sse2_unaligned
    40075450    0.01%        4  Unsafe_Unpark
    40073600    0.01%        4  mem_cgroup_handle_over_high_[k]
    40068384    0.01%        4  Continuation.yield
    40056492    0.01%        4  ThawBase::recurse_thaw_interpreted_frame(frame const&, frame&, int)
    40055783    0.01%        4  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<286822ul, G1BarrierSet>, (AccessInternal::BarrierType)3, 286822ul>::oop_access_barrier(oopDesc*, long)
    40032144    0.01%        4  ArrayList$ArrayListSpliterator.forEachRemaining
    40010820    0.01%        4  Invokers$Holder.linkToTargetMethod
    40010292    0.01%        4  Continuation.isDone
    40006699    0.01%        4  ForkJoinPool$WorkQueue.getAndSetAccess
    40003447    0.01%        4  FreezeBase::finalize_freeze(frame const&, frame&, int)
    40003249    0.01%        4  NonJavaThread::Iterator::step()
    39992835    0.01%        4  FreeListAllocator::release(void*)
    30295217    0.00%        3  get_futex_key_[k]
    30192906    0.00%        3  wake_q_add_safe_[k]
    30172287    0.00%        3  futex_wake_mark_[k]
    30130874    0.00%        3  JavaFrameAnchor::make_walkable()
    30102314    0.00%        3  futex_wait_queue_[k]
    30096235    0.00%        3  __condvar_confirm_wakeup
    30063781    0.00%        3  G1YoungRemSetSamplingClosure::do_heap_region(HeapRegion*)
    30060357    0.00%        3  Cont thaw
    30058081    0.00%        3  do_futex_[k]
    30045459    0.00%        3  System$2.unparkVirtualThread
    30043900    0.00%        3  __softirqentry_text_start_[k]
    30042508    0.00%        3  G1CardSet::occupied() const
    30032886    0.00%        3  AccessInternal::PostRuntimeDispatch<G1BarrierSet::AccessBarrier<548964ul, G1BarrierSet>, (AccessInternal::BarrierType)2, 548964ul>::oop_access_barrier(void*)
    30025131    0.00%        3  __GI___pthread_getspecific
    30023748    0.00%        3  calc_thresholds(unsigned long, unsigned long, unsigned int)
    30017190    0.00%        3  G1SegmentedArray::allocate()
    30012505    0.00%        3  OptoRuntime::new_instance_C(Klass*, JavaThread*)
    30005440    0.00%        3  Cell$$Lambda$64.0x0000000801036ba0.applyAsInt
    30000935    0.00%        3  AbstractQueuedSynchronizer$Node.setPrevRelaxed
    30000038    0.00%        3  __clock_gettime
    29999212    0.00%        3  VirtualThread.park
